
*****

####  琉璃苑軒風  
##### 1#       楼主       发表于 2025-2-6 15:03

 本帖最后由 琉璃苑軒風 于 2025-2-6 22:54 编辑 

看各路教程拼拼凑凑，我在实操中感觉其他其实都没什么卡点，但是最麻烦的反倒是模型的下载，动不动速度就掉到就几MB到几百KB，

所以我既然下完了，就分流一下ollama的默认精度（8B 14B 32B）少一个被下载模型的折腾都好，拷贝到目录里就行，这个反正跑前都要核验过MD5的不用担心

32B（能满足比较基础的要求，需要22-24显存，除了基础占用还有开始输入输出的额外占用，不能卡太死，可多卡凑一起，但是会慢点）

链接：[https://pan.baidu.com/s/1SvweXjREmcxplOkqj-uBkw?pwd=DEEP](https://pan.baidu.com/s/1SvweXjREmcxplOkqj-uBkw?pwd=DEEP) 

提取码：DEEP

14B（大概能有点用，需要10-12g显存）

链接：[https://pan.baidu.com/s/1CUUvIlmWMbqy2tW7TxJZDQ?pwd=DEEP](https://pan.baidu.com/s/1CUUvIlmWMbqy2tW7TxJZDQ?pwd=DEEP) 

提取码：DEEP

8B（8g显存左右的卡都能跑，能回话，其他不要想太多）

链接：[https://pan.baidu.com/s/1KM0-p_XXafeZiETeidxfxA?pwd=DEEP](https://pan.baidu.com/s/1KM0-p_XXafeZiETeidxfxA?pwd=DEEP) 

提取码：DEEP

有其他问题要问我能回答我都回答，折腾了一会终于有点明白了，还躺了不少雷

联网可以尝试用Page Assist插件（需要加速器）

如果能帮忙传个硅基流动的火也谢谢你，毕竟蒸馏就是服务器过载时候能用，肯定比不上完整部署的671B
[https://cloud.siliconflow.cn/i/erfbHC4B](https://cloud.siliconflow.cn/i/erfbHC4B)

<img src="https://img.saraba1st.com/forum/202502/06/145455dbtqttxcdgc11g01.jpg" referrerpolicy="no-referrer">

<strong>WechatIMG683.jpg</strong> (106.07 KB, 下载次数: 0)

下载附件

2025-2-6 14:54 上传

<img src="https://img.saraba1st.com/forum/202502/06/145455lyv2xabnu8xy7pu7.jpg" referrerpolicy="no-referrer">

<strong>WechatIMG684.jpg</strong> (178.53 KB, 下载次数: 0)

下载附件

2025-2-6 14:54 上传

﹍﹍﹍

评分

 参与人数 2战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| Horla| + 1|好评加鹅|
| a4ac7| + 1|好评加鹅|

查看全部评分

*****

####  我被骗了五块钱  
##### 2#       发表于 2025-2-6 15:04

显存不够可以用内存凑吗<img src="https://static.saraba1st.com/image/smiley/face/151.gif" referrerpolicy="no-referrer">

*****

####  琉璃苑軒風  
##### 3#         楼主| 发表于 2025-2-6 15:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358564&amp;ptid=2245374" target="_blank">我被骗了五块钱 发表于 2025-2-6 15:04</a>

显存不够可以用内存凑吗</blockquote>
可以，但是非常非常慢，70B我跑起来first token latency等到我没耐心了

我是四通道D4，可能12通道D5的epyc能好一些

*****

####  黄泉川此方  
##### 4#       发表于 2025-2-6 15:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358564&amp;ptid=2245374" target="_blank">我被骗了五块钱 发表于 2025-2-6 15:04</a>

显存不够可以用内存凑吗</blockquote>
可以，我试过24显存+32内存跑70B

很卡，也没比32B强很多

*****

####  天地一机成化育  
##### 5#       发表于 2025-2-6 15:14

目前对普通人来说本地部署依旧看不到性价比

*****

####  袄_偶滴小乔  
##### 6#       发表于 2025-2-6 15:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358564&amp;ptid=2245374" target="_blank">我被骗了五块钱 发表于 2025-2-6 15:04</a>
显存不够可以用内存凑吗</blockquote>
显存不够的时候gpu好像不工作的，是cpu在跑。

我68xt跑14b，全用显存的速度大概30token/s，跑更大模型16g显存不够用，走cpu运算直接崩到2token/s

*****

####  claymorep  
##### 7#       发表于 2025-2-6 15:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358620&amp;ptid=2245374" target="_blank">袄_偶滴小乔 发表于 2025-2-6 15:14</a>
显存不够的时候gpu好像不工作的，是cpu在跑。

我68xt跑14b，全用显存的速度大概30token/s，跑更大模型16 ...</blockquote>
好吧，我也16g显存，看来不能用更大的<img src="https://static.saraba1st.com/image/smiley/face2017/007.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  琉璃苑軒風  
##### 8#         楼主| 发表于 2025-2-6 15:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358666&amp;ptid=2245374" target="_blank">claymorep 发表于 2025-2-6 15:19</a>

好吧，我也16g显存，看来不能用更大的

—— 来自 鹅球 v3.3.96-alpha</blockquote>
意外之喜是可以多卡，我all in booom上本来想把8g那张卡卖掉的，结果误打误撞可以当24g的卡用了

*****

####  琉璃苑軒風  
##### 9#         楼主| 发表于 2025-2-6 15:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358619&amp;ptid=2245374" target="_blank">天地一机成化育 发表于 2025-2-6 15:14</a>

目前对普通人来说本地部署依旧看不到性价比</blockquote>
等迭代吧，我看评分，现在ds R1蒸馏出来的14B都比早先的的32B甚至70B强了

*****

####  makourisu-2  
##### 10#       发表于 2025-2-6 15:49

请问4070的笔记本能不能跑起来8B或者再小一点的模型<img src="https://static.saraba1st.com/image/smiley/face2017/007.png" referrerpolicy="no-referrer">有点好奇，想折腾玩玩看

*****

####  琉璃苑軒風  
##### 11#         楼主| 发表于 2025-2-6 15:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358918&amp;ptid=2245374" target="_blank">makourisu-2 发表于 2025-2-6 15:49</a>

请问4070的笔记本能不能跑起来8B或者再小一点的模型有点好奇，想折腾玩玩看 ...</blockquote>
可以8B以及以下，就是效果真就图一乐了

*****

####  tsukicn  
##### 12#       发表于 2025-2-6 15:56

有没有70b的，直接下太慢了。。。

*****

####  sese199  
##### 13#       发表于 2025-2-6 15:59

我看nga上一个帖子，说8g显存+32g内存就能跑32b q4的蒸馏模型？

*****

####  子虚乌有  
##### 14#       发表于 2025-2-6 16:00

本地跑可以写刘备文了吗

*****

####  moekyo  
##### 15#       发表于 2025-2-6 16:12

国内不是有这个对标的分发网站吗
[https://modelscope.cn/models](https://modelscope.cn/models)

*****

####  xburke  
##### 16#       发表于 2025-2-6 16:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359003&amp;ptid=2245374" target="_blank">sese199 发表于 2025-2-6 15:59</a>

我看nga上一个帖子，说8g显存+32g内存就能跑32b q4的蒸馏模型？</blockquote>
4g显存+32g内存就可以

*****

####  黄泉川此方  
##### 17#       发表于 2025-2-6 16:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359011&amp;ptid=2245374" target="_blank">子虚乌有 发表于 2025-2-6 16:00</a>

本地跑可以写刘备文了吗</blockquote>
写出来的是地摊文学级别

70B消融以后会变成弱智

*****

####  琉璃苑軒風  
##### 18#         楼主| 发表于 2025-2-6 16:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359003&amp;ptid=2245374" target="_blank">sese199 发表于 2025-2-6 15:59</a>

我看nga上一个帖子，说8g显存+32g内存就能跑32b q4的蒸馏模型？</blockquote>
速度正常么？我四通道D4反正拉稀的一塌糊涂。

*****

####  琉璃苑軒風  
##### 19#         楼主| 发表于 2025-2-6 16:21

 本帖最后由 琉璃苑軒風 于 2025-2-6 16:26 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359011&amp;ptid=2245374" target="_blank">子虚乌有 发表于 2025-2-6 16:00</a>

本地跑可以写刘备文了吗</blockquote>
没试过，看攻略是破防容易，但是本地的精度，写出来很是不好看

*****

####  琉璃苑軒風  
##### 20#         楼主| 发表于 2025-2-6 16:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359112&amp;ptid=2245374" target="_blank">moekyo 发表于 2025-2-6 16:12</a>

国内不是有这个对标的分发网站吗

https://modelscope.cn/models</blockquote>
没有合适的网络，这个也不快

*****

####  moekyo  
##### 21#       发表于 2025-2-6 16:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359218&amp;ptid=2245374" target="_blank">琉璃苑軒風 发表于 2025-2-6 16:24</a>

没有合适的网络，这个也不快</blockquote>
我又搜到了这两个，当然我也没试过就是了
[https://hf-mirror.com/](https://hf-mirror.com/)
[https://aifasthub.com/](https://aifasthub.com/)

*****

####  chaosliu  
##### 22#       发表于 2025-2-6 16:35

我用4070tis也能部署32B的蒸馏模型，token的生成速度也可以接受<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">

*****

####  xing7673  
##### 23#       发表于 2025-2-6 16:37

我还以为你折腾了deepseek的联网搜索功能

正需要这个东西

*****

####  王苍幻  
##### 24#       发表于 2025-2-6 16:43

但是个人使用本地部署真的没啥意义
api就足够了

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  王苍幻  
##### 25#       发表于 2025-2-6 16:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359297&amp;ptid=2245374" target="_blank">chaosliu 发表于 2025-2-6 16:35</a>
我用4070tis也能部署32B的蒸馏模型，token的生成速度也可以接受</blockquote>
同显卡
那速度我不能忍受

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  zhao25  
##### 26#       发表于 2025-2-6 16:50

模型下好了，是直接覆盖到我之前的文件夹里面吗

*****

####  海底铁锚  
##### 27#       发表于 2025-2-6 16:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359316&amp;ptid=2245374" target="_blank">xing7673 发表于 2025-2-6 16:37</a>
我还以为你折腾了deepseek的联网搜索功能

正需要这个东西</blockquote>
用anything llm就可以了，有比较基础的搜索。

*****

####  kira1988  
##### 28#       发表于 2025-2-6 16:50

要本地部署满血版需要什么配置

*****

####  大十字紅朔  
##### 29#       发表于 2025-2-6 16:50

可以写涩涩吗？

*****

####  琉璃苑軒風  
##### 30#         楼主| 发表于 2025-2-6 16:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359426&amp;ptid=2245374" target="_blank">kira1988 发表于 2025-2-6 16:50</a>

要本地部署满血版需要什么配置</blockquote>
1342g基础显存+额外输入输出显存，别说个人，中小企业都很难有这个配置

*****

####  琉璃苑軒風  
##### 31#         楼主| 发表于 2025-2-6 16:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359423&amp;ptid=2245374" target="_blank">zhao25 发表于 2025-2-6 16:50</a>

模型下好了，是直接覆盖到我之前的文件夹里面吗</blockquote>
是的

。zsbd

*****

####  琉璃苑軒風  
##### 32#         楼主| 发表于 2025-2-6 19:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359369&amp;ptid=2245374" target="_blank">王苍幻 发表于 2025-2-6 16:43</a>

但是个人使用本地部署真的没啥意义

api就足够了</blockquote>
我主楼已经有提到了，“毕竟蒸馏就是服务器过载时候能用，肯定比不上完整部署的671B”

api能正常用不抽风，那肯定比本地好阿，但是现在这个ds日常抽风，硅基间歇抽风的前提下

本地部署是决定了下限，而非上限

*****

####  精钢魔像  
##### 33#       发表于 2025-2-6 19:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359425&amp;ptid=2245374" target="_blank">海底铁锚 发表于 2025-2-6 16:50</a>

用anything llm就可以了，有比较基础的搜索。</blockquote>
效果怎么样，能有kimi的水平吗

*****

####  Lsky  
##### 34#       发表于 2025-2-6 20:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359426&amp;ptid=2245374" target="_blank">kira1988 发表于 2025-2-6 16:50</a>

要本地部署满血版需要什么配置</blockquote>
[https://www.bilibili.com/video/BV1REPqeFE6d/](https://www.bilibili.com/video/BV1REPqeFE6d/)

从这个视频看的话，4B量化版本，用cpu跑，用400g左右的内存可以

成本50000

*****

####  FeteFete  
##### 35#       发表于 2025-2-6 20:49

量化了么？

要是量化的话用的是多少量化?

*****

####  肥胖的道奇兔  
##### 36#       发表于 2025-2-6 21:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358564&amp;ptid=2245374" target="_blank">我被骗了五块钱 发表于 2025-2-6 15:04</a>

显存不够可以用内存凑吗</blockquote>
用16G显存的卡能跑32b吗

*****

####  darktide  
##### 37#       发表于 2025-2-6 21:32

本地部署有啥教程没？包括联网搜索的

*****

####  琉璃苑軒風  
##### 38#         楼主| 发表于 2025-2-6 22:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67361219&amp;ptid=2245374" target="_blank">darktide 发表于 2025-2-6 21:32</a>

本地部署有啥教程没？包括联网搜索的</blockquote>
这个一大堆，我就是东拼西凑发现没有卡点，除了下模型下的要死要活，所以做了下分流

﹍﹍﹍

评分

 参与人数 1战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| darktide| + 2|好的，谢谢|

查看全部评分

*****

####  琉璃苑軒風  
##### 39#         楼主| 发表于 2025-2-6 22:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67359316&amp;ptid=2245374" target="_blank">xing7673 发表于 2025-2-6 16:37</a>

我还以为你折腾了deepseek的联网搜索功能

正需要这个东西</blockquote>
咦？刚才没回复上？

这个挂Page Assist就行（搜这个名字就有一大堆教程），比是比不上原版，但是也有明显改善结果

*****

####  シマエナガ  
##### 40#       发表于 2025-2-7 08:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67358918&amp;ptid=2245374" target="_blank">makourisu-2 发表于 2025-2-6 15:49</a>

请问4070的笔记本能不能跑起来8B或者再小一点的模型有点好奇，想折腾玩玩看 ...</blockquote>
内存够大就行 跑GGUF可以


*****

####  zhao25  
##### 41#       发表于 2025-2-7 08:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67361140&amp;ptid=2245374" target="_blank">肥胖的道奇兔 发表于 2025-2-6 21:19</a>

用16G显存的卡能跑32b吗</blockquote>
我12G显存，跑起来了32b的，就是有点慢，估计是用内存了。。。

