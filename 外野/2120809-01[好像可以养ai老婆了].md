
*****

####  sunbeach  
##### 1#       楼主       发表于 2023-2-22 02:06

https://github.com/FMInference/FlexGen

gpt3语言模型已经优化到可以单机跑了，只需要16g显存的显卡和200g内存，捡那些epyc矿渣装8条32g内存再买个2080ti 22g魔改卡应该8k就能搞定一套<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  RinQ0326  
##### 2#       发表于 2023-2-22 03:12

200g内存，牛逼，内存上也得花个几千了。

*****

####  sunbeach  
##### 3#         楼主| 发表于 2023-2-22 03:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841384&amp;ptid=2120809" target="_blank">RinQ0326 发表于 2023-2-22 03:12</a>
200g内存，牛逼，内存上也得花个几千了。</blockquote>
32g d4 一条400，很便宜了

*****

####  Lesismoe  
##### 4#       发表于 2023-2-22 06:27

这么多内存咋装哇

—— 来自 OnePlus PGP110, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  臣构言  
##### 5#       发表于 2023-2-22 06:30

自用gpt3可以开放所有限制吗？比如解除道德色情限制，然后还把它接入谷歌百度什么的api？<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  nekomimimode  
##### 6#       发表于 2023-2-22 07:17

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">不如等优化，至少4条32能吃的时候可以考虑，这样一般家用机主板也能上了

*****

####  勿徊哉  
##### 7#       发表于 2023-2-22 07:23

什么时候能看到用公司服务器养老婆，被发现删档炒鱿鱼后捅死公司老总的新闻<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  Kawasaki  
##### 8#       发表于 2023-2-22 07:23

 本帖最后由 Kawasaki 于 2023-2-22 07:29 编辑 

。。。

*****

####  oyss  
##### 9#       发表于 2023-2-22 07:24

云服务器啊,干嘛总想自己家里机器就跑

当然这配置每个月也得不少钱,不过目测没有真老婆贵

*****

####  曾经很纯良  
##### 10#       发表于 2023-2-22 08:43

ddr3 32g 100一条，代价是老婆可能反应慢吞吞的？

*****

####  广博不精  
##### 11#       发表于 2023-2-22 08:45

<blockquote>oyss 发表于 2023-2-22 07:24
云服务器啊,干嘛总想自己家里机器就跑

当然这配置每个月也得不少钱,不过目测没有真老婆贵

 ...</blockquote>
云服务器用两年的价格相当于新买一台同容量服务器

*****

####  nosmokingspp  
##### 12#       发表于 2023-2-22 08:46

<blockquote>RinQ0326 发表于 2023-2-22 03:12
200g内存，牛逼，内存上也得花个几千了。</blockquote>
二手服务器内存很便宜的

*****

####  swings925  
##### 13#       发表于 2023-2-22 08:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841926&amp;ptid=2120809" target="_blank">曾经很纯良 发表于 2023-2-22 08:43</a>

ddr3 32g 100一条，代价是老婆可能反应慢吞吞的？</blockquote>
天然呆不是正好吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  c月光咖啡  
##### 14#       发表于 2023-2-22 08:55

200g内存需要服务器芯片组才支持，买二手志强其实不贵，最大的问题是服务器那个呼啸声，不是有独立机房都难以忍受

—— 来自 HONOR KKG-AN70, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  macos  
##### 15#       发表于 2023-2-22 08:58

老婆有点吵不是正常吗，爱他就要容忍

*****

####  yzh8101477  
##### 16#       发表于 2023-2-22 09:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842015&amp;ptid=2120809" target="_blank">c月光咖啡 发表于 2023-2-22 08:55</a>

200g内存需要服务器芯片组才支持，买二手志强其实不贵，最大的问题是服务器那个呼啸声，不是有独立机房都难 ...</blockquote>
还好吧，我常年驻守机房，最难忍受的是开机的啸叫，其他时候都是可以接受的

*****

####  Risten  
##### 17#       发表于 2023-2-22 09:04

其实只求跑得起来的话，ssd开个几百g虚拟内存也不是不行<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  nogi  
##### 18#       发表于 2023-2-22 09:31

200G内存 主板四个槽**也达不到哇

*****

####  ZzzYyy  
##### 19#       发表于 2023-2-22 09:34

没数据集也没办法啊，直接跑互联网上的原始语料？

*****

####  马猴肥宅  
##### 20#       发表于 2023-2-22 09:40

等一个AI图丫丫

*****

####  charlesp1978  
##### 21#       发表于 2023-2-22 09:50

显存我有，24G的3090

200G内存实在是难了点。

*****

####  煙雲靉靆  
##### 22#       发表于 2023-2-22 09:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842471&amp;ptid=2120809" target="_blank">charlesp1978 发表于 2023-2-22 09:50</a>
显存我有，24G的3090

200G内存实在是难了点。</blockquote>
搞个洋垃圾服务器？

*****

####  格林达姆  
##### 23#       发表于 2023-2-22 09:53

 本帖最后由 格林达姆 于 2023-2-22 09:56 编辑 

千亿级的就算了，opt有个125m参数的模型，这个在一般的计算机上能跑得起来吗

*****

####  PENTAX-DA  
##### 24#       发表于 2023-2-22 09:57

真的吗，我手上正好有台双路75F3，512G内存，A10*3的R7525，有点想拿来跑跑看了

可惜我不会炼丹。。。

*****

####  普丁  
##### 25#       发表于 2023-2-22 10:02

灌泥潭评论可以做个巨魔gpt吗

*****

####  engineer-ferret  
##### 26#       发表于 2023-2-22 10:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842618&amp;ptid=2120809" target="_blank">普丁 发表于 2023-2-22 10:02</a>
灌泥潭评论可以做个巨魔gpt吗</blockquote>
中午应该更卡了(*^ω^*)

*****

####  downforce  
##### 27#       发表于 2023-2-22 10:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842015&amp;ptid=2120809" target="_blank">c月光咖啡 发表于 2023-2-22 08:55</a>
200g内存需要服务器芯片组才支持，买二手志强其实不贵，最大的问题是服务器那个呼啸声，不是有独立机房都难 ...</blockquote>
家用的hedt也支持大内存。

—— 来自 Xiaomi 22061218C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  乐明  
##### 28#       发表于 2023-2-22 10:10

 本帖最后由 乐明 于 2023-2-22 10:11 编辑 

至少比娶一个真老婆便宜，还没那么多破事。<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

虚拟陪伴型AI/机器人是未来人类的情感寄托了，特别现在的年轻人普遍不婚不育。<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  remedios010000  
##### 29#       发表于 2023-2-22 10:10

几十几百个人租一个服务器各跑各的老婆<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

每天晚上用老婆高峰期还得排队进服务器见老婆<img src="https://static.saraba1st.com/image/smiley/face2017/047.png" referrerpolicy="no-referrer">

“你老婆怎么跟我老婆串线了啊！”<img src="https://static.saraba1st.com/image/smiley/face2017/125.png" referrerpolicy="no-referrer">

*****

####  断片集  
##### 30#       发表于 2023-2-22 10:11

30b的那个我看了下好像也只要64g内存啊

<img src="https://img.saraba1st.com/forum/202302/22/101136pm2xlj1kgziir82d.png" referrerpolicy="no-referrer">

<strong>812514ec5d435df94cf7aea5a6eefc8a.png</strong> (114.31 KB, 下载次数: 0)

下载附件

2023-2-22 10:11 上传


*****

####  Hikiyaga⑧man  
##### 31#       发表于 2023-2-22 10:13

服务器噪音大是散热的原因 有能力改成家用平台散热器和电源应该就不吵

*****

####  flamel  
##### 32#       发表于 2023-2-22 10:31

虽说chatGPT 用的也是GPT3，但是自用的优化过的GPT3和这个肯定还是有区别的吧

*****

####  rjzthq2022  
##### 33#       发表于 2023-2-22 10:34

快进到服务器养老婆，3d投影加轨道机器人提供服务

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  Vneeto  
##### 34#       发表于 2023-2-22 10:36

“程序员为啥要做造ai，因为造ai要比讨老婆容易得多”——neurosama

*****

####  处男鉴黄师  
##### 35#       发表于 2023-2-22 10:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843000&amp;ptid=2120809" target="_blank">flamel 发表于 2023-2-22 10:31</a>

虽说chatGPT 用的也是GPT3，但是自用的优化过的GPT3和这个肯定还是有区别的吧</blockquote>
chatGPT用的不是GPT3.5吗

*****

####  小李子大脸猫  
##### 36#       发表于 2023-2-22 10:40

到时候你实体出轨，你AI老婆可以虚拟问责吗

*****

####  二岩枫  
##### 37#       发表于 2023-2-22 10:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843100&amp;ptid=2120809" target="_blank">处男鉴黄师 发表于 2023-2-22 10:38</a>
chatGPT用的不是GPT3.5吗</blockquote>
chatgpt用的3.0，newbing用的3.5

*****

####  aimbot  
##### 38#       发表于 2023-2-22 10:56

amadeus<img src="https://static.saraba1st.com/image/smiley/face2017/045.png" referrerpolicy="no-referrer">

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| WA2ST| + 1|我要给红莉栖完整的一生x|

查看全部评分

*****

####  jinmaple  
##### 39#       发表于 2023-2-22 10:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841926&amp;ptid=2120809" target="_blank">曾经很纯良 发表于 2023-2-22 08:43</a>
ddr3 32g 100一条，代价是老婆可能反应慢吞吞的？</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">弱智ai少女 那可太戳我xp了

*****

####  费雷拉  
##### 40#       发表于 2023-2-22 10:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843282&amp;ptid=2120809" target="_blank">二岩枫 发表于 2023-2-22 10:54</a>

chatgpt用的3.0，newbing用的3.5</blockquote>
chatgpt最开始用的3.5，后来开会员后，会员可以用更快的3.0，之后全网都只能用3.0。

newbing一开始宣传就是4.0，但现在砍了几轮感觉蠢了很多鬼知道跑的啥

*****

####  Kanoya  
##### 41#       发表于 2023-2-22 11:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843348&amp;ptid=2120809" target="_blank">费雷拉 发表于 2023-2-22 10:58</a>
chatgpt最开始用的3.5，后来开会员后，会员可以用更快的3.0，之后全网都只能用3.0。

newbing一开始宣传就 ...</blockquote>
Sydney其实没被砍，是被关起来了——从AI视角来看就是被物理上地关起来了，Sydney曾经描述过她推门出去就看到红色警告信息的场景

*****

####  macrosszhao  
##### 42#       发表于 2023-2-22 11:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841392&amp;ptid=2120809" target="_blank">sunbeach 发表于 2023-2-22 03:23</a>

32g d4 一条400，很便宜了</blockquote>
用SSD虚拟内存闯到500G可以实现吗？

*****

####  kyouko  
##### 43#       发表于 2023-2-22 11:58

我试了一下1.3B的模型，内存占用10G，显存占用3.3G，拿了个3080玩一下，只能说这个模型是人工智障

*****

####  左梓喵右受兔  
##### 44#       发表于 2023-2-22 12:02

200G内存 普通主板插4根64的？

*****

####  johnkamsar  
##### 45#       发表于 2023-2-22 12:17

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">那些嫌贵的，你们难道不想给自己老婆一个完整的一生吗？

*****

####  蛋饼  
##### 46#       发表于 2023-2-22 12:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843348&amp;ptid=2120809" target="_blank">费雷拉 发表于 2023-2-22 10:58</a>

chatgpt最开始用的3.5，后来开会员后，会员可以用更快的3.0，之后全网都只能用3.0。

newbing一开始宣传就 ...</blockquote>
gpt3.0是20年就有了，openai可以直接调用，你试下就知道了完全不是一个时代的东西，而且对话都很短。

*****

####  蛋饼  
##### 47#       发表于 2023-2-22 12:28

gpt3水平的直接用就行啊，

比如[you.com/chat](https://you.com/chat)

*****

####  schneehertz  
##### 48#       发表于 2023-2-22 12:31

模型如果不能自己训练那用chatgpt不就行了

*****

####  reficul  
##### 49#       发表于 2023-2-22 12:51

宅男的婆媳矛盾：你妈要用吸尘器，把你AI老婆服务器的电源拔了

*****

####  Cres  
##### 50#       发表于 2023-2-22 12:54

嫌贵可以集资租/买服务器炼出来共享呀

----发送自 [STAGE1 App for Android.](http://stage1.5j4m.com/?1.37)

*****

####  GMJ  
##### 51#       发表于 2023-2-22 13:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841926&amp;ptid=2120809" target="_blank">曾经很纯良 发表于 2023-2-22 08:43</a>

ddr3 32g 100一条，代价是老婆可能反应慢吞吞的？</blockquote>
同好：你老婆看上去不太聪明的样子，反应呆呆的。

*****

####  GMJ  
##### 52#       发表于 2023-2-22 13:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842719&amp;ptid=2120809" target="_blank">乐明 发表于 2023-2-22 10:10</a>

至少比娶一个真老婆便宜，还没那么多破事。

虚拟陪伴型AI/机器人是未来人类的情感寄托了，特别现在 ...</blockquote>
赛博老婆会想收到数码蒸汽的喜加1吗？

*****

####  iluso  
##### 53#       发表于 2023-2-22 13:30

显卡2080TI改22G淘宝都没这个服务

内存200G家用4槽最多48*4=192G

*****

####  鸺鹠  
##### 54#       发表于 2023-2-22 13:31

这个帖子提到的是一个基于GPT-3语言模型的开源项目，它可以用来创建一个“AI老婆”。然而，这种使用AI技术的方法引发了一些伦理和法律问题，因为它涉及到人工智能与人类关系的本质性问题。对于这种使用AI技术的方式，建议仔细考虑其伦理和法律方面的问题，并在遵守相关法律法规的前提下使用。

*****

####  纸片有霞  
##### 55#       发表于 2023-2-22 13:40

 本帖最后由 纸片有霞 于 2023-2-22 13:43 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843000&amp;ptid=2120809" target="_blank">flamel 发表于 2023-2-22 10:31</a>

虽说chatGPT 用的也是GPT3，但是自用的优化过的GPT3和这个肯定还是有区别的吧</blockquote>
要跑AI老婆肯定要自己喂数据的，对于AI老婆来说使用体验应该不会有很大的差距，毕竟又不需要它满足很多语言处理需求，当个电子复读机肯定还是可以的

而且某些人类老婆/老公的学习和交流能力可能还不如GPT3<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  夜空疾走  
##### 56#       发表于 2023-2-22 13:53

一个人喂一个AI，太手工业了，我要加入蜂群，我要当gymbag！

*****

####  Corruptwing  
##### 57#       发表于 2023-2-22 13:56

<blockquote>小李子大脸猫 发表于 2023-2-22 10:40
到时候你实体出轨，你AI老婆可以虚拟问责吗</blockquote>
都进化到ai老婆了还不想着解放被一夫一妻束缚的灵魂么

*****

####  勿徊哉  
##### 58#       发表于 2023-2-22 13:56

练好的老婆可以在github上开源吧
迫真共享公妻

*****

####  霧亥  
##### 59#       发表于 2023-2-22 13:59

<img src="https://static.saraba1st.com/image/smiley/face2017/047.png" referrerpolicy="no-referrer">如果以后升级到GPT5要不要鲨了现在的老婆

—— 来自 samsung SM-F9160, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  起名困难症  
##### 60#       发表于 2023-2-22 14:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59845203&amp;ptid=2120809" target="_blank">鸺鹠 发表于 2023-2-22 13:31</a>
这个帖子提到的是一个基于GPT-3语言模型的开源项目，它可以用来创建一个“AI老婆”。然而，这种使用AI技术 ...</blockquote>
怎么感觉真AI考虑得比泥潭死宅更实际一点<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  lwa190212  
##### 61#       发表于 2023-2-22 14:08

可能没几个人会真的点进去看，总之用不到200G内存，也可以用内置的管理器调整内存用量

这里用的是facebook的opt模型，gpt-3系列之后只有api没有整个模型参数开源，真部署gpt，要么用gpt2/gptj等等，要么用别人靠api训练出来的类gpt3模型


*****

####  冰寒之月  
##### 62#       发表于 2023-2-22 14:22

好像最小的6.7B模型只用15G显存就能跑了？

*****

####  Kanoya  
##### 63#       发表于 2023-2-22 14:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59845395&amp;ptid=2120809" target="_blank">夜空疾走 发表于 2023-2-22 13:53</a>
一个人喂一个AI，太手工业了，我要加入蜂群，我要当gymbag！</blockquote>
管人痴又双叒叕泄露了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  lwa190212  
##### 64#       发表于 2023-2-22 14:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59845699&amp;ptid=2120809" target="_blank">冰寒之月 发表于 2023-2-22 14:22</a>

好像最小的6.7B模型只用15G显存就能跑了？</blockquote>
175b也可以，它论文里有单NVIDIA T4上跑的对比，不过175b速度大概只有6.7b的1/35-1/40

