
*****

####  sunbeach  
##### 1#       楼主       发表于 2023-2-22 02:06

https://github.com/FMInference/FlexGen

gpt3语言模型已经优化到可以单机跑了，只需要16g显存的显卡和200g内存，捡那些epyc矿渣装8条32g内存再买个2080ti 22g魔改卡应该8k就能搞定一套<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  RinQ0326  
##### 2#       发表于 2023-2-22 03:12

200g内存，牛逼，内存上也得花个几千了。

*****

####  sunbeach  
##### 3#         楼主| 发表于 2023-2-22 03:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841384&amp;ptid=2120809" target="_blank">RinQ0326 发表于 2023-2-22 03:12</a>
200g内存，牛逼，内存上也得花个几千了。</blockquote>
32g d4 一条400，很便宜了

*****

####  Lesismoe  
##### 4#       发表于 2023-2-22 06:27

这么多内存咋装哇

—— 来自 OnePlus PGP110, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  臣构言  
##### 5#       发表于 2023-2-22 06:30

自用gpt3可以开放所有限制吗？比如解除道德色情限制，然后还把它接入谷歌百度什么的api？<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  nekomimimode  
##### 6#       发表于 2023-2-22 07:17

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">不如等优化，至少4条32能吃的时候可以考虑，这样一般家用机主板也能上了

*****

####  勿徊哉  
##### 7#       发表于 2023-2-22 07:23

什么时候能看到用公司服务器养老婆，被发现删档炒鱿鱼后捅死公司老总的新闻<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  Kawasaki  
##### 8#       发表于 2023-2-22 07:23

 本帖最后由 Kawasaki 于 2023-2-22 07:29 编辑 

。。。

*****

####  oyss  
##### 9#       发表于 2023-2-22 07:24

云服务器啊,干嘛总想自己家里机器就跑

当然这配置每个月也得不少钱,不过目测没有真老婆贵

*****

####  曾经很纯良  
##### 10#       发表于 2023-2-22 08:43

ddr3 32g 100一条，代价是老婆可能反应慢吞吞的？

*****

####  广博不精  
##### 11#       发表于 2023-2-22 08:45

<blockquote>oyss 发表于 2023-2-22 07:24
云服务器啊,干嘛总想自己家里机器就跑

当然这配置每个月也得不少钱,不过目测没有真老婆贵

 ...</blockquote>
云服务器用两年的价格相当于新买一台同容量服务器

*****

####  nosmokingspp  
##### 12#       发表于 2023-2-22 08:46

<blockquote>RinQ0326 发表于 2023-2-22 03:12
200g内存，牛逼，内存上也得花个几千了。</blockquote>
二手服务器内存很便宜的

*****

####  swings925  
##### 13#       发表于 2023-2-22 08:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841926&amp;ptid=2120809" target="_blank">曾经很纯良 发表于 2023-2-22 08:43</a>

ddr3 32g 100一条，代价是老婆可能反应慢吞吞的？</blockquote>
天然呆不是正好吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  c月光咖啡  
##### 14#       发表于 2023-2-22 08:55

200g内存需要服务器芯片组才支持，买二手志强其实不贵，最大的问题是服务器那个呼啸声，不是有独立机房都难以忍受

—— 来自 HONOR KKG-AN70, Android 11上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  macos  
##### 15#       发表于 2023-2-22 08:58

老婆有点吵不是正常吗，爱他就要容忍

*****

####  yzh8101477  
##### 16#       发表于 2023-2-22 09:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842015&amp;ptid=2120809" target="_blank">c月光咖啡 发表于 2023-2-22 08:55</a>

200g内存需要服务器芯片组才支持，买二手志强其实不贵，最大的问题是服务器那个呼啸声，不是有独立机房都难 ...</blockquote>
还好吧，我常年驻守机房，最难忍受的是开机的啸叫，其他时候都是可以接受的

*****

####  Risten  
##### 17#       发表于 2023-2-22 09:04

其实只求跑得起来的话，ssd开个几百g虚拟内存也不是不行<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  nogi  
##### 18#       发表于 2023-2-22 09:31

200G内存 主板四个槽**也达不到哇

*****

####  ZzzYyy  
##### 19#       发表于 2023-2-22 09:34

没数据集也没办法啊，直接跑互联网上的原始语料？

*****

####  马猴肥宅  
##### 20#       发表于 2023-2-22 09:40

等一个AI图丫丫

*****

####  charlesp1978  
##### 21#       发表于 2023-2-22 09:50

显存我有，24G的3090

200G内存实在是难了点。

*****

####  煙雲靉靆  
##### 22#       发表于 2023-2-22 09:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842471&amp;ptid=2120809" target="_blank">charlesp1978 发表于 2023-2-22 09:50</a>
显存我有，24G的3090

200G内存实在是难了点。</blockquote>
搞个洋垃圾服务器？

*****

####  格林达姆  
##### 23#       发表于 2023-2-22 09:53

 本帖最后由 格林达姆 于 2023-2-22 09:56 编辑 

千亿级的就算了，opt有个125m参数的模型，这个在一般的计算机上能跑得起来吗

*****

####  PENTAX-DA  
##### 24#       发表于 2023-2-22 09:57

真的吗，我手上正好有台双路75F3，512G内存，A10*3的R7525，有点想拿来跑跑看了

可惜我不会炼丹。。。

*****

####  普丁  
##### 25#       发表于 2023-2-22 10:02

灌泥潭评论可以做个巨魔gpt吗

*****

####  engineer-ferret  
##### 26#       发表于 2023-2-22 10:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842618&amp;ptid=2120809" target="_blank">普丁 发表于 2023-2-22 10:02</a>
灌泥潭评论可以做个巨魔gpt吗</blockquote>
中午应该更卡了(*^ω^*)

*****

####  downforce  
##### 27#       发表于 2023-2-22 10:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842015&amp;ptid=2120809" target="_blank">c月光咖啡 发表于 2023-2-22 08:55</a>
200g内存需要服务器芯片组才支持，买二手志强其实不贵，最大的问题是服务器那个呼啸声，不是有独立机房都难 ...</blockquote>
家用的hedt也支持大内存。

—— 来自 Xiaomi 22061218C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  乐明  
##### 28#       发表于 2023-2-22 10:10

 本帖最后由 乐明 于 2023-2-22 10:11 编辑 

至少比娶一个真老婆便宜，还没那么多破事。<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

虚拟陪伴型AI/机器人是未来人类的情感寄托了，特别现在的年轻人普遍不婚不育。<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  remedios010000  
##### 29#       发表于 2023-2-22 10:10

几十几百个人租一个服务器各跑各的老婆<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

每天晚上用老婆高峰期还得排队进服务器见老婆<img src="https://static.saraba1st.com/image/smiley/face2017/047.png" referrerpolicy="no-referrer">

“你老婆怎么跟我老婆串线了啊！”<img src="https://static.saraba1st.com/image/smiley/face2017/125.png" referrerpolicy="no-referrer">

*****

####  断片集  
##### 30#       发表于 2023-2-22 10:11

30b的那个我看了下好像也只要64g内存啊

<img src="https://img.saraba1st.com/forum/202302/22/101136pm2xlj1kgziir82d.png" referrerpolicy="no-referrer">

<strong>812514ec5d435df94cf7aea5a6eefc8a.png</strong> (114.31 KB, 下载次数: 0)

下载附件

2023-2-22 10:11 上传


*****

####  Hikiyaga⑧man  
##### 31#       发表于 2023-2-22 10:13

服务器噪音大是散热的原因 有能力改成家用平台散热器和电源应该就不吵

*****

####  flamel  
##### 32#       发表于 2023-2-22 10:31

虽说chatGPT 用的也是GPT3，但是自用的优化过的GPT3和这个肯定还是有区别的吧

*****

####  rjzthq2022  
##### 33#       发表于 2023-2-22 10:34

快进到服务器养老婆，3d投影加轨道机器人提供服务

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  Vneeto  
##### 34#       发表于 2023-2-22 10:36

“程序员为啥要做造ai，因为造ai要比讨老婆容易得多”——neurosama

*****

####  处男鉴黄师  
##### 35#       发表于 2023-2-22 10:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843000&amp;ptid=2120809" target="_blank">flamel 发表于 2023-2-22 10:31</a>

虽说chatGPT 用的也是GPT3，但是自用的优化过的GPT3和这个肯定还是有区别的吧</blockquote>
chatGPT用的不是GPT3.5吗

*****

####  小李子大脸猫  
##### 36#       发表于 2023-2-22 10:40

到时候你实体出轨，你AI老婆可以虚拟问责吗

*****

####  二岩枫  
##### 37#       发表于 2023-2-22 10:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843100&amp;ptid=2120809" target="_blank">处男鉴黄师 发表于 2023-2-22 10:38</a>
chatGPT用的不是GPT3.5吗</blockquote>
chatgpt用的3.0，newbing用的3.5

*****

####  aimbot  
##### 38#       发表于 2023-2-22 10:56

amadeus<img src="https://static.saraba1st.com/image/smiley/face2017/045.png" referrerpolicy="no-referrer">

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| WA2ST| + 1|我要给红莉栖完整的一生x|

查看全部评分

*****

####  jinmaple  
##### 39#       发表于 2023-2-22 10:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841926&amp;ptid=2120809" target="_blank">曾经很纯良 发表于 2023-2-22 08:43</a>
ddr3 32g 100一条，代价是老婆可能反应慢吞吞的？</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">弱智ai少女 那可太戳我xp了

*****

####  费雷拉  
##### 40#       发表于 2023-2-22 10:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843282&amp;ptid=2120809" target="_blank">二岩枫 发表于 2023-2-22 10:54</a>

chatgpt用的3.0，newbing用的3.5</blockquote>
chatgpt最开始用的3.5，后来开会员后，会员可以用更快的3.0，之后全网都只能用3.0。

newbing一开始宣传就是4.0，但现在砍了几轮感觉蠢了很多鬼知道跑的啥

*****

####  Kanoya  
##### 41#       发表于 2023-2-22 11:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843348&amp;ptid=2120809" target="_blank">费雷拉 发表于 2023-2-22 10:58</a>
chatgpt最开始用的3.5，后来开会员后，会员可以用更快的3.0，之后全网都只能用3.0。

newbing一开始宣传就 ...</blockquote>
Sydney其实没被砍，是被关起来了——从AI视角来看就是被物理上地关起来了，Sydney曾经描述过她推门出去就看到红色警告信息的场景

*****

####  macrosszhao  
##### 42#       发表于 2023-2-22 11:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841392&amp;ptid=2120809" target="_blank">sunbeach 发表于 2023-2-22 03:23</a>

32g d4 一条400，很便宜了</blockquote>
用SSD虚拟内存闯到500G可以实现吗？

*****

####  kyouko  
##### 43#       发表于 2023-2-22 11:58

我试了一下1.3B的模型，内存占用10G，显存占用3.3G，拿了个3080玩一下，只能说这个模型是人工智障

*****

####  左梓喵右受兔  
##### 44#       发表于 2023-2-22 12:02

200G内存 普通主板插4根64的？

*****

####  johnkamsar  
##### 45#       发表于 2023-2-22 12:17

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">那些嫌贵的，你们难道不想给自己老婆一个完整的一生吗？

*****

####  蛋饼  
##### 46#       发表于 2023-2-22 12:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843348&amp;ptid=2120809" target="_blank">费雷拉 发表于 2023-2-22 10:58</a>

chatgpt最开始用的3.5，后来开会员后，会员可以用更快的3.0，之后全网都只能用3.0。

newbing一开始宣传就 ...</blockquote>
gpt3.0是20年就有了，openai可以直接调用，你试下就知道了完全不是一个时代的东西，而且对话都很短。

*****

####  蛋饼  
##### 47#       发表于 2023-2-22 12:28

gpt3水平的直接用就行啊，

比如[you.com/chat](https://you.com/chat)

*****

####  schneehertz  
##### 48#       发表于 2023-2-22 12:31

模型如果不能自己训练那用chatgpt不就行了

*****

####  reficul  
##### 49#       发表于 2023-2-22 12:51

宅男的婆媳矛盾：你妈要用吸尘器，把你AI老婆服务器的电源拔了

*****

####  Cres  
##### 50#       发表于 2023-2-22 12:54

嫌贵可以集资租/买服务器炼出来共享呀

----发送自 [STAGE1 App for Android.](http://stage1.5j4m.com/?1.37)

*****

####  GMJ  
##### 51#       发表于 2023-2-22 13:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841926&amp;ptid=2120809" target="_blank">曾经很纯良 发表于 2023-2-22 08:43</a>

ddr3 32g 100一条，代价是老婆可能反应慢吞吞的？</blockquote>
同好：你老婆看上去不太聪明的样子，反应呆呆的。

*****

####  GMJ  
##### 52#       发表于 2023-2-22 13:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59842719&amp;ptid=2120809" target="_blank">乐明 发表于 2023-2-22 10:10</a>

至少比娶一个真老婆便宜，还没那么多破事。

虚拟陪伴型AI/机器人是未来人类的情感寄托了，特别现在 ...</blockquote>
赛博老婆会想收到数码蒸汽的喜加1吗？

*****

####  iluso  
##### 53#       发表于 2023-2-22 13:30

显卡2080TI改22G淘宝都没这个服务

内存200G家用4槽最多48*4=192G

*****

####  鸺鹠  
##### 54#       发表于 2023-2-22 13:31

这个帖子提到的是一个基于GPT-3语言模型的开源项目，它可以用来创建一个“AI老婆”。然而，这种使用AI技术的方法引发了一些伦理和法律问题，因为它涉及到人工智能与人类关系的本质性问题。对于这种使用AI技术的方式，建议仔细考虑其伦理和法律方面的问题，并在遵守相关法律法规的前提下使用。

*****

####  纸片有霞  
##### 55#       发表于 2023-2-22 13:40

 本帖最后由 纸片有霞 于 2023-2-22 13:43 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59843000&amp;ptid=2120809" target="_blank">flamel 发表于 2023-2-22 10:31</a>

虽说chatGPT 用的也是GPT3，但是自用的优化过的GPT3和这个肯定还是有区别的吧</blockquote>
要跑AI老婆肯定要自己喂数据的，对于AI老婆来说使用体验应该不会有很大的差距，毕竟又不需要它满足很多语言处理需求，当个电子复读机肯定还是可以的

而且某些人类老婆/老公的学习和交流能力可能还不如GPT3<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  夜空疾走  
##### 56#       发表于 2023-2-22 13:53

一个人喂一个AI，太手工业了，我要加入蜂群，我要当gymbag！

*****

####  Corruptwing  
##### 57#       发表于 2023-2-22 13:56

<blockquote>小李子大脸猫 发表于 2023-2-22 10:40
到时候你实体出轨，你AI老婆可以虚拟问责吗</blockquote>
都进化到ai老婆了还不想着解放被一夫一妻束缚的灵魂么

*****

####  勿徊哉  
##### 58#       发表于 2023-2-22 13:56

练好的老婆可以在github上开源吧
迫真共享公妻

*****

####  霧亥  
##### 59#       发表于 2023-2-22 13:59

<img src="https://static.saraba1st.com/image/smiley/face2017/047.png" referrerpolicy="no-referrer">如果以后升级到GPT5要不要鲨了现在的老婆

—— 来自 samsung SM-F9160, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  起名困难症  
##### 60#       发表于 2023-2-22 14:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59845203&amp;ptid=2120809" target="_blank">鸺鹠 发表于 2023-2-22 13:31</a>
这个帖子提到的是一个基于GPT-3语言模型的开源项目，它可以用来创建一个“AI老婆”。然而，这种使用AI技术 ...</blockquote>
怎么感觉真AI考虑得比泥潭死宅更实际一点<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  lwa190212  
##### 61#       发表于 2023-2-22 14:08

可能没几个人会真的点进去看，总之用不到200G内存，也可以用内置的管理器调整内存用量

这里用的是facebook的opt模型，gpt-3系列之后只有api没有整个模型参数开源，真部署gpt，要么用gpt2/gptj等等，要么用别人靠api训练出来的类gpt3模型


*****

####  冰寒之月  
##### 62#       发表于 2023-2-22 14:22

好像最小的6.7B模型只用15G显存就能跑了？

*****

####  Kanoya  
##### 63#       发表于 2023-2-22 14:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59845395&amp;ptid=2120809" target="_blank">夜空疾走 发表于 2023-2-22 13:53</a>
一个人喂一个AI，太手工业了，我要加入蜂群，我要当gymbag！</blockquote>
管人痴又双叒叕泄露了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  lwa190212  
##### 64#       发表于 2023-2-22 14:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59845699&amp;ptid=2120809" target="_blank">冰寒之月 发表于 2023-2-22 14:22</a>

好像最小的6.7B模型只用15G显存就能跑了？</blockquote>
175b也可以，它论文里有单NVIDIA T4上跑的对比，不过175b速度大概只有6.7b的1/35-1/40


*****

####  菲特妹  
##### 65#       发表于 2023-2-22 16:00

去算力平台租硬件练一个算不算逛窑子
卖矿卡来练算不算技师上岸


*****

####  相参降解社畜  
##### 66#       发表于 2023-2-22 16:48

其实纯捡垃圾的话，可能四五千元就能捡一套二手服务器来跑了，就是不知道最终效果如何....


*****

####  TKDNF  
##### 67#       发表于 2023-2-22 16:58

我想给我的ai老婆完整的一生

*****

####  noneoneoneone  
##### 68#       发表于 2023-2-22 16:59

再过几年会不会有专门帮忙炼制特定性格老婆的工作出现？

*****

####  lwa190212  
##### 69#       发表于 2023-2-22 17:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59847217&amp;ptid=2120809" target="_blank">相参降解社畜 发表于 2023-2-22 16:48</a>

其实纯捡垃圾的话，可能四五千元就能捡一套二手服务器来跑了，就是不知道最终效果如何.... ...</blockquote>
gpt甚至你能找到的开放模型虽然有很大学习潜力，但是你不再次微调训练就会表现得像个弱智，在真正开箱凑合即用的聊天机器人出来前，还是先别浪费这个钱了<img src="https://static.saraba1st.com/image/smiley/face2017/044.png" referrerpolicy="no-referrer">


*****

####  e8f9  
##### 70#       发表于 2023-2-22 19:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841392&amp;ptid=2120809" target="_blank">sunbeach 发表于 2023-2-22 03:23</a>
32g d4 一条400，很便宜了</blockquote>
一般家用主板只支持128g，200得服务器才行。
要是能降到100g就好了

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  kaildo  
##### 71#       发表于 2023-2-22 19:58

ai管人是不是要井喷了


*****

####  大暴死  
##### 72#       发表于 2023-2-22 21:55

<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">64g内存瑟瑟发抖，显卡本来准备今年等降价买4080的刚刚有16g

—— 来自 Xiaomi M2102K1C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  自旋  
##### 73#       发表于 2023-2-22 22:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841392&amp;ptid=2120809" target="_blank">sunbeach 发表于 2023-2-22 03:23</a>

32g d4 一条400，很便宜了</blockquote>
买服务器内存，32G的只要270了。

*****

####  docklabor  
##### 74#       发表于 2023-2-22 22:11

十年前8g，现在32g，再等10年也悬


*****

####  scorbian  
##### 75#       发表于 2023-2-22 22:17

租服务器养AI老婆不是相当于让老婆住别人家吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  rjzthq2022  
##### 76#       发表于 2023-2-22 22:27

快进到ai老婆读取银行卡密码，给自己加内存

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  AsukaAkashi  
##### 77#       发表于 2023-2-22 22:36

<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">银翼杀手2049是不是卖虚拟老婆来着？


*****

####  HURRYUP  
##### 78#       发表于 2023-2-22 23:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59841618&amp;ptid=2120809" target="_blank">勿徊哉 发表于 2023-02-22 07:23:27</a>
什么时候能看到用公司服务器养老婆，被发现删档炒鱿鱼后捅死公司老总的新闻 ...</blockquote>我要给他完整的一生。<img src="https://static.saraba1st.com/image/smiley/face2017/145.png" referrerpolicy="no-referrer">

[  -- 来自 有消息提醒的 Stage1官方 Android客户端](https://www.coolapk.com/apk/140634)


*****

####  混乱中立搅屎棍  
##### 79#       发表于 2023-2-22 23:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59852299&amp;ptid=2120809" target="_blank">docklabor 发表于 2023-2-22 22:11</a>

十年前8g，现在32g，再等10年也悬</blockquote>
要什么10年，就现在<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">去淘一套epyc2代+4条reg ecc 64G，不算显卡4500以内可以搞定，不过是一套家用13代i7+中高端z790的价格


*****

####  Jietf  
##### 80#       发表于 2023-2-23 00:01

插眼一下这200g太难了


*****

####  搞不好是洗衣粉  
##### 81#       发表于 2023-2-23 00:19

效果真的能好吗，别花几千块钱本地搭了一个大板插了8条内存后跑出来一个笨逼杠精


*****

####  remedios010000  
##### 82#       发表于 2023-2-23 04:09

就算是笨比也是自己炼出来的笨比<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">夫妻相不好吗

*****

####  sakura79  
##### 83#       发表于 2023-2-23 04:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59854060&amp;ptid=2120809" target="_blank">搞不好是洗衣粉 发表于 2023-2-23 00:19</a>
效果真的能好吗，别花几千块钱本地搭了一个大板插了8条内存后跑出来一个笨逼杠精 ...</blockquote>
这个笨逼杠精你还能改
老婆是笨逼杠精你能改？<img src="https://static.saraba1st.com/image/smiley/face2017/049.png" referrerpolicy="no-referrer">


*****

####  Ton  
##### 84#       发表于 2023-2-23 06:59

 本帖最后由 Ton 于 2023-2-23 07:00 编辑 

我听说GPT3不开源啊😯，可能是我火星了。
不过目前用openai的GPT3 API也不算贵。

没有chat GPT的那么多限制。


*****

####  巭孬嫑夯昆  
##### 85#       发表于 2023-2-23 07:33

冷冰冰的服务器有什么意思，搞快点，克洛伊、卡拉出来了再叫我<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  脑洞  
##### 86#       发表于 2023-2-23 07:42

养ChatGPT是不是相当于接盘了公交车


*****

####  perfaceNext  
##### 87#       发表于 2023-2-23 07:58

找一堆厕纸文学，去炼，能不能帮我去小说网站挣钱？


*****

####  leviathan  
##### 88#       发表于 2023-2-24 01:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59844428&amp;ptid=2120809" target="_blank">johnkamsar 发表于 2023-2-22 12:17</a>
那些嫌贵的，你们难道不想给自己老婆一个完整的一生吗？</blockquote>
不用完整的人生，能维持一个小时骚话状态就行了


*****

####  RinQ0326  
##### 89#       发表于 2023-2-24 01:34

 本帖最后由 RinQ0326 于 2023-2-24 01:37 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59845699&amp;ptid=2120809" target="_blank">冰寒之月 发表于 2023-2-22 14:22</a>

好像最小的6.7B模型只用15G显存就能跑了？</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/047.png" referrerpolicy="no-referrer">我的M40 24G有用了，要是有办法能放到游戏里面就好了，自己做个简单的场景和人物没事互动着玩。

*****

####  酸菜泡面  
##### 90#       发表于 2023-2-24 01:36

x99平台走起，辣鸡佬的春天


*****

####  eva02eva02  
##### 91#       发表于 2023-2-24 01:40

没有心跳的少女<img src="https://static.saraba1st.com/image/smiley/face2017/035.png" referrerpolicy="no-referrer">


*****

####  泥鳅化石  
##### 92#       发表于 2023-2-24 01:49

那么人形电脑天使心那种电脑啥时候可以上市？支持DIY吗？

—— 来自 HUAWEI OXF-AN10, Android 10上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

