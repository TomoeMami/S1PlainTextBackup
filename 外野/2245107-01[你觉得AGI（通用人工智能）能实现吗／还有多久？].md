
*****

####  danbreath  
##### 1#       楼主       发表于 2025-2-4 00:21

<input name="formhash" type="hidden" value="bbc93cef"/)

<strong>单选投票</strong> , 投票后结果可见, 共有 402 人参与投票

距结束还有:

<strong>

4 天11 小时1 分钟

</strong>

1.  我认为不可能实现

2.  今年以内

3.  3年以内

4.  3-5年

5.  5-10年

6.  10-20年

7.  20年以上

8.  我认为能实现，但我此生见不到了

9.  我是行外人，来打酱油的

 
提交

 本帖最后由 danbreath 于 2025-2-4 00:31 编辑 

agi的标准放低一点：能够稳定产出有一点用的可回收学术垃圾（并且几乎不需要人工筛选和纠错）

泥潭的超能力者们，我很好奇！

*****

####  gammatau  
##### 2#       发表于 2025-2-4 00:24

学术垃圾这个标准有点低了，30年前就有几个理科生瞎编了一堆狗屁不通的文科词投给文化评论期刊结果过了

*****

####  子虚乌有  
##### 3#       发表于 2025-2-4 00:30

民科，我觉得当ai有了一点点创造力之后就能飞速进化淘汰人类

*****

####  matthewsteel  
##### 4#       发表于 2025-2-4 00:43

像是midjourney之类的产品，现在还没有deepseek这样的，免费让大家直接用到最顶尖的模型的吧?

几年内，如果真的可以直接语音让手机助理帮你快速p一下照片。几年后也能如此容易的生成图片，那就真的太好了

*****

####  ryanghj  
##### 5#       发表于 2025-2-4 00:48

AGI的定义如果是“超过大多数人”而不是“超越所有人”，那AGI已经实现了

*****

####  jojog  
##### 6#       发表于 2025-2-4 00:55

我是觉得越来越远了

CoT也好agent也好最后离不开实时信息源检索

会上网搜资料总结这个迟早会因为aigc垃圾信息污染搜索引擎和各家服务防爬建墙导致搜不出东西

*****

####  联合利剑H  
##### 7#       发表于 2025-2-4 00:57

我认为可以实现，但时间上不会早于可控核聚变

*****

####  scp073  
##### 8#       发表于 2025-2-4 00:57

还是选了10-20年，回想上一个十年AI的发展，没理由不对下一个十年乐观<img src="https://static.saraba1st.com/image/smiley/face2017/032.png" referrerpolicy="no-referrer">

*****

####  小田切宁宁  
##### 9#       发表于 2025-2-4 00:58

我觉得实现不了 
人类连人类自己为什么会思考都研究不明白
还企图教会代码思考🤔

*****

####  希望之花  
##### 10#       发表于 2025-2-4 01:03

目前看着像是一个赛博草台，外表光鲜亮丽但是能找到踢爆它的角度

比如泥潭这贴https://www.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2236332

----发送自 [STAGE1 App for Android.](http://stage1.5j4m.com/?1.44)

*****

####  moekyo  
##### 11#       发表于 2025-2-4 01:05

其实这个投票的点是啥

*****

####  windrarara  
##### 12#       发表于 2025-2-4 01:12

个人感觉光靠文字是实现不了AGI的，目前的大模型算法本质还是概率，最好还得加上足够的视觉等其他感官的训练，人脑很大一块区域的组织都跟视觉相关

*****

####  烦死了  
##### 13#       发表于 2025-2-4 01:16

能实现，但是肯定不是大语言模型

*****

####  blackll7  
##### 14#       发表于 2025-2-4 01:36

<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">如果一个事物的存在只是其外形，文字表述，逻辑结构的话，那么transformer模型当然能成为agi。但是事物的存在根本不是那样的，历史性与可解释性都没有的这套搞法只能做到形似啊。
<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">讲简单点就是，你有一块橡皮泥，你能把他捏成飞机骨架的样子，然后你觉得橡皮泥很快可以飞了。

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  地刺  
##### 15#       发表于 2025-2-4 01:36

 本帖最后由 地刺 于 2025-2-4 01:38 编辑 

按照现在的速率发展 其实就是未来20年里面了,首先现在的ds以及不是llm的根据喂料猜词的模式了 他是加入了自推理 不需要物料输入也能产出 就像阿法狗是学人类棋谱但阿发zero是自训练

然后可控核聚变科技 今年已经能维持18分钟 这在物理学上已经是成功了的实验了 现在的问题只是怎么实用化 算是进入落地阶段了,一旦只要有能量盈余 铺开只是时间问题  而迭代中的ai可以解决人类需要堆算力解决的问题-比如材料学

接着就是左脚踩右脚了,无限的能源提供给无限的智力, 人类剩下的事就是怎么打发时间了<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

*****

####  十六夜鬼月  
##### 16#       发表于 2025-2-4 02:26

我始终坚持一点，那就是人工智能从一开始方向就错了。

真正人工智能是建立在模拟信号处理的基础上的。

使用数字信号处理一开始的初衷就是为了精确，这恰恰是与智慧生物处理信息特征相反，因为人的底层思维一点也不精确。

*****

####  ts1abaras  
##### 17#       发表于 2025-2-4 02:56

目前还不是概率模型？感觉方向就错了

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  RandomDictator  
##### 18#       发表于 2025-2-4 03:24

现在agi根本就没有一个精确且被广泛接受的定义，没法定义的事情怎么投嘛。以前经常提的图灵测试被llm解决之后就没有新的定义了

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  Ollie  
##### 19#       发表于 2025-2-4 04:24

记得某个脱口秀老头在节目上说，地球需要人类就是来造塑料

现在感觉人类存在的意义可能是造出agi、强人工智能之类的

*****

####  strider_oy  
##### 20#       发表于 2025-2-4 04:43

现在的ai不就是中文屋么？取决于你对ai的定义如何。

— from [S1 Next Goose](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  星花  
##### 21#       发表于 2025-2-4 06:33

现在不是要改成，未来累计能有1000亿利润的就算AGI了。<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  HOIHOISAN  
##### 22#       发表于 2025-2-4 06:42

10-20年

我外行瞎猜的

*****

####  处男老司机  
##### 23#       发表于 2025-2-4 06:43

<blockquote>十六夜鬼月 发表于 2025-2-4 02:26
我始终坚持一点，那就是人工智能从一开始方向就错了。

真正人工智能是建立在模拟信号处理的基础上的。

使用 ...</blockquote>
然而神经元的信号处理模式就是数字信号的脉冲式

*****

####  休達  
##### 24#       发表于 2025-2-4 06:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67342944&amp;ptid=2245107" target="_blank">blackll7 发表于 2025-2-4 01:36</a>
如果一个事物的存在只是其外形，文字表述，逻辑结构的话，那么transformer模型当然能成为agi。但是事物的存 ...</blockquote>
首先你举例的外形和文字表述的概念就不是一个东西，橡皮泥捏的确实只是抄了外观，但是文字表述一个概念这已经是抽象思维的范畴了。

agi的重点是通过文字模型构建的概念和概念的关系，这和我们认识到的人类思维是一样的，就是把外部具体的信息抽象成概念并且通过逻辑将概念和概念联系起来。

*****

####  星花  
##### 25#       发表于 2025-2-4 06:56

文字无法描述世界，几千年前佛教就知道了。<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  mimighost  
##### 26#       发表于 2025-2-4 07:19

3年肯定够了

*****

####  dulun59  
##### 27#       发表于 2025-2-4 07:59

连一个细胞里同时发生所有的化学/物理反应都不能看清的人类 却想要创造出通用“智慧人”

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  鲜血秋叶  
##### 28#       发表于 2025-2-4 08:11

完全不人工干预的话，感觉最后肯定会变成不可回收的胡言乱语

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  starash  
##### 29#       发表于 2025-2-4 08:23

实现肯定是能实现的，人也不过是蛋白质搭建的机械罢了。
几年…. 二十？

*****

####  krizalid9999  
##### 30#       发表于 2025-2-4 08:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67343304&amp;ptid=2245107" target="_blank">dulun59 发表于 2025-2-4 07:59</a>
连一个细胞里同时发生所有的化学/物理反应都不能看清的人类 却想要创造出通用“智慧人”

论坛助手,iPhone ...</blockquote>
人类钻木取火、熔铁炼钢、品草制药的时候，一样不知道这些技术的原理是啥呀。
不知道原理就不能干的话，人类压根发展不到能看懂原理的那一天。

—— 来自 HUAWEI ALN-AL00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  凉奶仙  
##### 31#       发表于 2025-2-4 09:05

你猜为啥相关人士都默契地把学名“大语言模型”里面的“语言”藏起来

*****

####  zerona  
##### 32#       发表于 2025-2-4 09:55

美国搞出来的，就别琢磨了。现在出个开源的等效品这急的。

*****

####  naclken.  
##### 33#       发表于 2025-2-4 10:14

能实现。

至于多久，我要是能预知未来还在这儿混？

*****

####  dongzi81  
##### 34#       发表于 2025-2-4 10:53

“神”造人，人再造“神”

逻辑闭环，完美

*****

####  循此苦旅  
##### 35#       发表于 2025-2-4 11:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67343118&amp;ptid=2245107" target="_blank">RandomDictator 发表于 2025-2-4 03:24</a>

现在agi根本就没有一个精确且被广泛接受的定义，没法定义的事情怎么投嘛。以前经常提的图灵测试被llm解决之 ...</blockquote>
从来都不只有图灵测试一个定义啊，也还有完全版图灵测试

*****

####  十六夜鬼月  
##### 36#       发表于 2025-2-4 12:16

 本帖最后由 十六夜鬼月 于 2025-2-4 12:45 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67343224&amp;ptid=2245107" target="_blank">处男老司机 发表于 2025-2-4 06:43</a>

然而神经元的信号处理模式就是数字信号的脉冲式</blockquote>
脉冲式≠数字信号。说再直白些，不是不连续的，间断的信号就一定是数字信号。

数字信号本质是经过调质后的有指定数学规律的模拟信号，而接收端对于信号的解调，也是按照这层数学规律进行解调。

再具体点，现代半导体电路，对于信号的认知就是两种状态：通，闭。对应的就是电压的高（于标准值），低（于标准值）。除此之外不会有第三种状态，此之为二进制。而神经元在传递电信号时，0.1v是一种状态，0.11v也是一种状态，0.111v仍然是一种状态。你不能说这种小数点后面的1的电压没有用，因为接收端同样会因为这点电压差而导致电化学反应的变化。

*****

####  aallqqppaa  
##### 37#       发表于 2025-2-4 12:30

agi一定是存在的，因为agi是拿人脑当标准的，实在不行把每个神经元都扫描以后存储下来，在模拟机上跑也是agi
但是具体实现上，目前对于人工智能的输入/输出很大程度上是建立在文字和视频/声音上的，可能ai会很擅长写文章/画图/做视频，但是对于现实世界要如何反应还是一个要参加的课题

—— 来自 HUAWEI ALT-AL10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  鸳鸳相抱  
##### 38#       发表于 2025-2-4 12:41

可以通过RL实现自学的大模型，我觉得已经是AGI了，剩下的就是微调一个底子比较好的原初模型，通过RL生成更多语料进一步成长而已

*****

####  IIIIIlllllIIIII  
##### 39#       发表于 2025-2-4 13:01

神谕机不存在 

curse of dimensionality 没法解决 agi就永远还有50年

— from [S1 Next Goose](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  nightrap  
##### 40#       发表于 2025-2-4 13:07

事实上，按我的预测AGI的研究是属于无底洞的性质，随着研究的推进人类会发现存在更多的方向和更多的可能性，是人类永远都研究不完的东西。

现在的AI说实在的，更多是靠现有样本的堆砌组合来得出想要的东西，跟真正意义上的AGI是连边都没摸到的，总有一天人类会发现这种方式的瓶颈和限制。因为按我的预测，真正的AGI不能受现实的语言文字限制，这点当前就差得老远。

当然因为现在的这种快节奏生活，人的多数需求就是模式化的，现有的AI确实已经足够满足一定的需求了，导致现在很多人会有当前的AI已经够用了的感觉。一旦人类的社会构成和生活方式发生改变，现有AI发展的不足和局限就会显露出来。


*****

####  nightrap  
##### 41#       发表于 2025-2-4 13:11

另外，我还预测，人类是有办法避免AI奴役人类的，要点就是未来发展AI时必须排除这些人类的恶性：私心、贪欲、控制欲、野心等等。

*****

####  吴怀在  
##### 42#       发表于 2025-2-4 13:24

ai奴役人类不是已经有了，困在算法里的外卖员。

杀人的不是枪，是拿枪的人。奴役人的不是ai，是控制ai的人。

主楼定义的agi有一点希望。至于能主动造反、奴役人类的ai，唯物主义就压根不承认能在图灵机上实现。

什么ai排除人类恶性，这种说法太唯心主义了


*****

####  红炉灰  
##### 43#       发表于 2025-2-4 14:03

很难很难
瞎编问题目前来看一直没能解决

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha


*****

####  黑哥啥时改密码  
##### 44#       发表于 2025-2-4 14:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67345021&amp;ptid=2245107" target="_blank">红炉灰 发表于 2025-2-4 14:03</a>

很难很难

瞎编问题目前来看一直没能解决</blockquote>
其实现在的ai本质上其实就是一个搜索工具

只不过搜索出来的结果 经过了模型的调试


*****

####  Anonymous_User  
##### 45#       发表于 2025-2-4 14:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67343228&amp;ptid=2245107" target="_blank">休達 发表于 2025-2-4 06:46</a>

首先你举例的外形和文字表述的概念就不是一个东西，橡皮泥捏的确实只是抄了外观，但是文字表述一个概念这 ...</blockquote>
思考不需要概念，否则人既不可能发明也不可能学会语言


*****

####  鸳鸳相抱  
##### 46#       发表于 2025-2-4 14:59

 本帖最后由 鸳鸳相抱 于 2025-2-4 15:01 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67344734&amp;ptid=2245107" target="_blank">nightrap 发表于 2025-2-4 13:07</a>

事实上，按我的预测AGI的研究是属于无底洞的性质，随着研究的推进人类会发现存在更多的方向和更多的可能性 ...</blockquote>
AGI不是神谕机，不是无所不能，AGI初期可能智商只有80，但是它可能达到了智能的门槛

现在最关键的是，什么叫智能体并没有明确定义，比如我觉得能够自学、智商达到80的智能体就能称之为智能了，而你显然不是这样认知的，还有很多人认为需要有哲学意义上的“自我”才能称之为智能，这个问题先讨论清楚了，主题的投票才有意义


*****

####  weary10  
##### 47#       发表于 2025-2-4 17:08

人工智能到底如何做到触类旁通？


*****

####  LilithMardin  
##### 48#       发表于 2025-2-4 17:30

越快越好嘛，在我死前让我机械飞升或者肉人突变都行，努努力争取活久点。

—— 来自 HUAWEI ALN-AL80, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2


*****

####  remedios010000  
##### 49#       发表于 2025-2-4 18:27

碳基生命没有资格指点硅基智慧生物该怎么进化吧<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">要我说还是得等人人都会编程，有便携天河二算力，量变积累够了才能有民科搓出来

----发送自 [STAGE1 App for Android.](http://stage1.5j4m.com/?1.44)


*****

####  魔灵高达  
##### 50#       发表于 2025-2-4 18:42

现在有那么多特化方向的AI工具，专门搜索的，专门写代码的，专门文生图、视频、音乐的、专门写大纲、专门写小段落的描写、专门推演剧情走向blabla，如果出一个能够完美统合这些AI工具的统合AI，是不是就已经能达成全领域超越百分之95以上人类的AI了呢？


*****

####  ellioe  
##### 51#       发表于 2025-2-4 20:26

什么时候能自迭代了再来说agi吧<img src="https://static.saraba1st.com/image/smiley/face2017/033.png" referrerpolicy="no-referrer">
我作为脆弱的碳基生物难以想象硅基生物该如何认识世界改造世界


*****

####  小处不可随便  
##### 52#       发表于 2025-2-4 20:55

 本帖最后由 小处不可随便 于 2025-2-4 21:00 编辑 

agi应该具有遗传和变异功能，剔除训练集随机性的影响，目前还没足够的算力支撑这些


*****

####  zoex  
##### 53#       发表于 2025-2-4 23:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67346109&amp;ptid=2245107" target="_blank">weary10 发表于 2025-2-4 17:08</a>

人工智能到底如何做到触类旁通？</blockquote>
知识的近似规律以不可解释的方式作为参数存在大模型里了。说实在，很难说人脑不也是这样的或者类似的。而物理定律本质也是基于数学大厦的近似规律，从牛顿力学到广义相对论，置信度的进步。

激素调节、条件反射这些功能也很像RL

人类比较难以复现果然还是自我意识，按皇帝新脑里的猜想，它是某种和量子力学有关的机制


*****

####  cleaner  
##### 54#       发表于 2025-2-4 23:42

与其说，AGI还有多久出现，倒不如问：真的需要AGI吗

*****

####  陈乔恩  
##### 55#       发表于 2025-2-4 23:44

我觉得肯定能实现，但是实现的那个agi和你想的那个估计差很远

—— 来自 HUAWEI TAH-AN00m, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.2.2.1


*****

####  冰寒之月  
##### 56#       发表于 2025-2-5 00:28

生物的神经网络是浅层+超多链接的形式  人脑神经元数量虽然只有500-1000亿(10^12)但链接却有10^15-16个突触

从单纯堆料角度目前最强大模型还得扩增1000-10000倍 规模才能追平人脑的突触部分 神经元本身可能还有复杂的参数需要模拟

而且现在语言大模型AI基本都是深层神经网络+有限链接 本质和生物思考方式就不一样 这种结构差异是否会导致智力发展局限在一定水平也没人知道

所以我不看好近期AGI能产生 

但任务专用AI很多已经超越人类了 只要在每一个特定领域做出个足够强大实用的专用AI  数量够多 那其实有没有AGI也无所谓了


*****

####  循此苦旅  
##### 57#       发表于 2025-2-5 00:55

<blockquote>cleaner 发表于 2025-2-4 23:42
与其说，AGI还有多久出现，倒不如问：真的需要AGI吗</blockquote>
想实现生产力极大就要有强AI。


*****

####  alixsander  
##### 58#       发表于 2025-2-5 01:56

没什么从业者看来，3-5年属于非常保守了


*****

####  橙冰  
##### 59#       发表于 2025-2-5 03:26

取决于能源，很多高阶科技都要在可控核聚变的基础上才能实现


*****

####  阿克萌德  
##### 60#       发表于 2025-2-5 09:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67348443&amp;ptid=2245107" target="_blank">冰寒之月 发表于 2025-2-5 00:28</a>

生物的神经网络是浅层+超多链接的形式  人脑神经元数量虽然只有500-1000亿(10^12)但链接却有10^15-16个突触 ...</blockquote>
再做一个统合这些专业AI的管理/决策型AI。


*****

####  卷饼大侠  
##### 61#       发表于 2025-2-5 10:55

下一个阶段在我看来肯定会是脑机接口，混合人脑和ai，具备两者的优势才是下一代技术趋势，agi还在遥远的地方


*****

####  cfeng123  
##### 62#       发表于 2025-2-5 11:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67343046&amp;ptid=2245107" target="_blank">十六夜鬼月 发表于 2025-2-4 02:26</a>

我始终坚持一点，那就是人工智能从一开始方向就错了。

真正人工智能是建立在模拟信号处理的基础上的。

使用 ...</blockquote>
数字信号也是可以添加干扰的，模拟信号只能粗略模拟数字信号，但数字信号是可以精确模拟模拟信号的（在你想要的精度下）


*****

####  cfeng123  
##### 63#       发表于 2025-2-5 11:22

感觉目前的AI是“按一定的规则去发挥”，发挥可能是筛选，可能是创造，在规则明晰的情况下训练出来的AI已经比人类更适应这种专属的工作内容了

随着这个规则越来越模糊，必然就到了AGI的零界点了

人类现在在做的更多就是拆除边界（来看看是否有意想不到的成果）和添加边界（消除一些不符合预期的导向）


*****

####  深蓝巫妖  
##### 64#       发表于 2025-2-5 11:36

我就希望两三年内搞出个人可用的小型电脑人工智能，可以帮助我整理电脑里的电影和游戏。现有的软件感觉还是要门槛来折腾的，太麻烦了。


*****

####  mimighost  
##### 65#       发表于 2025-2-5 12:18

openai的deep research已经是agi的雏形了，在拼凑年报信息上面和一般的文员有任何区别么？没有

写综述至少有博士生的水平


*****

####  ksana002  
##### 66#       发表于 2025-2-5 13:08

有一个问题，人类永远无法想象出根本不存在的事物，对agi的想象都是以人类思想行为作为参照，如果agi真的变成一种生命形式，这种生命的形态和特征恐怕是完全超出人的可能的任何想象之外，索拉里斯星在这方面是一个很好的思考

—— 来自 Google Pixel 6 Pro, Android 15上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.0.4-alpha


*****

####  十六夜鬼月  
##### 67#       发表于 2025-2-5 13:39

<blockquote>cfeng123 发表于 2025-2-5 11:18
数字信号也是可以添加干扰的，模拟信号只能粗略模拟数字信号，但数字信号是可以精确模拟模拟信号的（在你 ...</blockquote>
问题不是传递而是处理。传递过程再近似模拟，接收端接收后肯定首先要把它解调成数字信号，否则就处理不了。就像半导体处理不了第三种电压情况一样，这是物理特征决定的。


*****

####  MINKE  
##### 68#       发表于 2025-2-5 14:13

就目前transformer架构的llm而言结构机制还是太简单了，对生物学机制的理解停留在隐喻层面，缺乏对神经认知脑科学研究的进一步使用，例如明显的记忆分类机制、大脑功能分区机制等等都缺乏深入的生物启发式的研究实现。

LLM发展后就把传统NLP的语言学家丢到一边，跨学科协作似乎只有低潮才出现，还是目前方向热钱太多发展的太顺了


*****

####  懒懒的冬夜  
##### 69#       发表于 2025-2-5 14:37

AI和机器人配合出无人化工厂生产力能爆发式增长啊，能抵得过血汗工厂的成本，那木有发展出来的国家路就不好走了

*****

####  treexper  
##### 70#       发表于 2025-2-5 14:42

关键是，AGI是啥？先等搞哲学的老登们战完，搞计算机的再上吧。


*****

####  哈哈一笑  
##### 71#       发表于 2025-2-5 16:43

目前依靠大数据这种方式的人工智能肯定做不到 AGI


*****

####  a4ac7  
##### 72#       发表于 2025-2-5 17:18

 本帖最后由 a4ac7 于 2025-2-5 17:19 编辑 
<blockquote>视频通过反复拼写、拆分“strawberry”单词，数其中字母“R”的个数，最终确认答案为3个。
评论区主要讨论人工智能在解答字母相关问题时犯难的原因，有人认为与词元有关，有人觉得是受其他模型影响，还提及人工智能自我怀疑、深度推理等特点，以及大脑与人工智能处理方式的相似之处，同时也提到人工智能回答问题的特点和使用感受。</blockquote><blockquote>数据库里的答案是2，但是它自己分析出是3个，然后开始左右手互搏，最终选择相信自己的分析。</blockquote>
【外国人看DeepSeek解谜：“strawberry”里究竟几个“R”？ 歪果仁评论弹幕-哔哩哔哩】 [https://b23.tv/JQBBviv](https://b23.tv/JQBBviv)

我感觉agi是可能的

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  Kiriz  
##### 73#       发表于 2025-2-5 21:19

克隆人是否属于人工智能？


*****

####  dodolee  
##### 74#       发表于 2025-2-6 00:33

感觉很多人都将人类智能认定为智能的最高形式了，认为AI必须要按照人类智能的形式发展，但是单从生理上看，人类身体在漫长的进化过程中已经产生了很多BUG了，人类大脑产生的智能也未必就是最高效的实现方式吧，AI完全有可能少走很多弯路，直接通过更高效的方式实现超越人类的智能。

另外很多人似乎觉得AI一旦超越人类，就会奴役人类，但看人类自身，也只是在生产力水平还比较低的时候短暂奴役了其他低等动物吧，我觉得人类最终必然会创造出超级智能，这些超级智能必然会抛弃人类和地球飞向宇宙，人类这种智力水平和身体构造完全没有奴役的必要。


*****

####  Vacuolar  
##### 75#       发表于 2025-2-6 08:43

https://view.inews.qq.com/k/20241216A08ASP00?web_channel=wap&amp;openApp=false

虽然是谷歌人说的观点，但是我觉得他讲的没错


*****

####  bcxzzz  
##### 76#       发表于 2025-2-6 13:20

应该是可以实现，这样就出现了硅基生命，而且它的生命有赖于通电。万一它想解决电源受人类控制的问题，那就是天网战争。

—— 来自 HUAWEI LIO-AL00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  bcxzzz  
##### 77#       发表于 2025-2-6 13:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67351498&amp;ptid=2245107" target="_blank">MINKE 发表于 2025-2-5 14:13</a>
就目前transformer架构的llm而言结构机制还是太简单了，对生物学机制的理解停留在隐喻层面，缺乏对神经认知 ...</blockquote>
钱老的预言没错吧，果然21世纪是脑子研究大发展的世纪。只不过不是以他猜想的特异功能那种方式。

—— 来自 HUAWEI LIO-AL00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  高妹控  
##### 78#       发表于 2025-2-6 13:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67355313&amp;ptid=2245107" target="_blank">dodolee 发表于 2025-2-6 00:33</a>
感觉很多人都将人类智能认定为智能的最高形式了，认为AI必须要按照人类智能的形式发展，但是单从生理上看， ...</blockquote>
人类智能就是智能的最高形式啊，不然你搞两台装了deepseek的超算扔荒岛上，只提供电力和网线，看看它能不能迭代出赛博生命<img src="https://static.saraba1st.com/image/smiley/face2017/053.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  马猴肥宅  
##### 79#       发表于 2025-2-7 07:50

现在搭建ai知识库连知识库里有图片、pdf图纸、文字混合的信息都做不到，至少要能做到这一点才能基本可用。


*****

####  liy30dlys  
##### 80#       发表于 2025-2-8 11:59

看你怎么理解agi了

现在的水平不就是在大部分不是你专业的领域能帮到你，但是在你专业领域还是会露馅吗


*****

####  流缨  
##### 81#       发表于 2025-2-8 12:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67364839&amp;ptid=2245107" target="_blank">马猴肥宅 发表于 2025-2-7 07:50</a>

现在搭建ai知识库连知识库里有图片、pdf图纸、文字混合的信息都做不到，至少要能做到这一点才能基本可用。 ...</blockquote>
这一点其实是有技术路线的，部分实现你肯定都接触过，比如微信聊天记录里就能搜索到截图或者是拍照中的文字

目前AI知识库还没有一个整合方案，主要是流水线上靠后的RAG部分还比较新，使用的嵌入式模型的开发力度和受关注程度也完全不能比，而且增量更新如何实现也没有什么探索

OCR部分本身其实没啥难度，难得是如何持续维护更新

更何况就算光文字内容，现在能本地部署的那些玩意儿基本就是刚刚做到能搜的到，但不保证搜全了，这就使得实用性大打折扣，还得等技术演进


*****

####  马猴肥宅  
##### 82#       发表于 2025-2-8 13:25

<blockquote>流缨 发表于 2025-2-8 12:07
这一点其实是有技术路线的，部分实现你肯定都接触过，比如微信聊天记录里就能搜索到截图或者是拍照中的文 ...</blockquote>
是的，我发现嵌入式模型也涉及到对资料中文字内容的拆分、分析、解读、转化，并且挺影响输出效果的。感觉就差最后几步，很期待有完善的成果哈哈哈。反过来想，等这种模型完善了估计就有完整的商业化产品了，产品的成本和算力需求可能又不是个人用户能承担的。


*****

####  流缨  
##### 83#       发表于 2025-2-8 14:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67374487&amp;ptid=2245107" target="_blank">马猴肥宅 发表于 2025-2-8 13:25</a>

是的，我发现嵌入式模型也涉及到对资料中文字内容的拆分、分析、解读、转化，并且挺影响输出效果的。感觉 ...</blockquote>
这块其实不尽然，RAG部分可以放在用户本地，生成部分用API就可以解决，同时还有了一定安全性

因为嵌入式模型普遍参数量都是比较小的，消费级显卡就能搞定，真正的难题在于如何保证搜索的部分完整且有效，还要保证返回大模型的上下文token限制，目前都还没看到有啥办法

其实本质还是算力问题，如果有新的突破，算力不再是桎梏，那做个agent实际上也能当简易的知识库用了，需要额外提供知识的时候手动喂都行


*****

####  squallx  
##### 84#       发表于 2025-2-8 18:53

怎么泥潭也这么多分不清AGI ASI的

能达到常规人类水准的就算AGI了 远超人类水准的那是ASI 还早


*****

####  ushas  
##### 85#       发表于 2025-2-9 10:33

有用的垃圾……人类产出还不够多么<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">

