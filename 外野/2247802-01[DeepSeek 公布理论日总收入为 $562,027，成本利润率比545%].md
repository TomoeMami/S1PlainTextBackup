
*****

####  小野賢章  
##### 1#       楼主       发表于 2025-3-1 12:38

DeepSeek 的开源周今天的 One More Thing

[https://zhuanlan.zhihu.com/p/27181462601](https://zhuanlan.zhihu.com/p/27181462601)

<strong>线上系统的实际统计数据</strong>

<img src="https://img.saraba1st.com/forum/202503/01/123808mxxhhup77ynnnp7z.jpg" referrerpolicy="no-referrer">

<strong>v2-1f28a859205fbabda1169ce343700cdd_1440w.jpg</strong> (32.73 KB, 下载次数: 0)

下载附件

2025-3-1 12:38 上传

DeepSeek V3 和 R1 的所有服务均使用 H800 GPU，使用和训练一致的精度，即矩阵计算和 dispatch 传输采用和训练一致的 FP8 格式，core-attention 计算和 combine 传输采用和训练一致的 BF16，最大程度保证了服务效果。

另外，由于白天的服务负荷高，晚上的服务负荷低，因此我们实现了一套机制，在白天负荷高的时候，用所有节点部署推理服务。晚上负荷低的时候，减少推理节点，以用来做研究和训练。在最近的 24 小时里（北京时间 2025/02/27 12:00 至 2025/02/28 12:00），DeepSeek V3 和 R1 推理服务占用节点总和，峰值占用为 278 个节点，平均占用 226.75 个节点（每个节点为 8 个 H800 GPU）。假定 GPU 租赁成本为 2 美金/小时，总成本为 $87,072/天。

<strong>在 24 小时统计时段内，DeepSeek V3 和 R1：</strong>

输入 token 总数为 608B，其中 342B tokens（56.3%）命中 KVCache 硬盘缓存。输出 token 总数为 168B。平均输出速率为 20~22 tps，平均每输出一个 token 的 KVCache 长度是 4989。平均每台 H800 的吞吐量为：对于 prefill 任务，输入吞吐约 73.7k tokens/s（含缓存命中）；对于 decode 任务，输出吞吐约 14.8k tokens/s。以上统计包括了网页、APP 和 API 的所有负载。如果所有 tokens 全部按照 DeepSeek R1 的定价[1]计算，理论上一天的总收入为 $562,027，成本利润率 545%。

 <blockquote>当然我们实际上没有这么多收入，因为 V3 的定价更低，同时收费服务只占了一部分，另外夜间还会有折扣。</blockquote>

<img src="https://img.saraba1st.com/forum/202503/01/123630qu464w4a71gdnq3a.jpg" referrerpolicy="no-referrer">

<strong>v2-26f069dbfd803c157a23ea7a97d717f2_r.jpg</strong> (63.37 KB, 下载次数: 0)

下载附件

2025-3-1 12:36 上传

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 斯卡文分则能成| + 1|好评加鹅|

查看全部评分

*****

####  霜叶舞影  
##### 2#       发表于 2025-3-1 12:39

他甚至想教会你怎么运营

*****

####  ww-tsl  
##### 3#       发表于 2025-3-1 12:40

要是把写皇叔解禁哪怕只是放宽限制，就算不能加个0至少也能X5。

*****

####  卖哥  
##### 4#       发表于 2025-3-1 12:41

这个其实是给云服务商看的

5天开源的加速buff打上，满血R1装上，开始印钱！

*****

####  wly5556  
##### 5#       发表于 2025-3-1 12:42

哈哈，之前经常看到各种ds api定价不可能盈利的分析，这下官方下场了

*****

####  小野賢章  
##### 6#         楼主| 发表于 2025-3-1 12:43

顶级做空报告<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  吴怀在  
##### 7#       发表于 2025-3-1 12:44

我要多模态<img src="https://static.saraba1st.com/image/smiley/face2017/126.png" referrerpolicy="no-referrer">

*****

####  UNICORN00  
##### 8#       发表于 2025-3-1 12:46

这就是量化出身吗，没有几十个的利润怕是看不上<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  naclken.  
##### 9#       发表于 2025-3-1 12:54

……我还以为是用它搞量化投资的收益率<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

*****

####  雪城飞鸟  
##### 10#       发表于 2025-3-1 12:56

所以现在有什么流畅点的满血ds渠道推荐么

*****

####  ykent  
##### 11#       发表于 2025-3-1 12:56

这成本只是硬件成本啊，没算上人力成本、研发摊销，别忘了还有专员的费用。
怎么可能不亏。

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  卖哥  
##### 12#       发表于 2025-3-1 13:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549132&amp;ptid=2247802" target="_blank">ykent 发表于 2025-3-1 12:56</a>

这成本只是硬件成本啊，没算上人力成本、研发摊销，别忘了还有专员的费用。

怎么可能不亏。</blockquote>
这个账对Deepseek来说是不准确的，但是对云服务商来说就是很准确了，维护本来就在租金里了，研发已经直接喂饭了。

*****

####  harry3  
##### 13#       发表于 2025-3-1 13:07

deepseek的传达做的真是好，反观其他友商的官方账号全是一些没啥信息量的弱智推广营销稿

*****

####  雷囧羊  
##### 14#       发表于 2025-3-1 13:08

这明显冲着gpt4.5百万token收费150刀来的<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  小野賢章  
##### 15#         楼主| 发表于 2025-3-1 13:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549198&amp;ptid=2247802" target="_blank">雷囧羊 发表于 2025-3-1 13:08</a>
 这明显冲着gpt4.5百万token收费150刀来的</blockquote>
潞晨科技创始人尤洋在微博和朋友圈表示，短期内，中国的MaaS模式可能是最差的商业模式，大厂相互卷低价和免费，满血版DeepSeek R1每百万token（输出）只收16元。如果每日输出1000亿token，基于DeepSeek的服务每月的机器成本是4.5亿元，亏损4亿元；用AMD芯片月收入4500万元，月机器成本2.7亿元，这意味着亏损也超过2亿元。

“用户越多，亏损越多。”尤洋表示。

*****

####  colice  
##### 16#       发表于 2025-3-1 13:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549243&amp;ptid=2247802" target="_blank">小野賢章 发表于 2025-3-1 13:16</a>
潞晨科技创始人尤洋在微博和朋友圈表示，短期内，中国的MaaS模式可能是最差的商业模式，大厂相互卷低价和 ...</blockquote>
“就该大家一起涨价收割韭菜。”<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  Azcarlo  
##### 17#       发表于 2025-3-1 13:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549243&amp;ptid=2247802" target="_blank">小野賢章 发表于 2025-3-1 13:16</a>

潞晨科技创始人尤洋在微博和朋友圈表示，短期内，中国的MaaS模式可能是最差的商业模式，大厂相互卷低价和 ...</blockquote>
尤洋这下脸都被打肿了，DeepSeek甚至知乎上开了个账号专门发了一遍。

<img src="https://img.saraba1st.com/forum/202503/01/132502v3vvfvkdgmhzqhgz.png" referrerpolicy="no-referrer">

<strong>Snipaste_2025-03-01_13-24-26.png</strong> (258.35 KB, 下载次数: 0)

下载附件

2025-3-1 13:25 上传

<img src="https://img.saraba1st.com/forum/202503/01/132506u7oz9g6y6gd9cw00.png" referrerpolicy="no-referrer">

<strong>Snipaste_2025-03-01_13-24-01.png</strong> (182.23 KB, 下载次数: 0)

下载附件

2025-3-1 13:25 上传

尤教授嘴是真的硬，兄啊咱技不如人就不能收着点吗？真要弄到被别人发现是纯菜？

*****

####  Nanachi  
##### 18#       发表于 2025-3-1 13:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549314&amp;ptid=2247802" target="_blank">Azcarlo 发表于 2025-3-1 13:27</a>
尤洋这下脸都被打肿了，DeepSeek甚至知乎上开了个账号专门发了一遍。</blockquote>
和瑞幸自称咖啡豆成本3元/杯一样搞笑

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  ryanghj  
##### 19#       发表于 2025-3-1 13:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549132&amp;ptid=2247802" target="_blank">ykent 发表于 2025-3-1 12:56</a>

这成本只是硬件成本啊，没算上人力成本、研发摊销，别忘了还有专员的费用。

怎么可能不亏。</blockquote>
用自有服务器部署，理论上运营成本只有电费

*****

####  2017.05.04  
##### 20#       发表于 2025-3-1 13:58

开发不起可以部署DSR1印钱<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

——来自 [S1 Orange](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2244111) 1.2.5

*****

####  流浪的翅膀  
##### 21#       发表于 2025-3-1 13:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549478&amp;ptid=2247802" target="_blank">ryanghj 发表于 2025-3-1 13:50</a>
用自有服务器部署，理论上运营成本只有电费</blockquote>
设备折旧要算的

*****

####  卖哥  
##### 22#       发表于 2025-3-1 14:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549525&amp;ptid=2247802" target="_blank">流浪的翅膀 发表于 2025-3-1 13:58</a>

设备折旧要算的</blockquote>
成本没有算电费、维护人工费、折旧费，而是购买对应云服务的市场价租金。

*****

####  你被巨魔了  
##### 23#       发表于 2025-3-1 14:04

<img src="https://static.saraba1st.com/image/smiley/face2017/053.png" referrerpolicy="no-referrer">这么说也能理解，就gpt4.5那收费有几个能不眼馋

*****

####  orecheng  
##### 24#       发表于 2025-3-1 14:05

辛辛苦苦赚服务费哪有金融市场操作一下赚得多

*****

####  脸宽  
##### 25#       发表于 2025-3-1 14:07

现在官网 api 咋样了，想在官网花钱

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  天涯墨客  
##### 26#       发表于 2025-3-1 14:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549584&amp;ptid=2247802" target="_blank">脸宽 发表于 2025-3-1 14:07</a>
现在官网 api 咋样了，想在官网花钱

—— 来自 鹅球 v3.3.96</blockquote>
官网接沉浸式翻译那些有点不太方便

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  ryanghj  
##### 27#       发表于 2025-3-1 14:09

 本帖最后由 ryanghj 于 2025-3-1 14:11 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549584&amp;ptid=2247802" target="_blank">脸宽 发表于 2025-3-1 14:07</a>

现在官网 api 咋样了，想在官网花钱

—— 来自 鹅球 v3.3.96</blockquote>

<img src="https://img.saraba1st.com/forum/202503/01/140931un23pzk3ph4phhws.png" referrerpolicy="no-referrer">

<strong>3c8c705b-10e2-46e0-a518-7679dbec235e.png</strong> (203.21 KB, 下载次数: 0)

下载附件

2025-3-1 14:09 上传

近期服务器应该是扩容了，运行很平稳，但是目前他们加了个排队机制，在高峰期首字延迟会很高

<img src="https://img.saraba1st.com/forum/202503/01/141150a09i9w30i2ili32w.png" referrerpolicy="no-referrer">

<strong>bc783a3e-688b-4876-9b91-640f25058e9b.png</strong> (146.68 KB, 下载次数: 0)

下载附件

2025-3-1 14:11 上传

﹍﹍﹍

评分

 参与人数 1战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| mahoraga| + 2|好评加鹅|

查看全部评分

*****

####  change5665  
##### 28#       发表于 2025-3-1 14:12

我说今早问d老师问题反应这么快，不服务器繁忙了

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  fyjq  
##### 29#       发表于 2025-3-1 14:16

<blockquote>卖哥 发表于 2025-3-1 14:01
成本没有算电费、维护人工费、折旧费，而是购买对应云服务的市场价租金。 ...</blockquote>
云服务产商出租GPU难道不供电，不派人维护，他们的GPU不会折旧？这些钱肯定是算进去的了啊

*****

####  小野賢章  
##### 30#         楼主| 发表于 2025-3-1 14:16

DeepSeek 一共 2224 张 H800，全部跑 R1 API 一年利润 1.73 亿刀。

Grok 20 万张 H100，全部跑 R1 API 一年利润 156 亿刀，特斯拉 2024 年毛利润 174.5 亿刀<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  蛋爷  
##### 31#       发表于 2025-3-1 14:34

想想共享单车滴滴打车和外卖之争，这种事情追求短期利润就是放弃市场。百度AI殷鉴不远。在能承受的范围内尽量挤占对手的空间就是商战阳谋。

*****

####  艾诺琳  
##### 32#       发表于 2025-3-1 14:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549525&amp;ptid=2247802" target="_blank">流浪的翅膀 发表于 2025-3-1 13:58</a>
设备折旧要算的</blockquote>
折旧也是云服务商考虑的
你出门打车还要考虑出租车折旧费？

*****

####  2017.05.04  
##### 33#       发表于 2025-3-1 14:40

说白了就是按deepseek现在的水平，哪怕租云服务平台的卡跑api卖钱都是纯赚，相比起来奥特曼和马一龙还在贴钱
这个效果其实类似当年特斯拉成为第一个净盈利的新能源汽车，足够震撼行业了
很多人不愿意承认只是鸵鸟行为，或者不能接受不是openai而是一个小公司先拿到里程碑

——来自 [S1 Orange](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2244111) 1.2.5

*****

####  秦南心  
##### 34#       发表于 2025-3-1 14:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549314&amp;ptid=2247802" target="_blank">Azcarlo 发表于 2025-3-1 13:27</a>

尤洋这下脸都被打肿了，DeepSeek甚至知乎上开了个账号专门发了一遍。</blockquote>
尤是鱿鱼的鱿吗<img src="https://static.saraba1st.com/image/smiley/face2017/049.png" referrerpolicy="no-referrer">

*****

####  leakleak  
##### 35#       发表于 2025-3-1 15:08

现在甚至租用服务器都能赚钱了，难以想象如果 DeepSeek 自己设计一张专用计算卡会多么的恐怖

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  shqingda_  
##### 36#       发表于 2025-3-1 15:15

 本帖最后由 shqingda_ 于 2025-3-1 15:16 编辑 

大D老师瞄着closeAI打，让大家知道这玩意有多暴利，尤洋什么的也顺带嘴一嘴，感觉其实都没太放在眼里

*****

####  Fingest  
##### 37#       发表于 2025-3-1 16:07

真就天降伟人 

*****

####  Azcarlo  
##### 38#       发表于 2025-3-1 18:03

笑死我了，AI圈开年大戏，尤洋开炮硅基流动

[https://zhuanlan.zhihu.com/p/27282739710](https://zhuanlan.zhihu.com/p/27282739710)

<img src="https://img.saraba1st.com/forum/202503/01/180113d3f56if467flkflm.png" referrerpolicy="no-referrer">

<strong>1.png</strong> (278.12 KB, 下载次数: 0)

下载附件

2025-3-1 18:01 上传

<img src="https://img.saraba1st.com/forum/202503/01/180119kc8l0c8slw5pgryd.png" referrerpolicy="no-referrer">

<strong>2.png</strong> (361.97 KB, 下载次数: 0)

下载附件

2025-3-1 18:01 上传

硅基流动袁老师回应：

<img src="https://img.saraba1st.com/forum/202503/01/180126oygno8whfkuhfbr8.png" referrerpolicy="no-referrer">

<strong>3.png</strong> (171.43 KB, 下载次数: 0)

下载附件

2025-3-1 18:01 上传

给他🤡完了

*****

####  colice  
##### 39#       发表于 2025-3-1 18:06

这不就是“贱|人贱己贱行业”警告么<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  overflowal  
##### 40#       发表于 2025-3-1 18:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67550932&amp;ptid=2247802" target="_blank">Azcarlo 发表于 2025-3-1 18:03</a>
笑死我了，AI圈开年大戏，尤洋开炮硅基流动

https://zhuanlan.zhihu.com/p/27282739710</blockquote>
这种小丑就不要给太多关注了

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  7uly  
##### 41#       发表于 2025-3-1 18:12

真的破防了 然后还嘴硬 太难看了 

*****

####  moekyo  
##### 42#       发表于 2025-3-1 18:16

这姓尤的有人科普吗

*****

####  2017.05.04  
##### 43#       发表于 2025-3-1 18:16

想起功夫了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">
这不就是打不过对面想揪个围观拱火的打一顿显微风吗

——来自 [S1 Orange](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2244111) 1.2.5


*****

####  Nanachi  
##### 44#       发表于 2025-3-1 18:16

感觉这人已经开始借机炒作吸引流量了

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  overflowal  
##### 45#       发表于 2025-3-1 18:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67551008&amp;ptid=2247802" target="_blank">moekyo 发表于 2025-3-1 18:16</a>
这姓尤的有人科普吗</blockquote>
能说出Deepseek难道不该对美国心存感恩吗这种话的人，你细品，学术界出来的废物

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| moekyo| + 1|那没事了|

查看全部评分


*****

####  orecheng  
##### 46#       发表于 2025-3-1 18:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67551018&amp;ptid=2247802" target="_blank">overflowal 发表于 2025-3-1 18:17</a>

能说出Deepseek难道不该对美国心存感恩吗这种话的人，你细品，学术界出来的废物

—— 来自 鹅球 v3.3.96 ...</blockquote>
我觉得都得向卖假药的百度感恩，毕竟Scaling Law是百度发现的，然后Anthropic创始人带到了OpenAI去的。

李彦宏这人眼光是真的牛皮，就是定力实在太差了


*****

####  yswm  
##### 47#       发表于 2025-3-1 19:03

 本帖最后由 yswm 于 2025-3-1 19:05 编辑 

deepseek这些天不管是开源自己的技术组件，还是发布运行报告，应该是奔着要引领AI技术发展方向去的，做AI领域的linux


*****

####  T型钉宫病毒  
##### 48#       发表于 2025-3-1 19:51

体感来说这两天沉浸式翻译接deepseek快了很多

*****

####  Fuuki  
##### 49#       发表于 2025-3-1 19:53

硅基确实慢，公司冲了pro，一周前经常因为慢切换到免费的阿里，上周开始才感觉好一些了
输出还只有4k token


*****

####  mahoraga  
##### 50#       发表于 2025-3-1 20:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67551008&amp;ptid=2247802" target="_blank">moekyo 发表于 2025-3-1 18:16</a>

这姓尤的有人科普吗</blockquote>
我前两年还真看到过，当时是看到一个叫colossalAI的项目，大概是训练和推理的框架都做吧,我没有具体实验过,就是当时看stra数量比较多就简单看了下. 当时看了下他的资料, 是搞AI方面高性能计算的。

但是说实话这个colossalAI有点一直不温不火的，我看到至少都有两三年了，我记得是chatgpt之前我就有看到过一次，但是到现在好像也没弄出什么名堂，反而是后来的像是vllm, SGLang这些现在比较主流


*****

####  空き地卯木  
##### 51#       发表于 2025-3-1 20:23

<blockquote>mahoraga 发表于 2025-3-1 20:14
我前两年还真看到过，当时是看到一个叫colossalAI的项目，大概是训练和推理的框架都做吧,我没有具体实验 ...</blockquote>
那大方向上岂不是ds同行吗？性能或者功能，他的团队写出来啥成果了么？

*****

####  rednaxela  
##### 52#       发表于 2025-3-1 20:25

这么算H800每年利润7w刀？现在H800有没有25万？那不是半年回本每年200%利润


*****

####  overflowal  
##### 53#       发表于 2025-3-1 20:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67551968&amp;ptid=2247802" target="_blank">空き地卯木 发表于 2025-3-1 20:23</a>
那大方向上岂不是ds同行吗？性能或者功能，他的团队写出来啥成果了么？</blockquote>
是硅基的同行。急了说跑deepseek赚不了钱。最后被deepseek发的报告打脸。
硅基老板最后的表示是，你这种每天只有几千人访问的小虾米确实不赚钱<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">
—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  2017.05.04  
##### 54#       发表于 2025-3-1 20:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67551990&amp;ptid=2247802" target="_blank">rednaxela 发表于 2025-3-1 20:25</a>
这么算H800每年利润7w刀？现在H800有没有25万？那不是半年回本每年200%利润</blockquote>
没有，市场目录价20w
稳赚不赔的

——来自 [S1 Orange](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2244111) 1.2.5


*****

####  mahoraga  
##### 55#       发表于 2025-3-1 20:45

<blockquote>空き地卯木 发表于 2025-3-1 20:23
那大方向上岂不是ds同行吗？性能或者功能，他的团队写出来啥成果了么？</blockquote>
大的方向上是，但是他们不自己做模型，主要是搞框架的，所以其实赛道差的还比较远。

其实chatgpt刚出llama刚出那会我还时不时看到他们发个博客说诶呀我们这个框架训练llama复现了什么什么效果，多少多少高效. 当时觉得这个团队跟进得还算挺快的，最近确实没怎么关注了，训练方面不确定，推理肯定是干不过那几个主流开源框架

我其实都很好奇他怎么能算出来差这么多的，之前到底怎么算的，我回去找找他之前的算法到底误差最大的在哪里


*****

####  ryanghj  
##### 56#       发表于 2025-3-1 20:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67552190&amp;ptid=2247802" target="_blank">mahoraga 发表于 2025-3-1 20:45</a>

大的方向上是，但是他们不自己做模型，主要是搞框架的，所以其实赛道差的还比较远。

其实chatgpt刚出lla ...</blockquote>
他是直接用vllm部署了一下觉得很慢，然后觉得DeepSeek团队水平肯定不如vllm所以一定更慢

但是vllm这两天一直在跟着DeepSeek搞适配就很难绷了

<img src="https://img.saraba1st.com/forum/202503/01/204812fzqccmmr4cfk0kf1.png" referrerpolicy="no-referrer">

<strong>474270da-de48-4824-8d26-e453f3ce9809.png</strong> (67.63 KB, 下载次数: 0)

下载附件

2025-3-1 20:48 上传

*****

####  qratosones1337  
##### 57#       发表于 2025-3-1 20:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67551679&amp;ptid=2247802" target="_blank">Fuuki 发表于 2025-3-1 19:53</a>
硅基确实慢，公司冲了pro，一周前经常因为慢切换到免费的阿里，上周开始才感觉好一些了
输出还只有4k token ...</blockquote>
阿里那不是更慢，想要速度的话还得是火山

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  ryanghj  
##### 58#       发表于 2025-3-1 20:55

按照ds官方的数据，全中国的ai需求只需要大约20万张H800（2500个节点）就可以满足

*****

####  moekyo  
##### 59#       发表于 2025-3-1 20:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67551889&amp;ptid=2247802" target="_blank">mahoraga 发表于 2025-3-1 20:14</a>

我前两年还真看到过，当时是看到一个叫colossalAI的项目，大概是训练和推理的框架都做吧,我没有具体实验 ...</blockquote>
你说的vllm是这个这个吗[https://github.com/vllm-project/vllm/pull/13747](https://github.com/vllm-project/vllm/pull/13747)<img src="https://static.saraba1st.com/image/smiley/face2017/035.png" referrerpolicy="no-referrer">

*****

####  约翰里德  
##### 60#       发表于 2025-3-1 20:57

硅基老板说他们的特色是可以调temperature， 别的都是假的，默认0.6，只有他们是真的可以调0-2的，没用过其他的，是的吗


*****

####  2017.05.04  
##### 61#       发表于 2025-3-1 21:11

<img src="https://img.saraba1st.com/forum/202503/01/211109g29q0mlb0lpbtbpg.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20250301_211051.jpg</strong> (1.67 MB, 下载次数: 0)

下载附件

2025-3-1 21:11 上传

<img src="https://img.saraba1st.com/forum/202503/01/210802uwhhbs6t8jxvwzhr.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20250301_210620.jpg</strong> (427.03 KB, 下载次数: 0)

下载附件

2025-3-1 21:08 上传

<img src="https://img.saraba1st.com/forum/202503/01/210803wpdspeywndoop8oe.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20250301_210629.jpg</strong> (411.72 KB, 下载次数: 0)

下载附件

2025-3-1 21:08 上传

<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

——来自 [S1 Orange](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2244111) 1.2.5

*****

####  mahoraga  
##### 62#       发表于 2025-3-1 21:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67552290&amp;ptid=2247802" target="_blank">moekyo 发表于 2025-3-1 20:56</a>

你说的vllm是这个这个吗https://github.com/vllm-project/vllm/pull/13747</blockquote>
是的啊， vllm应该是现在最主流的了把，SGLang也经常听到有人在用。


*****

####  2017.05.04  
##### 63#       发表于 2025-3-1 21:30

<img src="https://img.saraba1st.com/forum/202503/01/213030q69yt9xq4bdqy976.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20250301_212047.jpg</strong> (496.93 KB, 下载次数: 0)

下载附件

2025-3-1 21:30 上传

这个讽刺的最好

——来自 [S1 Orange](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2244111) 1.2.5

*****

####  daliang  
##### 64#       发表于 2025-3-1 21:33

<blockquote>ryanghj 发表于 2025-3-1 20:55
按照ds官方的数据，全中国的ai需求只需要大约20万张H800（2500个节点）就可以满足 ...</blockquote>
2500个节点那就2万张吧


*****

####  2017.05.04  
##### 65#       发表于 2025-3-1 21:36

<img src="https://img.saraba1st.com/forum/202503/01/213620ula45fj7045ltyah.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_20250301_213555.jpg</strong> (392.85 KB, 下载次数: 0)

下载附件

2025-3-1 21:36 上传

——来自 [S1 Orange](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2244111) 1.2.5


*****

####  凉良  
##### 66#       发表于 2025-3-1 21:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549011&amp;ptid=2247802" target="_blank">ww-tsl 发表于 2025-3-1 12:40</a>

要是把写皇叔解禁哪怕只是放宽限制，就算不能加个0至少也能X5。</blockquote>
DS破限难度非常低啊 只比grok稍许甲厚点。 DS写皇叔的问题是太发散太折磨人了。

*****

####  ryanghj  
##### 67#       发表于 2025-3-1 21:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67552549&amp;ptid=2247802" target="_blank">daliang 发表于 2025-3-1 21:33</a>

2500个节点那就2万张吧</blockquote>
打错了，25000个节点


*****

####  流浪的翅膀  
##### 68#       发表于 2025-3-1 21:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549761&amp;ptid=2247802" target="_blank">艾诺琳 发表于 2025-3-1 14:37</a>

折旧也是云服务商考虑的

你出门打车还要考虑出租车折旧费？</blockquote>
人家说自有服务器部署，运营只需考虑电费。

类比自己用电车开出租还差不多。


*****

####  nemo_mxc  
##### 69#       发表于 2025-3-1 22:09

终于也有一天S1吃瓜迟到自己身边了 笑死

*****

####  overflowal  
##### 70#       发表于 2025-3-1 22:09

2000多个H800每天处理600B的token，神之优化，英伟达都要承认自己不会用GPU

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  mahoraga  
##### 71#       发表于 2025-3-1 22:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67552206&amp;ptid=2247802" target="_blank">ryanghj 发表于 2025-3-1 20:47</a>

他是直接用vllm部署了一下觉得很慢，然后觉得DeepSeek团队水平肯定不如vllm所以一定更慢

但是vllm这两天 ...</blockquote>
我靠我刚自己去看了下视频算了下，本来没仔细看之前，我以为是业务场景和一些假设上不一致，导致差这么多，毕竟尤洋也是干这个的，我想不可能实际技术上差了那么远吧，还拉了个表准备逐个环节算差异

结果我算到一半发现两边差别最大的就是单台H800的推理效率，尤洋的假设是250 token/秒， deepseek给的我哪怕按低了算也是1万 token/秒， 这中间几十倍的差距啊，那还有什么好说的

另外他这个没事去Q一下硅基流动，还把deepseek从自己公司下线的举动， 也太不成熟了，Deepseek这么大的热点硅基流动肯定要做的啊，有啥好说人家的

*****

####  绕指流光  
##### 72#       发表于 2025-3-1 22:12

尤洋太小丑了，等R2再出来的时候把他另外一半脸打肿<img src="https://p.sda1.dev/22/a3865c5c8b930924089711e90b2c26e9/image.jpg" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  ads147147  
##### 73#       发表于 2025-3-1 22:12

充分理解了为什么让火云邪神破防的不是打死他而是你想学啊，我教你啊。。

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  shqingda_  
##### 74#       发表于 2025-3-1 22:13

虽然不想引流但是看乐了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer"> 
[https://www.zhihu.com/question/13759294910](https://www.zhihu.com/question/13759294910) 
[https://www.zhihu.com/question/13752772042](https://www.zhihu.com/question/13752772042)


*****

####  neptunehs  
##### 75#       发表于 2025-3-1 22:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67552295&amp;ptid=2247802" target="_blank">约翰里德 发表于 2025-3-1 20:57</a>
硅基老板说他们的特色是可以调temperature， 别的都是假的，默认0.6，只有他们是真的可以调0-2的，没用过其 ...</blockquote>
但也有一种说法是temperature这个参数对r1是完全无效的


*****

####  coldhot3  
##### 76#       发表于 2025-3-1 22:46

<blockquote>neptunehs 发表于 2025-3-1 22:38
但也有一种说法是temperature这个参数对r1是完全无效的</blockquote>
deepseek的r1文档上说是没用的，但是硅基是不是自己弄了啥改进，这就不知道了。

*****

####  kouym  
##### 77#       发表于 2025-3-1 22:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67549593&amp;ptid=2247802" target="_blank">天涯墨客 发表于 2025-3-1 14:09</a>

官网接沉浸式翻译那些有点不太方便

—— 来自 鹅球 v3.3.96</blockquote>
很方便的 只要兼容openai格式的就能用官网的api 不需要单独适配的

就是现在多了个排队模式 体验上稍微比之前没火前 慢一点点

*****

####  ryanghj  
##### 78#       发表于 2025-3-1 22:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67552999&amp;ptid=2247802" target="_blank">coldhot3 发表于 2025-3-1 22:46</a>

deepseek的r1文档上说是没用的，但是硅基是不是自己弄了啥改进，这就不知道了。 ...</blockquote>
你误解了，所有Transformer模型都可以设置Temperature，只是官网不让调因为推理模型对Temperature很敏感所以没开放，第三方自己部署的都可以调


*****

####  coldhot3  
##### 79#       发表于 2025-3-1 22:52

<blockquote>ryanghj 发表于 2025-3-1 22:49
你误解了，所有Transformer模型都可以设置Temperature，只是官网不让调因为推理模型对Temperature很敏感所 ...</blockquote>
就是说他们的模型能调，但是ds人为锁死了？那我们私有部署的ds蒸馏模型也能调了？我们正在挠头怎么解决ai思维发散问题呢。降低temperature有效果吗？


*****

####  ryanghj  
##### 80#       发表于 2025-3-1 22:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67553041&amp;ptid=2247802" target="_blank">coldhot3 发表于 2025-3-1 22:52</a>

就是说他们的模型能调，但是ds人为锁死了？那我们私有部署的ds蒸馏模型也能调了？我们正在挠头怎么解决ai ...</blockquote>
Temp=0的时候每次相同输入都会给出相同输出，这个参数本质上是在最后挑选的时候改变候选词的权重


*****

####  coldhot3  
##### 81#       发表于 2025-3-1 22:58

<blockquote>ryanghj 发表于 2025-3-1 22:54
Temp=0的时候每次相同输入都会给出相同输出，这个参数本质上是在最后挑选的时候改变候选词的权重 ...</blockquote>
我们先从翻译资料开始，然后远期目标是让ai审核资料，当然如果ai能提出改进意见，我就失业了。但现在ai翻译有时候自己就开始输出无意义的语句，请问这一点的频率能通过降低温度来减少吗？谢谢。


*****

####  tubarl_kumiko  
##### 82#       发表于 2025-3-1 23:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67553086&amp;ptid=2247802" target="_blank">coldhot3 发表于 2025-3-1 22:58</a>

我们先从翻译资料开始，然后远期目标是让ai审核资料，当然如果ai能提出改进意见，我就失业了。但现在ai翻 ...</blockquote>
[https://github.com/deepseek-ai/a ... zotero/README_cn.md](https://github.com/deepseek-ai/awesome-deepseek-integration/blob/main/docs/zotero/README_cn.md)

翻译用v3模型，温度设置为1.3就行了吧


*****

####  库德里尔  
##### 83#       发表于 2025-3-1 23:57

r1当然可以接受温度作为参数，但是是为了兼容性考虑。
实际上它会忽略掉。

读文档之后我是这么认为的。


*****

####  qratosones1337  
##### 84#       发表于 2025-3-2 03:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67553505&amp;ptid=2247802" target="_blank">库德里尔 发表于 2025-3-1 23:57</a>

r1当然可以接受温度作为参数，但是是为了兼容性考虑。

实际上它会忽略掉。</blockquote>
官网和火山的API可以设置温度，但是不生效，无论设置多少都会变成0.6

