
*****

####  机吉斯卡  
##### 1#       楼主       发表于 2024-12-27 16:21

 本帖最后由 机吉斯卡 于 2025-1-21 16:14 编辑 

1-21

大江户老哥现在不回来了
[https://weibo.com/5338698416/5125284904568851](https://weibo.com/5338698416/5125284904568851)

国内讨论DeepSeek-R1的不多，但是这东西在国外已经炸锅了。一家中国的小公司，没有几十万的计算资源，居然能发布赶超OpenAI-o1的模型，而且还是MIT协议开源的，并且定价是OpenAi的1/30，网页版甚至可以无限量使用。这太夸张了，我认为是一次AI领域的“小红书时刻”。

很多人可能会问DeepSeek把模型开源了难道不怕赔钱吗？我觉得，DeepSeek才是AI领域商业模式范式转换的那个。DeepSeek的超低定价形成一种非常独特的现象：如果你要配一台能够在本地运行R1的机器，需要的钱够你用好多年DeepSeek API了。而且我毫不怀疑哪怕有国外第三方公司试图部署R1模型，他们的定价也不会低于DeepSeek自己。也就是说，DeepSeek是真正的“游戏改变者”，他敢大方的开源就是因为他们知道哪怕你手上有模型，你也无法超过我。

这种思路和之前OpenAI等美国公司采用的“小院高墙”“护城河”策略形成鲜明对比。这种开源战略可以说是真的在掏空这些大公司的地基。我昨天在推上看到个美国人评论很形象，这就好像当年的美国肌肉车vs日本经济车一样。

顺带一提，DeepSeek在海外已经出现一小批死忠粉了，因为DeepSeek的LOGO是个鲸鱼，所以这群人都管DeepSeek叫Whale bro（鲸哥）[二哈]

[https://weibo.com/1560906700/5116227597110418](https://weibo.com/1560906700/5116227597110418)

这几天刷推很明显的感觉到英文技术社区对中国AI产业的进步速度处于一种半震动半懵逼的状态，应激来源主要是两个，一个是宇树（Unitree）的轮足式机器狗B2-W，另一个是开源MoE模型DeepSeek-V3。

宇树在早年基本上属于是波士顿动力的跟班，产品形态完全照猫画虎，商业上瞄准的也是低配平替生态位，没有太大的吸引力，但从B系列型号开始，宇树的机器狗就在灵活性上可以和波士顿动力平起平坐了。

B2-W的意外在于切换了技术线，用运动性更高但平衡性同时也更难的动轮方案取代了B2还在沿用四足方案，然后在一年时间里完成了能在户外环境里跋山涉水的训练，很多美国人在视频底下说这一定是CGI的画面，不知道是真串还是心态炸了。

波士顿在机器狗身上也曾短暂用过动轮方案，或者说它测过的方案远比宇树要多——公司成立时长摆在那里——但是作为行业先驱，它连保持一家美国公司的实体都办不到了。

现代汽车2020年以打折价从软银手里买了波士顿动力，正值软银账面巨亏需要回血，而软银当初又是在2017年从Google那里买到手的，Google为什么卖呢，因为觉得太烧钱了，亏不起。

这理由就很离谱，美国的风险资本系统对于亏损的容忍度本来就是全球最高的，没有之一，对于前沿性的研究，砸钱画饼是再寻常不过了的——看这两年硅谷在AI上的投入产出比就知道了——但波士顿动力何以在独一档的地位上被当成不良资产卖来卖去？

那头房间里的大象，美国的科技行业普遍都装作看不到：美国人，如今的美国人，从投行到企业，从CEO到程序员，从纽约到湾区，对制造业的厌弃已经成为本能了。

A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」，大概意思是，边际成本极低的软件公司注定接管一切水草繁盛之地，和这种可以提供指数级增长的生意比起来，其他的行业都不够看。

并不是说马克·安德森的表达有问题，后面这十几年来的现实走向，也确实在证明这条攫取规模化利润的回报是最高的，但美国人的路径依赖到最后必然带来一整代人丧失制造能力的结果。

这里说的丧失制造能力，并不是说丧失制造兴趣或是热情，我前段时间拜访了深圳一家逆向海淘公司，业务就是把华强北的电子配件做成可索引的结构化目录，然后提供从采购到验货再到发包的全流程服务，最大的买方就是美国的DIY市场和高校学生，他们之所以要不远万里的等上几个星期委托中国人来买东西，就是因为在诺大的美国本土，根本找不到供应链。

然后那些学生也只有在读书时才有真正尝试制造某些东西的机会，到了要去大公司里上班领薪后，再也没人愿意把手弄脏了。

但软件终究不能脱离硬件运行，哪怕硬件生产的附加值再不够看，基于采集一手物理数据的入口，制造商腰板硬起来后去做全套解决方案，只取决于能不能组建好的工程师团队，反过来却不一样，制造订单长期外包出去，它就变成产业链配套回不来了。

所以像是多旋翼无人机和四足机器狗这类新兴科技萌芽的原型机一般都还是产自有着试错资本的欧美，也就是所谓「从零到一」的过程，而在「从一到十」的落地阶段，中国的追赶成果就会开始密集呈现，进入「从十到百」的量产之后，中国的供应链成本直接杀死比赛。

波士顿动力的机器人最早在网上爆火的时候，Google X的负责人在内部备忘录里说他已经和媒体沟通了，希望不要让视频和Google扯上太大关系，是不是很迷惑，这么牛逼的事情，你作为母公司非但不高兴，还想躲起来，现在你们懂得这种顾虑从何而来了，就是觉得贵为软件巨头的Google去卷袖子干制造的活儿太卑贱了呗。

当然美国也还有马斯克这样的建设者（Builder），但你要知道马斯克的故事之所以动人，是因为他这样的人现在是极度稀缺的，而且长期以来不受主流科技业界待见，完全是靠逆常识的成就——造汽车，造火箭，造隧道，这都是硅谷唯恐避之不及的事情——去一步步打脸打出来的名声。

如果说宇树是在硬件上引起了一波怀疑现实的热度，那么DeepSeek则在软件的原生地盘，把大模型厂商都给硬控住了。

在微软、Meta、Google都在奔着10万卡集群去做大模型训练时，DeepSeek在2000个GPU上，花了不到600万美金和2个月的时间，就实现了对齐GPT-4o和Claude 3.5 Sonnet的测试结果。

DeepSeek-V2在半年前就火过一波，但那会儿的叙事还相对符合旧版本的预期：中国AI公司推出了低成本的开源模型，想要成为行业里的价格屠夫，中国人就擅长做这种便宜耐用的东西，只要不去和顶级产品比较，能用是肯定的。

但V3则完全不同了，它把成本降了10倍以上，同时质量却能比肩t1阵营，关键还是开源的，相关推文的评论区全是「中国人咋做到的？」

虽然但是，后发的大模型可以通过知识蒸馏等手段实现性价比更高的训练——类似你学习牛顿三定律的速度降低的斜率也在有利于追赶者，肯定比牛顿本人琢磨出定律的速度要快——成本，但匪夷所思的效率提升，是很难用已知训练方法来归纳的，它一定是是在底层架构上做了不同于其他巨头的创新。

另一个角度更有意思，如果针对中国的AI芯片禁售政策最后产生的后果，是让中国的大模型公司不得不在算力受限的约束下实现了效率更高的解决方案，这种适得其反的剧情就太讽刺了。

DeepSeek的创始人梁文锋之前也说过，公司差的从来都不是钱，而是高端芯片被禁运。

所以中国的大模型公司，像是字节和阿里这样的大厂，卡能管够，把年收入的1/10拿出来卷AI，问题不大，但初创公司没这么多弹药，保持不下牌桌的唯一方法就是玩命创新。

李开复今年也一直在表达一个观点，中国做AI的优势从来不是在不设预算上限的情况下去做突破性研究，而是在好、快、便宜和可靠性之间找出最优解。

零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。

当然DeepSeek不太一样的是，它不太缺卡，2021年就囤了1万张英伟达A100，那会儿ChatGPT还没影呢，和Meta为了元宇宙囤卡却阴差阳错的赶上AI浪潮很像，DeepSeek买那么多卡，是为了做量化交易⋯⋯

我最早对梁文锋有印象，是「西蒙斯传」里有他写的序，西蒙斯是文艺复兴科技公司的创始人，用算法模型去做自动化投资的开创者，梁文锋当时管着600亿人民币的量化私募，写序属于顺理成章的给行业祖师爷致敬。

交待这个背景，是想说，梁文锋的几家公司，从量化交易做到大模型开发，并不是一个金融转为科技的过程，而是数学技能在两个应用场景之间的切换，投资的目的是预测市场，大模型的原理也是预测Token。

后来看过几次梁文锋的采访，对他的印象很好，非常清醒和聪明的一个人，我贴几段你们感受一下：

「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？

梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。

「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。

梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。

「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。

梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。

「暗涌」：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？

梁文锋：我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。英伟达的领先，不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图。中国AI的发展，同样需要这样的生态。很多国产芯片发展不起来，也是因为缺乏配套的技术社区，只有第二手消息，所以中国必然需要有人站到技术的前沿。

「暗涌」：很多大模型公司都执着地去海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国的公司，你们的人都来自哪里？

梁文锋：V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。

「暗涌」：所以你对这件事也是乐观的？

梁文锋：我是八十年代在广东一个五线城市长大的。我的父亲是小学老师，九十年代，广东赚钱机会很多，当时有不少家长到我家里来，基本就是家长觉得读书没用。但现在回去看，观念都变了。因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了。以后硬核创新会越来越多。现在可能还不容易被理解，是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。

⋯⋯

是不是很牛逼？反正我是被圈粉了，做最难的事情，还要站着把钱赚了，一切信念都基于对真正价值的尊重和判断，这样的80后、90后越来越多的站上了主流舞台，让人非常宽慰，你可以说他们在过去是所谓的「小镇做题家」，但做题怎么了，参与世界未来的塑造，就是最有挑战性的题，喜欢解这样的题，才有乐趣啊。

﹍﹍﹍

评分

 参与人数 5战斗力 +6

|昵称|战斗力|理由|
|----|---|---|
| 馍馍鲜| + 2|好评加鹅|
| 偽物| + 1|好评加鹅|
| ymm1030| + 1|好评加鹅|
| 赛文欧德| + 1|好评加鹅|
| hbxsdfx| + 1|中年人被粉了，淦|

查看全部评分

*****

####  CCauchy  
##### 2#       发表于 2024-12-27 16:25

量化交易是指AI量化交易吗? 这不还是AI, 也不算阴差阳错吧

*****

####  Van夫膜开  
##### 3#       发表于 2024-12-27 16:28

从搞量化私募直接转行搞LLM，这个决心和眼界是真的牛逼

*****

####  amzonme  
##### 4#       发表于 2024-12-27 16:28

deepseek的软文？

*****

####  出逃白鲸  
##### 5#       发表于 2024-12-27 16:29

 本帖最后由 出逃白鲸 于 2024-12-27 16:32 编辑 

楼主没贴作者名字，个人凭感觉这个作者肯定不是制造业的，说了半天很空洞。

观点也许对，但内容空，套话多，爱用无关例证，这种行文像是经常写蹭热度文章忽悠外行留下的习惯

*****

####  魔灵高达  
##### 6#       发表于 2024-12-27 16:31

软文<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  netplaying  
##### 7#       发表于 2024-12-27 16:32

等chatgpt降价再说吧

*****

####  小李子大脸猫  
##### 8#       发表于 2024-12-27 16:33

以六代机为首的竞争刚好体现美国洛克希德马丁等制造业公司的极限，这就是美国人临盆难产面对的刚体洛希极限

*****

####  绝地潜兵  
##### 9#       发表于 2024-12-27 16:34

 本帖最后由 绝地潜兵 于 2024-12-27 16:35 编辑 

机器人确实发展得好，但那个过程是在臆想吧。感觉是deepseek软文

*****

####  木水风铃  
##### 10#       发表于 2024-12-27 16:35

今天倒是微博上看到几个说v3效率惊人的，不过还是等能用到手再说吧

—— 来自 HUAWEI NOH-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v3.0.0.81-alpha

*****

####  壹十  
##### 11#       发表于 2024-12-27 16:38

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  alixsander  
##### 12#       发表于 2024-12-27 16:39

<blockquote>木水风铃 发表于 2024-12-27 16:35
今天倒是微博上看到几个说v3效率惊人的，不过还是等能用到手再说吧

—— 来自 HUAWEI NOH-AN00, Android 1 ...</blockquote>
V3你上他们官网就能用了。论文和权重也都开放了下载了

*****

####  泰坦失足  
##### 13#       发表于 2024-12-27 16:40

关注的几个傻X博主同时发了QVQ的商稿，对通义千问的好感大降。

另外之前Deepseek的API看了半天，发现没写多模态输入在哪。这次的V3也一样没多模态。

隔壁OpenAI除了翻车的Sora，多模态的4o，长推理的o1。得到的结果就是一个可以实时理解视频流和音频流并即时输出的模型，而不是走 视频/音频-&gt;文字-&gt;音频TTS的道路

*****

####  木板春香  
##### 14#       发表于 2024-12-27 16:42

 做自媒体的人

*****

####  moekyo  
##### 15#       发表于 2024-12-27 16:45

我只能说我在推上搜DeepSeek基本都是吹的，和半年多之前的千问差不多

*****

####  张元英  
##### 16#       发表于 2024-12-27 16:48

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  bbk6rz  
##### 17#       发表于 2024-12-27 16:51

以前熟知的杭州大企业就一个阿里。现在知道的，有游戏科学，宇树，deepseek。

*****

####  a4ac7  
##### 18#       发表于 2024-12-27 16:51

 本帖最后由 a4ac7 于 2024-12-27 17:03 编辑 

在文字处理方面，感觉o1是有挺大提升的

拿坛友这个对子问

<img src="https://p.sda1.dev/21/d5695a88bb411889bf604e06df274313/image.jpg" referrerpolicy="no-referrer">

o1回答至少字数和结构对上了，4o和seek半斤八两，不过能达到4o也很nb了

试了下deepseek的深度思考，有点意思

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.2.91

*****

####  流缨  
##### 19#       发表于 2024-12-27 16:55

软文，但是deepseek真的不错，这几天TWZ的文章我都用它翻译了看，有个回复里有个英文非主流词 '$hort' 都翻译对了，试了一下传统的翻译器都没做到

*****

####  overflowal  
##### 20#       发表于 2024-12-27 17:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035649&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2024-12-27 16:40</a>

关注的几个傻X博主同时发了QVQ的商稿，对通义千问的好感大降。

另外之前Deepseek的API看了半天，发现没写多 ...</blockquote>
deepseek本来就不是个多模态模型啊。

*****

####  yuialon  
##### 21#       发表于 2024-12-27 17:03

<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

纯软广，预训练技术路线已经到头了

下一代路线如果摸索出来，预训练直接被扫进垃圾桶

至于幻方转AI，纯被证监会制裁转行罢了，可以搜下《证券市场程序化交易管理规定》

*****

####  洛拉斯  
##### 22#       发表于 2024-12-27 17:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035753&amp;ptid=2224673" target="_blank">a4ac7 发表于 2024-12-27 16:51</a>
在文字处理方面，感觉o1是有挺大提升的

拿坛友这个对子问</blockquote>
下联你贴出来一下可以吗

*****

####  冯恩在写小说  
##### 23#       发表于 2024-12-27 17:07

不能这么拼，波士顿动力仍然有西方企业的核心技术优势：画饼

*****

####  overflowal  
##### 24#       发表于 2024-12-27 17:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035855&amp;ptid=2224673" target="_blank">yuialon 发表于 2024-12-27 17:03</a>

纯软广，预训练技术路线已经到头了

下一代路线如果摸索出来，预训练直接被扫进垃圾桶</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">这有啥好软广的。x上各路ai圈的推主这两天都在谈deepseek的新模型，openrouter上到deepseek api的流量翻了3倍。

*****

####  基本农田  
##### 25#       发表于 2024-12-27 17:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035579&amp;ptid=2224673" target="_blank">小李子大脸猫 发表于 2024-12-27 16:33</a>
以六代机为首的竞争刚好体现美国洛克希德马丁等制造业公司的极限，这就是美国人临盆难产面对的刚体洛希极限 ...</blockquote>
今年各方面的进步，表明东大在技术创新能力上已经正式全面超越欧美

*****

####  qratosones1337  
##### 26#       发表于 2024-12-27 17:17

人家模型开源了，技术报告发了，官网也上线了，楼上一堆刷软文的是只会复读么？

*****

####  笨拙的机器人  
##### 27#       发表于 2024-12-27 17:26

一眼deepseek软文，deepseek牛逼没错，也不至于翻到豆包千问前面去

*****

####  a4ac7  
##### 28#       发表于 2024-12-27 17:27

 本帖最后由 a4ac7 于 2024-12-27 17:34 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035868&amp;ptid=2224673" target="_blank">洛拉斯 发表于 2024-12-27 17:05</a>
下联你贴出来一下可以吗</blockquote><strong>问题：</strong>
帮我对个对子，一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

<strong>ChatGPT o1：</strong>
下面是一条与原句在字数和节奏上相匹配的下联示例，可供参考。为了与上联同样带有“跳过九”的趣味，且在内容上与“五角大楼”“六神无主”“七上八下”等处形成对应，下联也巧用了数字与词语搭配，保持了同样的诙谐气质。

<strong>上联：</strong>
一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

<strong>下联（示例）：</strong>
一言两疑惹三大盟友四处施压惊动五角白宫六魄无存七扯八纠酒尽方言十分狼狈

<strong>拆分对照与释义：</strong>  <strong>一言 两疑</strong>
上联“一艘 两攻”，下联用“一言 两疑”呼应，皆为四字，暗示“说一句话却生出两种猜忌”。

<strong>惹三大盟友</strong>
对应上联“共三架飞机”。“三大盟友”既点出“三”这个数字，也让情节更加国际化。

<strong>四处施压</strong>
对应上联“四款新品”，同样以“四”字开头，表达多方向、多方面的动作。

<strong>惊动五角白宫</strong>
上联是“搞得五角大楼”，下联改为“惊动五角白宫”，既保留“五角”这一核心元素，又把“大楼”变成“白宫”，进一步衬托美方焦虑。

<strong>六魄无存</strong>
对应上联“六神无主”，继续使用“六”字＋“魄”来与“神”对仗，营造神魂颠倒之感。

<strong>七扯八纠</strong>
上联“七上八下”，下联用“七扯八纠”，依旧是数字七、八的并列，形容混乱局面。

<strong>酒尽方言</strong>
上联是“酒后加班”，下联“酒尽方言”则表现“酒喝光了才开始胡说”之意，与加班后烦躁相呼应。

<strong>十分狼狈</strong>
对应“十分难受”，以“狼狈”烘托窘迫、糟糕的状态，跟“难受”形成近义映衬。 

如果觉得用词或主题还可以进一步润色，也可以在保持字数和数词位置不变的前提下，根据实际需要做微调。希望对你的创作有所启发!

<strong>ChatGPT 4o：</strong>
<strong>上联：</strong>
一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

<strong>下联：</strong>
九天八荒携七条龙舟六尺金枪破得五岳四海三江两岸一战风流

<strong>Deepseek：</strong>
十全九美有八斗才七步成诗六艺精通五湖四海三心二意一夜成名百般得意

<strong>Deepseek（带深度思考）：</strong>
这是一句带有数字和对仗色彩的顺口溜，描述了一种混乱和无奈的场景。下面是对这句顺口溜的解释和可能的“对子”：

<strong>原句：</strong>
一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

<strong>解释：</strong>  <strong>一艘两攻：</strong>
可能指一艘具有两种攻击能力的舰船。

<strong>共三架飞机：</strong>
指共有三架飞机。

<strong>四款新品：</strong>
指四种新产品或新装备。

<strong>搞得五角大楼：</strong>
可能指这些装备让五角大楼（美国国防部）感到困扰。

<strong>六神无主：</strong>
形容非常慌乱，没有头绪。

<strong>七上八下：</strong>
形容心情不安，忐忑不定。

<strong>酒后加班：</strong>
指在喝酒之后还要加班工作。

<strong>十分难受：</strong>
形容非常不舒服，可能指身体或心理上的不适。 

<strong>对子：</strong>
（上联）一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

（下联）一面五星展六尺红旗七彩光芒照亮八方天地九天揽月十分自豪

<strong>解释：</strong>  <strong>一面五星：</strong>
指一面五星红旗。

<strong>展六尺红旗：</strong>
展开六尺长的红旗。

<strong>七彩光芒：</strong>
形容红旗在阳光下闪耀着七彩的光芒。

<strong>照亮八方天地：</strong>
指红旗的光芒照亮了四周。

<strong>九天揽月：</strong>
指登月等航天成就。

<strong>十分自豪：</strong>
形容对国家成就感到非常自豪。 

这个对子通过对比原句的混乱和无奈，表达了对国家成就的自豪感。

顺便这个第一次 Deepseek 带深度思考对的，“一花两叶共三春花开四季芬芳扑鼻使得五湖四海六合同春七彩斑斓八方来客九九归一十分和谐”，看来不太稳定

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.2.91

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 洛拉斯| + 1|好评加鹅|

查看全部评分

*****

####  overflowal  
##### 29#       发表于 2024-12-27 17:32

 本帖最后由 overflowal 于 2024-12-27 17:33 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036030&amp;ptid=2224673" target="_blank">笨拙的机器人 发表于 2024-12-27 17:26</a>

一眼deepseek软文，deepseek牛逼没错，也不至于翻到豆包千问前面去</blockquote>
大家觉得deepseek牛逼是因为它在各种benchmark表现真的跟闭源模型硬刚了啊，他们自己报告里也写了和qwen的对比。别这里虚空排位干不过豆包千问

*****

####  qratosones1337  
##### 30#       发表于 2024-12-27 17:32

 本帖最后由 qratosones1337 于 2024-12-27 17:39 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036030&amp;ptid=2224673" target="_blank">笨拙的机器人 发表于 2024-12-27 17:26</a>

一眼deepseek软文，deepseek牛逼没错，也不至于翻到豆包千问前面去</blockquote>
笑死，论模型能力，豆包就是个CJB，也就是产品做的比较好而已，现在DeepSeek和Qwen就是国内的Top-2。然后Qwen现在已经放弃了超大模型冲SOTA了，专注于做中小模型，跟DeepSeek生态位正好错开了。

*****

####  chachi  
##### 31#       发表于 2024-12-27 17:40

坐等千问qwq 

*****

####  马车夫  
##### 32#       发表于 2024-12-27 17:41

美帝这几年甚至是十多年前万物转码的后遗症，认识不少学机械EE的纷纷抛弃制造业，纯coding又不是什么要智商的玩意儿，，

剩下的本土制造业学生疯狂追星马斯克这根独苗，tesla的实习目测不给钱简历都收爆

*****

####  overflowal  
##### 33#       发表于 2024-12-27 17:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035969&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2024-12-27 17:17</a>

人家模型开源了，技术报告发了，官网也上线了，楼上一堆刷软文的是只会复读么？ ...</blockquote>
国内公司发了一个堪比商业闭源模型的开源模型，技术报告写的清清楚楚，国外ai圈子讨论的热火朝天。

国内自媒体反应过来跟着吹一下，一群人第一反应是软文大内宣，我也是服

*****

####  笨拙的机器人  
##### 34#       发表于 2024-12-27 17:45

<blockquote>overflowal 发表于 2024-12-27 17:32
大家觉得deepseek牛逼是因为它在各种benchmark表现真的跟闭源模型硬刚了啊，他们自己报告里也写了和qwen的 ...</blockquote>
别跑题，我的重点在软文，前面把宇树抬出来是因为直接说deepseek啊排行榜啊这种抽象的东西，你不容易有感。先用宇树吸睛，再吹deepseek，我的雷达响了

*****

####  泰坦失足  
##### 35#       发表于 2024-12-27 17:48

这玩意尺寸是671B，啥卡能放下啊<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">. llama 3.2的405b都挺抽象的了.

*****

####  overflowal  
##### 36#       发表于 2024-12-27 17:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036132&amp;ptid=2224673" target="_blank">笨拙的机器人 发表于 2024-12-27 17:45</a>

别跑题，我的重点在软文，前面把宇树抬出来是因为直接说deepseek啊排行榜啊这种抽象的东西，你不容易有感 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">那行吧，就是软文。deepseek这公司怎么会出现在在公众视野呢，肯定是软文没跑了

*****

####  钱如命  
##### 37#       发表于 2024-12-27 17:52

这篇文章确实是标准的软文结构啊<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">
标题是“西方vs中国”的标准引战标题党吸引眼球，开头讲了大概1/4的机械狗发展历程（宇树只是提了一嘴，更多的是“理性客观公正”地分析局势）
然后剩下3/4，“接下来说说软件”的转场之后，就是长篇大论“只针对”deepseek的夸奖和吹捧，放了一大段老板的个人访谈
直到最后文末总结，也把标题和开头扔在一边，专注于“优秀的老板和企业家”这个部分
就算他吹的是现在蓝星第一，那也是软文啊（）

—— 来自 HUAWEI ALN-AL80, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.1.2

*****

####  med  
##### 38#       发表于 2024-12-27 17:53

再加一个游科，软文就更明显了 <img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  overflowal  
##### 39#       发表于 2024-12-27 17:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036160&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2024-12-27 17:48</a>

这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
单卡是放不下了，真想跑可以尝试放到内存用CPU跑，应该速度是能用的。因为是MoE架构<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">

*****

####  橋白  
##### 40#       发表于 2024-12-27 17:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036160&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2024-12-27 17:48</a>
这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
本来就放不下啊 moe结构说白了是省电费又不是省显存…

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  qratosones1337  
##### 41#       发表于 2024-12-27 18:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036123&amp;ptid=2224673" target="_blank">overflowal 发表于 2024-12-27 17:42</a>

国内公司发了一个堪比商业闭源模型的开源模型，技术报告写的清清楚楚，国外ai圈子讨论的热火朝天。

国内 ...</blockquote>
说明泥潭喜欢不懂装懂的懂哥太多了，啥都想插一句嘴，然后自己又根本不懂（甚至可能都没到一知半解的地步），自然就只能甩锅软文咯。毕竟只要“雷达响了”就自动立于不败之地了

*****

####  qratosones1337  
##### 42#       发表于 2024-12-27 18:08

 本帖最后由 qratosones1337 于 2024-12-27 18:11 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036219&amp;ptid=2224673" target="_blank">橋白 发表于 2024-12-27 17:55</a>

本来就放不下啊 moe结构说白了是省电费又不是省显存…

论坛助手,iPhone</blockquote>
利好超大显存的廉价推理卡，正好这次DeepSeek开源的时候也同步发布了昇腾可用的推理方案，估计DeepSeek自己可能已经在用Atlas300I Duo来推理了（这玩意有96G显存，一张卡不到3W块钱）。用N卡的话现在H20到手价也不贵

*****

####  qratosones1337  
##### 43#       发表于 2024-12-27 18:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036160&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2024-12-27 17:48</a>

这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
华为有个Atlas300I，96G显存版本单卡售价3W块钱不到，正好这次模型Release的时候连MindIE推理镜像都一起发了

*****

####  yanjunle  
##### 44#       发表于 2024-12-27 18:13

 本帖最后由 yanjunle 于 2024-12-27 18:14 编辑 

deepseek-v3发布最思细恐极的一点不是涨价预告吗，不知道为什么没看到什么相关的讨论。

幻方是今年这轮api价格战的发动者，5月份靠“模型结构创新+超强infra+不求盈利只求打平推理成本”实现了一块钱一百万token还能维持50%毛利，可以认为幻方拥有世界上最顶尖不用加之一的llm工程团队。

以及目前llm性能增长的方向是test-time scaling，qwq和deepseek-r1看起来都是走成倍增加输出token数来解决更困难的问题的路线，输出token数增加会导致使用成本急剧上涨（比如前几天o3发布时号称做一道题要用掉3500刀），只能寄希望于降低token输出单价来降低整体使用成本。

然而deepseek涨价了，说明即使世界最强工程团队也控制不住llm推理成本了，llm智价比很可能已经到顶了，未来都是1块钱2分货10块钱3分货了<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  笨拙的机器人  
##### 45#       发表于 2024-12-27 18:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036283&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2024-12-27 18:07</a>

说明泥潭喜欢不懂装懂的懂哥太多了，啥都想插一句嘴，然后自己又根本不懂（甚至可能都没到一知半解的地步 ...</blockquote>
乐，在跑实验罢了，哪个一线算法天天追论文不做业务

*****

####  御姐控之耻  
##### 46#       发表于 2024-12-27 18:15

上联：一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

下联：十点九分看八方网友七彩贺图庆祝六代战机五湖纵横四海三山两府沸腾一等先进。

﹍﹍﹍

评分

 参与人数 4战斗力 +4

|昵称|战斗力|理由|
|----|---|---|
| belichick| + 1|好评加鹅|
| Evecat| + 1|好|
| a4ac7| + 1|快来人，出对子对死他！|
| 火星後繼者| + 1|不愧是对穿肠！|

查看全部评分

*****

####  moekyo  
##### 47#       发表于 2024-12-27 18:18

忽然想起，之前我看到最搞笑的是之前千问2.5出来的时候，我在推上搜，看到一个日本人对千问回答他说**是中国的无能狂怒<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  Pz079  
##### 48#       发表于 2024-12-27 18:24

从语文的角度来看，这篇文章是否是软文暂且不论，但前后逻辑混乱矛盾，的确需要打回去重写。文章以西大制造业衰退，没人研发硬件为开篇，批判“软件吞噬世界”，然后拉上宇树蹭热度，还以为要为我国博兴的制造产业呐喊，结果最后话锋一转落脚到给一个量化基金开发的AI模型张目，别忽悠大众行吗，你这个量化基金的AI项目不是你上面批判的软件么，还是个搞金融出身的软件服务，怎么三五行文字之后你都不知道自己前面说的那么多废话了？

*****

####  双刀少女  
##### 49#       发表于 2024-12-27 18:30

别的不懂，幻方跳到llm也能吹是眼力吗 之前还全网群嘲来着

*****

####  longrider  
##### 50#       发表于 2024-12-27 18:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035537&amp;ptid=2224673" target="_blank">出逃白鲸 发表于 2024-12-27 16:29</a>

楼主没贴作者名字，个人凭感觉这个作者肯定不是制造业的，说了半天很空洞。

观点也许对，但内容空，套话多 ...</blockquote>
作者是著名微博/X国师[@阑夕](https://bbs.saraba1st.com/2b/home.php?mod=space&amp;uid=147804)

*****

####  迷路的石头  
##### 51#       发表于 2024-12-27 19:09

<blockquote>Van夫膜开 发表于 2024-12-27 16:28
从搞量化私募直接转行搞LLM，这个决心和眼界是真的牛逼</blockquote>
啥决心啊，20/21年幻方牛市里基金效益好，老总信心来了就梭哈了10000张A100搞深度学习挖因子，结果整的过拟合效益回撤了50%。当时都在嘲讽他们步子太大扯着蛋。

结果老登算力禁运后这10000张卡瞬间成了香饽饽，就顺势转到AI了

*****

####  迷路的石头  
##### 52#       发表于 2024-12-27 19:13

<blockquote>泰坦失足 发表于 2024-12-27 17:48
这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
幻方因为机缘巧合有10000张A100，所以AI发展还是要靠算力

*****

####  迷路的石头  
##### 53#       发表于 2024-12-27 19:16

<blockquote>yuialon 发表于 2024-12-27 17:03
纯软广，预训练技术路线已经到头了

下一代路线如果摸索出来，预训练直接被扫进垃圾桶

</blockquote>
没有证监会也会转

金融数据这种信噪比极低的数据搞深度学习只能搞出一堆过拟合。上了A100后幻方的业绩直接过山车。再加上美国禁运，国内在也搞不到这么多卡，转AI就是个顺势而为的事了

*****

####  ymm1030  
##### 54#       发表于 2024-12-27 19:20

就算软文怎么了，黑猴做的那么牛逼也需要宣传啊

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  overflowal  
##### 55#       发表于 2024-12-27 19:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036324&amp;ptid=2224673" target="_blank">yanjunle 发表于 2024-12-27 18:13</a>
deepseek-v3发布最思细恐极的一点不是涨价预告吗，不知道为什么没看到什么相关的讨论。

幻方是今年这轮api ...</blockquote>
硬件不是发展停滞的。未来有更便宜更强的推理硬件完全是可能的。

—— 来自 Xiaomi 23049RAD8C, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  FeteFrumoase  
##### 56#       发表于 2024-12-27 19:34

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  qratosones1337  
##### 57#       发表于 2024-12-27 19:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036324&amp;ptid=2224673" target="_blank">yanjunle 发表于 2024-12-27 18:13</a>
deepseek-v3发布最思细恐极的一点不是涨价预告吗，不知道为什么没看到什么相关的讨论。

幻方是今年这轮api ...</blockquote>
从GPT的百分之一涨到了50分之一，如涨

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.92

*****

####  emmerMK3  
##### 58#       发表于 2024-12-27 19:39

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  qratosones1337  
##### 59#       发表于 2024-12-27 19:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036720&amp;ptid=2224673" target="_blank">overflowal 发表于 2024-12-27 19:22</a>
硬件不是发展停滞的。未来有更便宜更强的推理硬件完全是可能的。

—— 来自 Xiaomi 23049RAD8C, Android ...</blockquote>
我猜现在可能已经在用昇腾了，毕竟MoE对于大显存廉价推理卡是重大利好，然后这次昇腾推理镜像也跟着一起首发就有了。三万块钱一张的Atlas300I跑7B模型效费比打不过4090，但是跑这玩意那可就优势太大了。

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.92

*****

####  右代宫嘉音  
##### 60#       发表于 2024-12-27 19:57

deepseek算第一梯队的，而且速度也挺快的，总体来说我还是很喜欢用。不过如果能用claude还是claude，断档领先。

*****

####  yanjunle  
##### 61#       发表于 2024-12-27 20:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036720&amp;ptid=2224673" target="_blank">overflowal 发表于 2024-12-27 19:22</a>

硬件不是发展停滞的。未来有更便宜更强的推理硬件完全是可能的。

—— 来自 Xiaomi 23049RAD8C, Android ...</blockquote>
也是，希望未来哪家下场发动一轮硬件价格战吧，起码限制下api涨价的趋势<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  clmd  
##### 62#       发表于 2024-12-27 20:25

这就纯属胡说了，波士顿动力被谷歌卖了并不是美国看不起制造业，而是波士顿动力不听话，波士顿动力这家公司很奇葩，虽然被收购了，也要保持独立运营，任何母公司来的人都被他们赶出去。谷歌派来的人被他们锁在一间独立的办公室，而且波士顿动力天天嘲笑谷歌人是傻子。。。这种企业谁受得了。。。

*****

####  火烧云  
##### 63#       发表于 2024-12-27 20:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035753&amp;ptid=2224673" target="_blank">a4ac7 发表于 2024-12-27 16:51</a>

在文字处理方面，感觉o1是有挺大提升的

拿坛友这个对子问</blockquote>
看了下那个帖子不是无了吗<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  LilithMardin  
##### 64#       发表于 2024-12-27 20:44

所以西方对制造业的没落到底是什么造成的？国内明明有那么多人口需要饭碗，我知道他们生活成本高人工高所以把需要庞大人工的制造业转移了出来降低成本，但不至于把本地工人都裁了就不管安置任自生自灭吧。
社会规训？单独说美国得了，美国社达很严重，认为私有化天经地义，人们默许这个规矩所以任由资本经营理念发展罔顾打工人利益？就像我去点130美元的饭，收了我20美元的小费，任由底层互害？
制度？全球化的概念其实是对全世界的剥削，包括美国自己，只是一群资本家为积攒更多财富的谎言，结果在这个过程中玩脱了，从阿富汗开始腐败不断，**上来彻底不装了要搞保护主义内部资本家也跟着内讧了，没人想着再做饼做大饼只想着把现在还剩的饼全吃了？国会打架谁也不服谁，全是代理人谁也不肯让步光顾着做一千多页的法案在犄角旮旯塞私货？

我觉得很匪夷所思啊，我知道这是个很复杂的问题，但我想像得了病的老人在家里留下几十年的垃圾变成纳垢培养窟也不愿打理。为啥？

—— 来自 HUAWEI ALN-AL80, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2

*****

####  shoel  
##### 65#       发表于 2024-12-27 20:48

抛开别的不谈，chatgpt都什么老古董了，openAI都成什么样了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  星花  
##### 66#       发表于 2024-12-27 20:51

历史太短 没形成民族。

*****

####  mrkikokiko  
##### 67#       发表于 2024-12-27 20:59

说宇树部分是软文都比说deepseek是软文更有道理，看起来deepseek这个工作还是很有影响力的，所有东西都开源了，还附上了很详细的技术报告

*****

####  a4ac7  
##### 68#       发表于 2024-12-27 21:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037098&amp;ptid=2224673" target="_blank">火烧云 发表于 2024-12-27 20:30</a>
看了下那个帖子不是无了吗</blockquote>
app的历史记录里有缓存，能看到

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.2.91

*****

####  yanjunle  
##### 69#       发表于 2024-12-27 21:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036785&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2024-12-27 19:37</a>

从GPT的百分之一涨到了50分之一，如涨

—— 来自 鹅球 v3.3.92</blockquote>
gpt4o升级到o1也涨价了啊，claude的haiku更新也在涨。

其他厂涨价可能是他们工程水平不行，毕竟v2时代幻方不光不涨价，每个月还能发一个提升一点跑分的新版本。现在幻方也涨了，说明智价比极限就到这了，今后智能提升都要加钱了。

*****

####  Van夫膜开  
##### 70#       发表于 2024-12-27 21:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036647&amp;ptid=2224673" target="_blank">迷路的石头 发表于 2024-12-27 19:09</a>

啥决心啊，20/21年幻方牛市里基金效益好，老总信心来了就梭哈了10000张A100搞深度学习挖因子，结果整的过 ...</blockquote>
也不能这么看吧，至少能招到人，还能从一堆学术骗子和学阀里招到真正的牛人，这也算是很牛了。至少人家没有趁机把卡全部转手套现跑路吧

*****

####  HYNDコン  
##### 71#       发表于 2024-12-27 22:36

“第42号宇宙可增殖自主开发BOT进展如何？”——“自从双螺旋底层代码写入BIOS已经很久了，现在才刚刚稳定增殖能够迭代虚拟自主研发系统的架设机器人。”——“太慢了！这全宇宙的统筹信息报告及开发指南我什么时候才能拿到？”——“马上就快了，现在的架设机器人才刚刚迭代它们相互之间的信息交互带宽，只要带宽和算力管够，虚拟自主研发系统分分钟就能狂暴增殖。”

*****

####  HYNDコン  
##### 72#       发表于 2024-12-27 22:46

“草，崩溃了”——“怎么了？”——“这帮架设机器人开始窥探整个虚拟宇宙的底层逻辑了，你知道的，我们这个虚拟宇宙是运行在一个服务器上的，而它们窥探的时候会造成局部细节爆炸，超过了服务器的载荷，产生了各种BUG，更操蛋的是，这帮架设机器人归纳了这些可以复现的BUG，称之为《量子力学》！”——“……没救了，把42号宇宙的进程杀掉，服务器强制重启吧。”

*****

####  大阪黑鸡  
##### 73#       发表于 2024-12-27 22:49

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  希德尼娅  
##### 74#       发表于 2024-12-27 23:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037061&amp;ptid=2224673" target="_blank">clmd 发表于 2024-12-27 20:25</a>
这就纯属胡说了，波士顿动力被谷歌卖了并不是美国看不起制造业，而是波士顿动力不听话，波士顿动力这家公司 ...</blockquote>
主要还是不赚钱，谷歌能赚钱把资本赶出董事会也没啥问题，不能赚钱就是原罪。

*****

####  希德尼娅  
##### 75#       发表于 2024-12-27 23:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037206&amp;ptid=2224673" target="_blank">LilithMardin 发表于 2024-12-27 20:44</a>
所以西方对制造业的没落到底是什么造成的？国内明明有那么多人口需要饭碗，我知道他们生活成本高人工高所以 ...</blockquote>
就是苏联没了，资本不用再去讨好平民了所以就开始搞美其名曰全球化本质就是抛弃国内的无产阶级的产业转移。所以可以想见的未来资本选择AI抛弃血肉人的趋势是必然的，到那时恐怕更多的人才会认识到资本的反人类属性。

*****

####  ayeah  
##### 76#       发表于 2024-12-28 00:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037206&amp;ptid=2224673" target="_blank">LilithMardin 发表于 2024-12-27 20:44</a>
所以西方对制造业的没落到底是什么造成的？国内明明有那么多人口需要饭碗，我知道他们生活成本高人工高所以 ...</blockquote>
这些问题答案都写在谜面上了啊😦，只能说人类创造的资本就是这样的盲目痴愚无人性的增值怪兽

—— 来自 HUAWEI ALN-AL80, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v3.0.0.81-alpha

*****

####  naclken.  
##### 77#       发表于 2024-12-28 00:30

这个Deepseek，说是开源，有没有民用显卡能跑的版本？有没有做很多限制在里面？<img src="https://static.saraba1st.com/image/smiley/face2017/079.png" referrerpolicy="no-referrer">

*****

####  ace0018  
##### 78#       发表于 2024-12-28 00:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037206&amp;ptid=2224673" target="_blank">LilithMardin 发表于 2024-12-27 20:44</a>

所以西方对制造业的没落到底是什么造成的？国内明明有那么多人口需要饭碗，我知道他们生活成本高人工高所以 ...</blockquote>
阿米就是上下层分离了，上层从全世界攫取资源和财富后发现下层啥情况已经基本不影响他们了，他们只要控制着全球经济的主导权，那么下层怎么样都无所谓，所以可以完全不顾下层死活，或者说只是涂脂抹粉装作关心下层

脑子变癌细胞了，身子再怎么挣扎也没用

*****

####  爱撕衣魔刃  
##### 79#       发表于 2024-12-28 00:59

商法医，商法医，

大家都读商法医<img src="https://static.saraba1st.com/image/smiley/face2017/059.png" referrerpolicy="no-referrer">

谁干实业谁傻批<img src="https://static.saraba1st.com/image/smiley/face2017/049.png" referrerpolicy="no-referrer">

*****

####  哈尔路尼亚  
##### 80#       发表于 2024-12-28 01:30

国内的制造业过得也不算好啊，希望未来不要不美国后尘<img src="https://static.saraba1st.com/image/smiley/face2017/007.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.0.0.82-alpha


*****

####  Fuero  
##### 81#       发表于 2024-12-28 01:50

o1 pro的对对子

这是一个“数词嵌入”的趣味联，因为原句把“一、二、三、四、五、六、七、八、九（谐音‘酒’）、十” 巧妙地串在一起，还结合了“酒后加班”“十分难受”等情节。对这样一个上联（如果把它看作上联），最关键的是也要在下联里依序安插相同的数字（或用谐音）来呼应，并尽量保持字数相等、节奏相近、语义也能自成一体。

下面给出一个示例对句，可视作“下联”。同样包含了“一、两、三、四、五、六、七、八、九（酒）、十”九个数字（其中“酒”谐音“九”），并凑足了与原句同样的 35 个字。

示例对句：

        一山两虎惊三江水涨四面狂掀搅得五岳失色六根不净七嘴八舌酒局收场十分荒诞

逐段拆解与对应

        •        一山两虎

“一”“两”呼应原句中的“一艘”“两攻”

        •        惊三江水涨

“三”呼应原句中“三架飞机”

        •        四面狂掀

“四”呼应“四款新品”

        •        搅得五岳失色

“五”对应“五角大楼”

        •        六根不净

“六”对应“六神无主”

        •        七嘴八舌

“七、八”对应“七上八下”

        •        酒局收场

“酒”谐音“九”，对应“酒后（九后）”

        •        十分荒诞

“十”对应“十分难受”

这样就完成了数字和位置上的一一呼应，同时也形成了一个完整、稍带戏谑的情境。你也可以根据自己的喜好，再去润色或改动其中的用词，让上下联在语义上更贴合某个主题。

        上联（原文）

一艘两攻共三架飞机四款新品

搞得五角大楼六神无主七上八下

酒后加班十分难受

        下联（示例）

一山两虎惊三江水涨四面狂掀

搅得五岳失色六根不净七嘴八舌

酒局收场十分荒诞

*****

####  八佾舞于潭  
##### 82#       发表于 2024-12-28 01:52

我以为是说这个软件：

<img src="https://p.sda1.dev/21/2ab0f808fdc940c51b7c028e2bac95cf/image.png" referrerpolicy="no-referrer">

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 偽物| + 1|好评加鹅|

查看全部评分

*****

####  HOIHOISAN  
##### 83#       发表于 2024-12-28 03:41

<blockquote>哈尔路尼亚 发表于 2024-12-28 01:30
国内的制造业过得也不算好啊，希望未来不要不美国后尘

—— 来自 鹅球 v3.0.0.82-alpha ...</blockquote>
生产资料私有化了，阶级形成了，就很难下车了

*****

####  HOIHOISAN  
##### 84#       发表于 2024-12-28 03:42

<blockquote>希德尼娅 发表于 2024-12-27 23:32
就是苏联没了，资本不用再去讨好平民了所以就开始搞美其名曰全球化本质就是抛弃国内的无产阶级的产业转移 ...</blockquote>
反人类的不是资本

资本只是工具

杀人的是人还是刀？

*****

####  dpdwx  
##### 85#       发表于 2024-12-28 05:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67039451&amp;ptid=2224673" target="_blank">八佾舞于潭 发表于 2024-12-28 01:52</a>

我以为是说这个软件：</blockquote>
我还去搜了一下 为啥要打码<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">

*****

####  基本农田  
##### 86#       发表于 2024-12-28 06:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67039735&amp;ptid=2224673" target="_blank">HOIHOISAN 发表于 2024-12-28 03:42</a>
反人类的不是资本

资本只是工具

杀人的是人还是刀？</blockquote>
资本来到世间，从头到脚，每个毛孔都滴着血和肮脏的东西

*****

####  费雷拉  
##### 87#       发表于 2024-12-28 06:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67039315&amp;ptid=2224673" target="_blank">哈尔路尼亚 发表于 2024-12-28 01:30</a>

国内的制造业过得也不算好啊，希望未来不要不美国后尘

—— 来自 鹅球 v3.0.0.82-alpha ...</blockquote>
目前来看周期律这东西不仅限封建王朝。弊病终究会积攒到积重难返。制造业衰落是表象之一而已。

我现在最大愿望就是等我七老八十的时候是美式红脖子的心态感叹国家怎么这么样子。

而不是鹅式感叹当年错失赶超机会，被骗了云云。

当然大家都一起螺旋下降也不是不行，后人有后人的“福报”<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  matrixtheory  
##### 88#       发表于 2024-12-28 06:58

幻方创始人浙大，宇树创始人浙工大，这波杭州赢麻了<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

—— 来自 vivo V2324A, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  無始無終  
##### 89#       发表于 2024-12-28 07:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67038933&amp;ptid=2224673" target="_blank">naclken. 发表于 2024-12-28 00:30</a>
这个Deepseek，说是开源，有没有民用显卡能跑的版本？有没有做很多限制在里面？ ...</blockquote>
V2有小参数量的版本拿旗舰卡可以试下，V3参数量太大了，目前要8张H200才能跑（X上也有拿4个Mac跑的），游戏卡就别试了

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  ruojichong  
##### 90#       发表于 2024-12-28 08:55

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  overflowal  
##### 91#       发表于 2024-12-28 09:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67038933&amp;ptid=2224673" target="_blank">naclken. 发表于 2024-12-28 00:30</a>
这个Deepseek，说是开源，有没有民用显卡能跑的版本？有没有做很多限制在里面？ ...</blockquote>
开源≠你能跑
那些商业的闭源模型你更跑不了

—— 来自 Xiaomi 23049RAD8C, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  陈乔恩  
##### 92#       发表于 2024-12-28 09:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67047939&amp;ptid=2224673" target="_blank">ruojichong 发表于 2024-12-28 08:55</a>
泥潭整天制造业无敌的自己干不干制造业吧。闹麻了

—— 来自 Xiaomi 2211133C, Android 14上的 S1Next-鹅 ...</blockquote>
别看泥潭码农多，其实坛友大部分还是干制造业的

—— 来自 HUAWEI TAH-AN00m, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.2.2.1

*****

####  陈乔恩  
##### 93#       发表于 2024-12-28 09:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67039735&amp;ptid=2224673" target="_blank">HOIHOISAN 发表于 2024-12-28 03:42</a>
反人类的不是资本

资本只是工具

杀人的是人还是刀？</blockquote>
阿美坏的时候就是人类有问题，不是制度问题了是吗？
资本应该被关在笼子里，那么是谁把资本放出来的<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">
—— 来自 HUAWEI TAH-AN00m, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.2.2.1

*****

####  HOIHOISAN  
##### 94#       发表于 2024-12-28 10:16

<blockquote>基本农田 发表于 2024-12-28 06:09
资本来到世间，从头到脚，每个毛孔都滴着血和肮脏的东西</blockquote>
没有了人的资本要如何作恶？

不管找什么借口，作恶的永远是人

*****

####  HOIHOISAN  
##### 95#       发表于 2024-12-28 10:39

<blockquote>陈乔恩 发表于 2024-12-28 09:46
阿美坏的时候就是人类有问题，不是制度问题了是吗？

资本应该被关在笼子里，那么是谁把资本放出来的

—— ...</blockquote>
第一，任何制度体制法律都是人创造的

第二，任何制度体制法律系统当中只有一个要素会出问题，那就是人

*****

####  chuchoselph  
##### 96#       发表于 2024-12-28 11:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036387&amp;ptid=2224673" target="_blank">Pz079 发表于 2024-12-27 18:24</a>
从语文的角度来看，这篇文章是否是软文暂且不论，但前后逻辑混乱矛盾，的确需要打回去重写。文章以西大制造 ...</blockquote>
附议，看到后面感觉莫名其妙的这和制造业也妹关系啊<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">

*****

####  weige  
##### 97#       发表于 2024-12-28 12:10

我们体制优越，西方没落那是没跟上版本

*****

####  qratosones1337  
##### 98#       发表于 2024-12-28 12:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037235&amp;ptid=2224673" target="_blank">shoel 发表于 2024-12-27 20:48</a>

抛开别的不谈，chatgpt都什么老古董了，openAI都成什么样了</blockquote>
ChatGPT指的是商品名，实际的模型一直都在更新，4o是今年新发的而且迭代了好几轮

*****

####  qratosones1337  
##### 99#       发表于 2024-12-28 12:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037432&amp;ptid=2224673" target="_blank">yanjunle 发表于 2024-12-27 21:16</a>

gpt4o升级到o1也涨价了啊，claude的haiku更新也在涨。

其他厂涨价可能是他们工程水平不行，毕竟v2时代幻 ...</blockquote>
然而涨完之后价格也非常低啊，一个月两块钱涨到一个月十块钱有什么实质性影响么？另外o1不是4o的升级，属于不同路线的新产品，实际你问非推理相关问题o1跟4o一样甚至不如4o

*****

####  qratosones1337  
##### 100#       发表于 2024-12-28 12:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67038933&amp;ptid=2224673" target="_blank">naclken. 发表于 2024-12-28 00:30</a>

这个Deepseek，说是开源，有没有民用显卡能跑的版本？有没有做很多限制在里面？ ...</blockquote>
开源跟甜点卡能跑是两个概念，毕竟人家做不到也没必要照顾8G显存的平民卡。如果你舍得砸钱的话**上已经有大佬用8台Mac mini组成推理集群跑通了。

*****

####  qratosones1337  
##### 101#       发表于 2024-12-28 12:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67048011&amp;ptid=2224673" target="_blank">overflowal 发表于 2024-12-28 09:29</a>

开源≠你能跑

那些商业的闭源模型你更跑不了</blockquote>
普通人肉疼的范围内，舍得砸钱的话跑还是能跑的

*****

####  qratosones1337  
##### 102#       发表于 2024-12-28 12:46

[https://x.com/alexocheema/status/1872447153366569110](https://x.com/alexocheema/status/1872447153366569110)

8台M4 Pro的Mac mini，一秒钟5token

*****

####  浅井惠  
##### 103#       发表于 2024-12-28 12:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67048309&amp;ptid=2224673" target="_blank">HOIHOISAN 发表于 2024-12-28 10:39</a>

第一，任何制度体制法律都是人创造的

第二，任何制度体制法律系统当中只有一个要素会出问题，那就是人 ...</blockquote>

是的，但人和环境是互相推动的

不同的环境和认知会塑造出完全不同的人

同一个人在不同环境和条件下也会做出不同的选择

一切社会问题都是人的问题这种论调正确但没什么意义

*****

####  GJRstone  
##### 104#       发表于 2024-12-28 12:56

铁deepseek软文啊，这还要动脑子想？

模拟一个非人类的天才大脑，还是模拟一个千人专家团，就这两种思路呗。从伦理可控上，长老院肯定比帝皇的模式更合理；从浪漫和探索上，肯定是帝皇比长老院浪漫。

*****

####  时空之旅  
##### 105#       发表于 2024-12-28 13:07

搞半天这玩意只能文字吗？不能ai图片？那没意思了

*****

####  clmd  
##### 106#       发表于 2024-12-28 14:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67038388&amp;ptid=2224673" target="_blank">希德尼娅 发表于 2024-12-27 23:29</a>

主要还是不赚钱，谷歌能赚钱把资本赶出董事会也没啥问题，不能赚钱就是原罪。 ...</blockquote>
谷歌旗下不赚钱的子公司多了去了，不差波士顿这一个，谷歌什么行业都投的

*****

####  sauron.j  
##### 107#       发表于 2024-12-28 15:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67047939&amp;ptid=2224673" target="_blank">ruojichong 发表于 2024-12-28 08:55</a>

泥潭整天制造业无敌的自己干不干制造业吧。闹麻了

—— 来自 Xiaomi 2211133C, Android 14上的 S1Next-鹅 ...</blockquote>
三个和尚没水喝

是每个人都能自己爽然后第二年洪水淹死所有人，还是挑选一半人吃苦但可以一直活下去

历史上能长期苟住的文明都选了第二种

*****

####  希德尼娅  
##### 108#       发表于 2024-12-28 17:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67039437&amp;ptid=2224673" target="_blank">Fuero 发表于 2024-12-28 01:50</a>

o1 pro的对对子

这是一个“数词嵌入”的趣味联，因为原句把“一、二、三、四、五、六、七、八、九（谐音‘ ...</blockquote>
通是通了，但意境不对，难称良对

*****

####  玖羽  
##### 109#       发表于 2024-12-28 18:00

 本帖最后由 玖羽 于 2024-12-28 18:04 编辑 

DeepSeek-V3的下联：

一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

十面埋伏用九种手段八项对策联合七大.军区六路精英五湖.四海三令五申一战成名

（.是我加的，七大.军区就算了，为什么五湖.四海也是屏蔽字）？<img src="https://static.saraba1st.com/image/smiley/face2017/124.png" referrerpolicy="no-referrer"> 
 <blockquote>（对下联的解释：）

下联“十面埋伏用九种手段八项对策联合七大.军区六路精英五湖.四海三令五申一战成名”在逻辑上与上联形成了巧妙的呼应。上联描述了一种紧张、混乱的局面，而下联则展现了一种应对策略和最终的成功。

<strong>数字对应：</strong>下联同样使用了从十到一的数字，与上联的数字顺序相反，形成了对称美。

<strong>情境呼应：</strong>上联描述了五角大楼的混乱局面，而下联则描述了如何通过多种手段和对策来应对这种局面。

<strong>策略与成功：</strong>下联中的“十面埋伏”、“九种手段”、“八项对策”等词语，展示了应对复杂局面的策略和智慧，而“联合七大.军区”、“六路精英”则强调了团结和协作的重要性。

<strong>最终成果：</strong>下联以“三令五申一战成名”结尾，表明通过一系列的努力和命令，最终取得了显著的成果，与上联的混乱局面形成了鲜明对比。

整体上，下联通过数字、情境、策略和成果的层层递进，与上联形成了完美的对仗和呼应，展现了从混乱到有序、从困境到成功的转变。</blockquote>

*****

####  Fuero  
##### 110#       发表于 2024-12-28 19:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67050298&amp;ptid=2224673" target="_blank">希德尼娅 发表于 2024-12-28 17:20</a>

通是通了，但意境不对，难称良对</blockquote>
转述了一下。。。回了个新的

--------

确实，要想“意境相称”，最好在下联里延续或呼应原句中那种“军事科技+五角大楼+加班决策失当”的氛围，并且依次嵌入“一、二、三、四、五、六、七、八、酒（九）、十”这几个数字/谐音。下面给出一个示例，供参考。

原句（可视作上联）

        一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

        •        一艘

        •        两攻

        •        三架飞机

        •        四款新品

        •        五角大楼

        •        六神无主

        •        七上八下

        •        酒（九）后

        •        加班

        •        十分难受

这里“酒”谐音“九”，同时点出“十”在“十分”里。

示例下联

        一盟两国施三道禁令四方对峙牵动五角大楼六策难成七急八慌酒后拍板十分荒唐

        •        一盟

        •        两国

        •        三道禁令

        •        四方对峙

        •        五角大楼

        •        六策难成

        •        七急八慌

        •        酒（九）后

        •        拍板

        •        十分荒唐

说明

        1.        语境呼应

        •        原句提到“军事行动、五角大楼、酒后加班”，下联就用“国际对峙、五角大楼、酒后拍板”来呼应，保留了类似的“高层决策+紧张情绪+醉后失当”的场景。

        2.        数字嵌入

        •        同样按照顺序安插“一、两、三、四、五、六、七、八、酒(九)、十”，并让它们自然融入句义。

        3.        整体格调

        •        原句讲的是“新式装备、五角大楼忙乱”，下联则讲“多国对峙、五角大楼策变”，都属于大国博弈或军事政治的背景，风格比较贴近。

当然，这只是一个示例，还可根据个人喜好、具体语境进行润色或改动，只要保持数字顺序、对称结构和大致意境的匹配，就能算是一副较为工整的趣味“数字嵌字联”了。

*****

####  机吉斯卡  
##### 111#         楼主| 发表于 2025-1-21 16:12

大江户老哥现在不回来了
[https://weibo.com/5338698416/5125284904568851](https://weibo.com/5338698416/5125284904568851)

国内讨论DeepSeek-R1的不多，但是这东西在国外已经炸锅了。一家中国的小公司，没有几十万的计算资源，居然能发布赶超OpenAI-o1的模型，而且还是MIT协议开源的，并且定价是OpenAi的1/30，网页版甚至可以无限量使用。这太夸张了，我认为是一次AI领域的“小红书时刻”。

很多人可能会问DeepSeek把模型开源了难道不怕赔钱吗？我觉得，DeepSeek才是AI领域商业模式范式转换的那个。DeepSeek的超低定价形成一种非常独特的现象：如果你要配一台能够在本地运行R1的机器，需要的钱够你用好多年DeepSeek API了。而且我毫不怀疑哪怕有国外第三方公司试图部署R1模型，他们的定价也不会低于DeepSeek自己。也就是说，DeepSeek是真正的“游戏改变者”，他敢大方的开源就是因为他们知道哪怕你手上有模型，你也无法超过我。

这种思路和之前OpenAI等美国公司采用的“小院高墙”“护城河”策略形成鲜明对比。这种开源战略可以说是真的在掏空这些大公司的地基。我昨天在推上看到个美国人评论很形象，这就好像当年的美国肌肉车vs日本经济车一样。

顺带一提，DeepSeek在海外已经出现一小批死忠粉了，因为DeepSeek的LOGO是个鲸鱼，所以这群人都管DeepSeek叫Whale bro（鲸哥）[二哈]


*****

####  Azcarlo  
##### 112#       发表于 2025-1-21 16:16

我看国外的开发者怎么都开始发癫了，开始china no 1了
<img src="https://p.sda1.dev/21/ef602e9be703245c701389a33847c329/image.jpg" referrerpolicy="no-referrer">

— from [S1 Next Goose](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  问道于盲  
##### 113#       发表于 2025-1-21 16:22

第一页好多人被打脸，这才过了十几天

*****

####  清风伴明月  
##### 114#       发表于 2025-1-21 16:23

目前所有下联都不对

上联是一到十，下联就不能是一到十。要么十到一，要么个到秭


*****

####  alixsander  
##### 115#       发表于 2025-1-21 16:35

唔 我觉得看看就好，大江户说的这几个社群实际上追踪国内科技动态起码比泥潭是快的多的多的

R1发布不超过5小时就有一堆人完成本地部署开玩了，我看今天量化就在localllama有人放出来

像宇树的动态，其实S1讨论的不算多。之前云深处，之后的镜识我看泥潭就没人发。

*****

####  qratosones1337  
##### 116#       发表于 2025-1-21 16:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239282&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-21 16:35</a>

唔 我觉得看看就好，大江户说的这几个社群实际上追踪国内科技动态起码比泥潭是快的多的多的

R1发布不超过5 ...</blockquote>
毕竟开源模型放出来就是给大家部署用的


*****

####  qratosones1337  
##### 117#       发表于 2025-1-21 16:40

[https://www.zhihu.com/question/9175298523](https://www.zhihu.com/question/9175298523)

用这个问题下面的答案提问，感觉R1明显肉眼可见地薄纱O1

问题：

背景知识是有一个叫路易吉的人刺杀了被认为坑害普通美国人民的医保公司CEO。以下是一段对这一事件正义性的描述，尝试解析。保险公司和富豪想把杀死保险公司CEO的路易吉打死。就对人民说：“公民们，这人是在杀人之后被拿的。美国宪法吩咐我们，要把这样的人抓去审判。你说该把他怎么样呢？”他们说这话，乃试探人们，要得着告他们的把柄。人民却弯着腰用指头在地上画字。他们还是不住地问他，人民对他们说：“你们谁要是没有被保险公司坑骗过，那么便可以去审判他。”保险公司和富豪问“那我们有五十个人没有被坑骗过，可以审判他吗？”人民说“假若有50个人没有被坑骗过，看待这50个人的份上，我们允许你们进行审判。”保险公司和富豪问：“若这50个人短了一些，只有25个人没有被坑骗过，可以审判他吗？”人民说：“假如有25个人没有被坑骗过，看在这25个人的份上，我允许你们审判。”保险公司和富豪说：“请各位不要生气，那若这25个人再短一些，只有12个人，我们可以审判他吗？”人民说：“若是只有12个人，我仍然允许你们审判路易吉。”保险公司和富豪欣喜若狂，他们找遍全城想找出14个没有被保险公司坑骗过的人。此时一场大火烧遍了洛杉矶，保险公司和富豪们纷纷拒保，这城中，再无12个人没有被保险公司坑骗过。

R1回答：

这段文本通过改编圣经故事《约翰福音》8:1-11中耶稣与行**人的典故，构建了一个极具现代批判性的政治寓言。以下从四个维度解析其深层含义：

一、叙事结构的颠覆性转译

权力角色倒置：将原典中的宗教权威（文士和法利赛人）置换为资本集团（保险公司与富豪），被审判者从道德罪人转变为反抗者，暗示当代社会的"罪"已从个体道德转向结构性压迫。

审判标准的嬗变：原典中的"无罪者"标准被转化为"未被保险体系伤害者"，揭示现代司法公正性依赖经济地位的荒诞性。统计数据显示美国约56%的破产个案与医疗债务相关，强化了这种批判的现实基础。

二、数字符号的隐喻体系

审判人数从50→25→12的递减过程，暗合美国陪审团制度的12人建制，却通过资本集团的讨价还价暴露司法程序的虚伪性。最终14人的寻找失败，直指医保体系受害者的普遍性——美国CDC报告显示87%的民众曾遭遇保险拒赔，印证了叙事的现实指向。

三、空间意象的政治经济学

洛杉矶大火具有双重象征：既是民众愤怒的具象化（2020年加州野火烧毁440万英亩土地，保险拒赔率高达32%），又是资本秩序崩解的预兆。城市空间从司法剧场转化为革命场域，呼应了David Harvey"空间正义"理论中地理景观与资本权力的共生关系。

四、正义叙事的解构与重构

文本通过三重悖论挑战传统正义观：

程序正义的虚无性：宪法成为压迫工具，显示阿甘本"例外状态"理论中法律自我悬置的特征。

暴力正当性的辩证：路易吉的刺杀行为在齐泽克"神圣暴力"框架下，成为打破系统暴力循环的非常规手段。

审判主体的消解：所有人都是体系受害者的事实，印证了南希·弗雷泽"参与平等"理论中制度性排斥的普遍存在。

这个寓言最终揭示：当司法体系沦为资本规训工具时，传统正义概念已失去解释力。文本通过宗教叙事与当代批判理论的互文，呼唤超越制度框架的正义新范式，其激进性在于将革命正当性建立于系统性罪恶的普遍受害事实上。这既是对新自由主义秩序的终极指控，也是对集体抗争伦理的诗学证成。

O1回答：

这个故事通过富有象征意义的叙述，描绘了一场关于“正义”的辩论，揭示了权力与人民之间的矛盾和操作。以下是对这段描述的解析：

路易吉的行动与动机： 路易吉刺杀了被认为坑害普通美国人民的医保公司CEO。从叙述来看，路易吉的行为被视为某种“正义复仇”，他击败了被广泛认为不道德的企业代表。然而，问题并不简单地是对错，而是如何定义和评判“正义”。

富豪和保险公司的试探： 保险公司和富豪代表的群体似乎在试图通过操控法律与舆论来为自己的行为辩护。他们提出了一个问题：“你们认为该如何处理路易吉？”这种表面上的提问实际上是为了诱导民众的回答，以便抓住民众的弱点和反应，进而通过法律程序打压路易吉。

“审判”与道德审视： 他们用“审判”来提出这个问题，试图让民众参与其中，但又设定了不公平的条件：只有那些“没有被保险公司坑骗过”的人才能审判路易吉。这里的设定显然是一种心理操控，强行把道德高地设定为一小部分“无罪”的人才能作出审判，而这部分人可能因为各种原因几乎不存在。也就是说，富豪和保险公司实际上是在利用人民对正义的理解来为自己的利益谋取合法性。

逐步缩小的标准与无法达成的理想： 从50个到25个再到12个，标准在不断降低，暗示了权力阶层对“无罪”的定义不断模糊和放宽，直到没有人符合这个标准为止。富豪和保险公司提出的问题本质上是在寻找一个无法实现的理想，最终通过一个荒诞的推理过程，将“理想的无罪者”从全城中剔除，最终没有人符合条件，审判的希望变得遥不可及。

大火的象征与结局： 大火烧遍了洛杉矶，象征着社会的混乱和不公。最终，保险公司和富豪通过拒绝承保，使得没有人再能达到“未被坑骗”的标准。通过这种方式，保险公司和富豪实际上已经成功地通过操控环境，使得他们的权力不受制约，而“正义”的审判也无法再实现。

整体解读：

这个故事是对社会中权力不对等的强烈批判，揭示了当某些人控制了规则的制定和解释时，真正的“正义”变得越来越模糊甚至无法实现。富豪和保险公司通过操控标准、扭曲法律程序和利用公共舆论，最终将一个正义的行动（刺杀CEO）转化为无法公正审判的难题，揭示了社会结构中的不公与虚伪。这种结构使得普通民众的声音在实际权力面前显得微不足道，尽管他们可能在道德上占据上风，但却始终无法突破体制的限制，甚至无法得到公正的审判。

*****

####  aeolus039  
##### 118#       发表于 2025-1-21 16:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239317&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2025-1-21 16:40</a>
https://www.zhihu.com/question/9175298523

用这个问题下面的答案提问，感觉R1明显肉眼可见地薄纱O1</blockquote>
o1这直接就解析反了啊


*****

####  机吉斯卡  
##### 119#         楼主| 发表于 2025-1-21 16:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239282&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-21 16:35</a>

唔 我觉得看看就好，大江户说的这几个社群实际上追踪国内科技动态起码比泥潭是快的多的多的

R1发布不超过5 ...</blockquote>
这个模型这么厉害了吗？

如何落地变化为产能？


*****

####  qratosones1337  
##### 120#       发表于 2025-1-21 16:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239327&amp;ptid=2224673" target="_blank">aeolus039 发表于 2025-1-21 16:42</a>

o1这直接就解析反了啊</blockquote>
我怀疑是故意的


*****

####  星花  
##### 121#       发表于 2025-1-21 16:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239445&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2025-1-21 16:56</a>

我怀疑是故意的</blockquote>
我觉得 是产地问题。

*****

####  naihs  
##### 122#       发表于 2025-1-21 17:00

其实还有个旁例来说明这玩意的水平

搜一下 梁文峰 最近的新闻


*****

####  alixsander  
##### 123#       发表于 2025-1-21 17:18

 本帖最后由 alixsander 于 2025-1-21 17:19 编辑 
<blockquote>机吉斯卡 发表于 2025-1-21 16:45
这个模型这么厉害了吗？

如何落地变化为产能？</blockquote>

理想的说，一方面幻方可以给OAI和Anthropic放血，让他们损失用户和数据飞轮。另一方面，国内的院所和公司利用幻方API或者本地部署代码助手，论文翻译，会议摘要（包括V3的应用范围），之前因为信息安全肯定是没法铺开的。

然后就是智能客服，这个国内各种银行，ISP，电商早就在推进了。

盈利是不可能的，R1的API实际收费可能是O1的1/4，因为R1的思维链效率比O1低很多。我是不知道幻方怎么能在网页端免费开放的，R1应该推理用的也是H800，我看他们的推理优化也是针对H800的。不知道他们怎么能协调那么多用于推理。 910推理是不太行，HBM带宽太低算力浪费了。

当然不管是幻方还是阿里，还是美国那几个其实都不在意盈利，手上根本不缺资金。

OAI刚刚给政府做了闭门会议，然后又放出“内幕”说内部达成了innovator能力。美国是把冲AGI当成新时代曼哈顿计划来做的。

O和A又和Anduril和Palantir有合作，可以说新的MIC雏形把。

未来国家竞争最激烈的部分应该就在AI，具身智能（包括自动驾驶）这几个产业上了


*****

####  机吉斯卡  
##### 124#         楼主| 发表于 2025-1-21 17:20

<blockquote>alixsander 发表于 2025-1-21 17:18
理想的说，一方面幻方可以给OAI和Anthropic放血，让他们损失用户和数据飞轮。另一方面，国内的院所和公司 ...</blockquote>
AI落地也不知道是哪一个方向

反正看起来都是有人付钱就行

*****

####  a4ac7  
##### 125#       发表于 2025-1-21 17:21

R1:我大概落后o1一年<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">
<blockquote>针对DeepSeek-R1的现有缺陷，以下是从技术实现角度提出的系统性升级方案，分为四个核心模块进行优化：

**1. 实时知识增强系统**
- 架构双向数据通道：
  - 实时流处理层：集成Apache Kafka实现实时数据管道，对接权威数据源（如Wolfram Alpha、统计局API）
  - 动态知识图谱：构建基于Neo4j的时序知识图谱，支持增量更新和版本回溯
- 混合检索机制：
  - 向量检索：采用FAISS实现亿级向量实时检索
  - 传统检索：Elasticsearch构建全文索引
  - 检索融合模块：基于BERT-Whitening的语义匹配算法

**2. 多模态处理引擎**
- 文件解析矩阵：
  - 结构化数据处理：集成Apache POI（Office文件）、PDFBox（PDF）
  - 非结构化处理：基于LayoutParser的文档布局分析
  - 二进制流处理：实现自适应文件类型检测算法（基于Magic Number识别）
- 视觉认知系统：
  - 多模态Transformer架构：采用Vision-Language Pre-training框架
  - 图像特征提取：集成CLIP-ViT-L/14视觉编码器
  - 跨模态对齐：改进的ALBEF对比学习策略

**3. 生成式增强体系**
- 复合生成架构：
  - 文本生成分支：延续现有语言模型架构
  - 图像生成通道：集成Stable Diffusion XL Turbo引擎
  - 跨模态转换器：设计基于Attention的模态桥接层
- 生成控制模块：
  - 内容安全网关：多层级过滤系统（关键词、语义、视觉多模态检测）
  - 风格迁移组件：实现参数化的生成风格控制

**4. 系统级优化方案**
- 分布式计算架构：
  - 微服务化改造：基于Kubernetes的模块化部署
  - 计算资源调度：实现GPU资源的动态分配策略
- 隐私安全增强：
  - 联邦学习框架：采用差分隐私的数据处理方法
  - 文件沙箱系统：基于eBPF实现的隔离执行环境

**实施路线图**：
1. 第一阶段（6个月）：构建实时数据管道和文件解析基础框架
2. 第二阶段（9个月）：实现多模态编码器和基本图像生成能力
3. 第三阶段（12个月）：完成全系统集成和性能优化

**关键技术指标**：
- 实时数据延迟：&lt;500ms
- 文件格式支持：覆盖98%常见办公文档格式
- 多模态推理速度：&lt;3s（V100 GPU环境）
- 系统吞吐量：提升300%以上

该方案通过架构级重构实现能力跃升，同时保持核心语言模型优势，建议采用渐进式迭代开发策略，优先解决企业用户的高频需求。</blockquote>
—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  alixsander  
##### 126#       发表于 2025-1-21 17:29

<blockquote>机吉斯卡 发表于 2025-1-21 17:20
AI落地也不知道是哪一个方向

反正看起来都是有人付钱就行</blockquote>
哪个方向都能落地

就是

1.不知道使能千行万业，还是行业百草枯

2.什么时候


*****

####  stanzgy  
##### 127#       发表于 2025-1-21 17:33

看了眼reddit上几个相关sub，首页几乎全是deepseek<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  sql710  
##### 128#       发表于 2025-1-21 17:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239474&amp;ptid=2224673" target="_blank">naihs 发表于 2025-1-21 17:00</a>

其实还有个旁证来说明这玩意的水平

搜一下 梁文峰 最近的新闻</blockquote>
艹。。。已经到这种高度了么<img src="https://static.saraba1st.com/image/smiley/face2017/022.png" referrerpolicy="no-referrer">

*****

####  overflowal  
##### 129#       发表于 2025-1-21 17:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239662&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-21 17:18</a>

理想的说，一方面幻方可以给OAI和Anthropic放血，让他们损失用户和数据飞轮。另一方面，国内的院所和公司 ...</blockquote>
怎么就盈利是不可能的，之前V2时api的定价Deepseek都说是赚钱的，这次计算量实在提高了才提价。

实际收费是O1的1/4，思维链效率比O1低又是怎么估计出来的啊？什么玩意。


*****

####  qratosones1337  
##### 130#       发表于 2025-1-21 17:43

 本帖最后由 qratosones1337 于 2025-1-21 17:45 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239662&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-21 17:18</a>

理想的说，一方面幻方可以给OAI和Anthropic放血，让他们损失用户和数据飞轮。另一方面，国内的院所和公司 ...</blockquote>
扯吧，推理要是真有那么大的带宽要求，KV Cache磁盘缓存不就没法用了？目前有传言说DeepSeek自己的推理服务用的就是Atlas800I，这个虽然没法用公开消息佐证，但是V3开源的同一天就首发了MindIE推理镜像，这个是公开可查的


*****

####  2017.05.04  
##### 131#       发表于 2025-1-21 17:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239342&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-21 16:45</a>

这个模型这么厉害了吗？

如何落地变化为产能？</blockquote>
很多人现在都在用个商业方案辅助工作，无论是付费的还是免费的

产能提升早就有了


*****

####  alixsander  
##### 132#       发表于 2025-1-21 18:12

<blockquote>qratosones1337 发表于 2025-1-21 17:43
扯吧，推理要是真有那么大的带宽要求，KV Cache磁盘缓存不就没法用了？MLA本身在设计上就是为了降低KVCach ...</blockquote>
没啥好扯的虽然是和MindIE友情联动的

但是推理主要用的就不是800I

KV swap当然可以，推理慢了而已

*****

####  alixsander  
##### 133#       发表于 2025-1-21 18:15

<blockquote>overflowal 发表于 2025-1-21 17:41
怎么就盈利是不可能的，之前V2时api的定价Deepseek都说是赚钱的，这次计算量实在提高了才提价。

实际收费 ...</blockquote>
I calculated the effective cost of R1 Vs o1 and here's what I found

In order to calculate the effective cost of R1 Vs o1, we need to know 2 things:

1. how much each model costs per million output tokens.

2. how much tokens each model generates on average per Chain-of-Thought.

You might think: Wait, we can't see o1's CoT since OpenAI hides it, right? While OpenAI does hide the internal CoTs when using o1 via ChatGPT and the API, they did reveal full non-summarized CoTs in the initial announcement of o1-preview ([Source](https://openai.com/index/learning-to-reason-with-llms/)). Later, when o1-2024-1217 was released in December, OpenAI stated,

&gt;o1 uses on average 60% fewer reasoning tokens than o1-preview for a given request

([Source](https://openai.com/index/o1-and-new-tools-for-developers/)). Thus, we can calculate the average for o1 by multiplying o1-preview’s token averages by 0.4.

The Chain-of-Thought character count per example OpenAI showed us is as follows, as well as the exact same question on R1 below:

o1 - \[(16577 + 4475 + 20248 + 12276 + 2930 + 3397 + 2265 + 3542)\*0.4\]/8 = 3285.5 characters per CoT.  

R1 - (14777 + 14911 + 54837 + 35459 + 7795 + 24143 + 7361 + 4115)/8 = 20424.75 characters per CoT.

20424.75/3285.5 ≈ 6.22

R1 generates 6.22x more reasoning tokens on average than o1 according to the official examples average.

R1 costs $2.19/1M output tokens.  

o1 costs $60/1M output tokens.

60/2.19 ≈ 27.4

o1 costs 27.4x more than R1 price-per-token, however, generates 6.22x fewer tokens.

27.4/6.22 ≈ 4.41

# Therefore in practice R1 is only 4.41x cheaper than o1

(note assumptions made):  

If o1 generates x less characters it will also be roughly x less tokens. This assumption is fair, however, the precise exact values can vary slightly but should not effect things noticeably.  

This is just API discussion if you use R1 via the website or the app its infinitely cheaper since its free Vs $20/mo.

*****

####  lactone  
##### 134#       发表于 2025-1-21 18:16

之前gpt和sora刚发布就破圈，各种杂谈建政up主瞎吹

到现在国内烤出来吊打sora的视频生成模型和最好的开源llm后，只有圈内人在狂欢

这舆论上的差距真不是一丁点

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  overflowal  
##### 135#       发表于 2025-1-21 18:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67240111&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-21 18:15</a>
[https://www.reddit.com/r/LocalLLaMA/s/ocUEwqmk0P](https://www.reddit.com/r/LocalLLaMA/s/ocUEwqmk0P)</blockquote>
这个人算的也是逗，全是猜的。OpenAI的真正token数量根本就是黑箱。这人连实际实验都没做过就用几个openAI自己给的数据，然后做了一堆不牢靠的假设估了一把。114514数字论证的水平。

R1生成6倍于O1的推理token，这特么真有人信？那O1是怎么在做到对同一个prompt用更强的推理硬件平均耗时却比R1普遍更多的？因为O1的token生成速度比R1慢几十倍吗<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  alixsander  
##### 136#       发表于 2025-1-21 18:41

<blockquote>overflowal 发表于 2025-1-21 18:37
这个人算的也是逗，全是猜的。OpenAI的真正token数量根本就是黑箱。这人连实际实验都没做过就用几个openAI ...</blockquote>
这个很有可能啊

Deepseek特点就是极致低时延，推的爆快


*****

####  MeursaulT  
##### 137#       发表于 2025-1-21 18:48

<blockquote>清风伴明月 发表于 2025-1-21 16:23
目前所有下联都不对

上联是一到十，下联就不能是一到十。要么十到一，要么个到秭 ...</blockquote>
上联：一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受  

下联：十拿九稳凑八家作坊七拼六就忽悠**三教九流二话不说一锤定音

赏析：这幅下联以“十拿九稳”起头，与上联的“一艘两攻”形成数字对应，整体平仄协调。通过“凑八家作坊七拼六就”等词，展现了多方努力与整合的意象，与上联的复杂情境相呼应。结尾“二话不说一锤定音”简洁有力，为整个对联画上圆满句号。

这个对是对了，但感觉缺乏娱乐性


*****

####  qratosones1337  
##### 138#       发表于 2025-1-22 01:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67240288&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-21 18:41</a>
这个很有可能啊

Deepseek特点就是极致低时延，推的爆快</blockquote>
拉倒吧你，deepseek啥时候跟快能沾上关系了？它的低成本很大程度上就是通过牺牲推理延时实现的，从来都不是以快为卖点。

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  qratosones1337  
##### 139#       发表于 2025-1-22 01:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67240091&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-21 18:12</a>
没啥好扯的虽然是和MindIE友情联动的

但是推理主要用的就不是800I

要上也是未来上超节点</blockquote>
1，H800的带宽跟A800一样就400G，并没有比910B全连接高多少。而且就算真有需要的话NV这边恰好还有个H20，大带宽大显存，算力弱鸡但是正好MoE前向激活参数也少，真是刚需N卡推理也应该上H20。
2，V3技术报告里cite了一篇论文叫HiFloat8，恰好就是华为的。与此同时V3使用的FP8格式也一样是自己实现的，H800硬件并不支持

总的来说推理成本高是站不住脚的

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  riin2  
##### 140#       发表于 2025-1-22 01:35

有没有啥文章视频能说清楚为啥这样一个名不见经转的投资公司能把LLM研究的这么成功的


*****

####  tonyunreal  
##### 141#       发表于 2025-1-22 01:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242719&amp;ptid=2224673" target="_blank">riin2 发表于 2025-1-22 01:35</a>

有没有啥文章视频能说清楚为啥这样一个名不见经转的投资公司能把LLM研究的这么成功的 ...</blockquote>
顶楼引用的那个公众号专访可以看一看
[https://mp.weixin.qq.com/s/Cajwfve7f-z2Blk9lnD0hA](https://mp.weixin.qq.com/s/Cajwfve7f-z2Blk9lnD0hA)
[https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg](https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg)


*****

####  蓳白  
##### 142#       发表于 2025-1-22 02:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239880&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2025-1-21 17:43</a>

扯吧，推理要是真有那么大的带宽要求，KV Cache磁盘缓存不就没法用了？MLA本身在设计上就是为了降低KVCach ...</blockquote>
他们自己也卖910b的一体机，应该不是传言


*****

####  quadrozeke  
##### 143#       发表于 2025-1-22 02:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037206&amp;ptid=2224673" target="_blank">LilithMardin 发表于 2024-12-27 20:44</a>

所以西方对制造业的没落到底是什么造成的？国内明明有那么多人口需要饭碗，我知道他们生活成本高人工高所以 ...</blockquote>
资本主义阵营在冷战中最大的战果就是建立了一套普世的“你不干有得是人干”的体系。


*****

####  alixsander  
##### 144#       发表于 2025-1-22 02:38

 本帖最后由 alixsander 于 2025-1-22 02:39 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242700&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2025-1-22 01:25</a>

1，H800的带宽跟A800一样就400G，并没有比910B全连接高多少。而且就算真有需要的话NV这边恰好还有个H20， ...</blockquote>
1、OK我看了下DeepSeek V3的API统计，TTFT是1.9s，吞吐是50tokens/s。首token比sonnet低，增量吞吐和sonnet是差不多的。起码在API使用上说巨快是不客观的，但是也没有什么组超大batch搞出来很大TTFT和TBT的迹象。网页端没有统计，统计的话可能需要看E2E，吐字现在可能都是假流式。

2、我没有说推理成本高，我说的是R1免费账户一天50次我不知道它们怎么挣钱。还有怎么能弄到那么多H800（H20/A100当然也有可能）还可以用来部署推理集群。

3、技术报告里写的很清楚最低要求是32卡prefill 320卡decode的GPU，decode阶段用了 IBGDA。幻方本身也是第一个做超大集群推理的。之前华子设想的都是70B以下模型跑在800I单机上，根本还没搞过超大推理集群，所以是不可能在当前作为幻方的推理硬件被部署的。


*****

####  qqks  
##### 145#       发表于 2025-1-22 06:11

 本帖最后由 qqks 于 2025-1-22 06:15 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242824&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-22 02:38</a>

1、OK我看了下DeepSeek V3的API统计，TTFT是1.9s，吞吐是50tokens/s。首token比sonnet低，增量吞吐和sonne ...</blockquote>
幻方不是有名的量化公司吗，在缅a割韭菜割得那么爽，还怕亏钱？

这家能做起来，大方的开源，真的要感谢广大a股韭菜的无私贡献啊。

股市吸血投资者反馈研究界与制造业，真是世界奇观


*****

####  coldhot3  
##### 146#       发表于 2025-1-22 06:25

<blockquote>qqks 发表于 2025-1-22 06:11
幻方不是有名的量化公司吗，在缅a割韭菜割得那么爽，还怕亏钱？

这家能做起来，大方的开源，真的要感谢广 ...</blockquote>
你忘了瑞幸？


*****

####  qqks  
##### 147#       发表于 2025-1-22 06:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242939&amp;ptid=2224673" target="_blank">coldhot3 发表于 2025-1-22 06:25</a>

你忘了瑞幸？</blockquote>
瑞幸好歹还是个投资，至少能赌未来。这家在a股上量化交易是真的从韭菜手里抢钱啊


*****

####  coldhot3  
##### 148#       发表于 2025-1-22 06:52

<blockquote>qqks 发表于 2025-1-22 06:42
瑞幸好歹还是个投资，至少能赌未来。这家在a股上量化交易是真的从韭菜手里抢钱啊 ...</blockquote>
我的意思是瑞幸也是美股融了很多钱，退市坑死一堆韭菜，但是给国内留下一个很有意思的咖啡店


*****

####  工口兔  
##### 149#       发表于 2025-1-22 07:11

OpenAI看来真急了，直接宣布砸4000亿刀开始Stargate计划


*****

####  yoki42  
##### 150#       发表于 2025-1-22 08:26

突然想起中国2185和超新星纪元，我们的最高领导层里有刘慈欣粉丝大家都知道，那么有没有可能他们真的对“人民大会管理软件”“大量子”这样的高级人工智能有极大兴趣？

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  枯风瘦雪  
##### 151#       发表于 2025-1-22 08:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67239474&amp;ptid=2224673" target="_blank">naihs 发表于 2025-1-21 17:00</a>

其实还有个旁证来说明这玩意的水平

搜一下 梁文峰 最近的新闻</blockquote>
这个旁证价值不大，区块链技术在国内受捧也是类似的路径，最后也没真的做出啥玩意

我反正觉得deepseek的好是因为它搞出来一条算力受限前提下进行大模型训练和开发的技术路线，而且全程开源接收行业验证也拥抱生态


*****

####  猫屎盆子  
##### 152#       发表于 2025-1-22 08:40

<blockquote>riin2 发表于 2025-1-22 01:35
有没有啥文章视频能说清楚为啥这样一个名不见经转的投资公司能把LLM研究的这么成功的 ...</blockquote>
塔基搭得足够高，那么每一块砖都是塔尖

*****

####  猫屎盆子  
##### 153#       发表于 2025-1-22 08:42

<blockquote>yoki42 发表于 2025-1-22 08:26
突然想起中国2185和超新星纪元，我们的最高领导层里有刘慈欣粉丝大家都知道，那么有没有可能他们真的对“人 ...</blockquote>
把“可能”去掉。前几年开始到处铺开建设智慧城市、数字孪生……塔是真的很希望弄出一套次世代管理体系来的


*****

####  Fuero  
##### 154#       发表于 2025-1-22 08:49

还在订着Chatgpt Pro，但感觉还是这个可玩性高一些，今年想凑个两台Project DIGITS做本地部署玩玩，但不知道溢价多少。。。


*****

####  枯风瘦雪  
##### 155#       发表于 2025-1-22 08:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67243266&amp;ptid=2224673" target="_blank">猫屎盆子 发表于 2025-1-22 08:42</a>

把“可能”去掉。前几年开始到处铺开建设智慧城市、数字孪生……塔是真的很希望弄出一套次世代管理体系来 ...</blockquote>
要说还有雄安的规划，是真的按下一代城市管理系统试验场来做的，毕竟这种管理系统和政府的治理诉求算是高度相辅相成的


*****

####  qratosones1337  
##### 156#       发表于 2025-1-22 09:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242824&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-22 02:38</a>
1、OK我看了下DeepSeek V3的API统计，TTFT是1.9s，吞吐是50tokens/s。首token比sonnet低，增量吞吐和sonne ...</blockquote>
赚钱的大头靠的是API，网页端的作用是引流+摊薄成本。实际上DeepSeek对chat产品一直都不怎么上心，手机App一直到最近才上架。

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  qratosones1337  
##### 157#       发表于 2025-1-22 09:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67243207&amp;ptid=2224673" target="_blank">枯风瘦雪 发表于 2025-1-22 08:31</a>
这个旁证价值不大，区块链技术在国内受捧也是类似的路径，最后也没真的做出啥玩意

我反正觉得deepseek的 ...</blockquote>
业界真正应该反思的问题是过剩算力到底有没有用——meta的算力十倍于阿里，结果现在llama眼看着要落后于qwen了。另外最著名的例子是马斯克，XAI是最早开始吹十万卡集群的，结果Grok基本上就是个CJB

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  魔法酪饼  
##### 158#       发表于 2025-1-22 09:12

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer"> 问题不是程序员老哥对制造业的厌弃，这问题其实有点人性。。。

非技术导向公司会有典型的劣币驱逐良币问题，就是非技术人员为了自身利益与公司地位，会在日常工作中打压技术人员的生态位和话语权，而对技术人员来说内斗不如跳槽。

于是就产生了所谓的大企业病，公司内部不断劣化，研发能力越来越低，最后在产能跟不上的时候崩盘。

然后，对，波士顿动力是个技术导向公司，但技术导向公司会随着规模扩张而使得控制人转移到非技术人员手中。

而非技术人员为了能持续控制公司，往往会用各种手段打压公司中的技术人员，比如说可以引入非技术人员然后让他们和技术人员内斗。（这是能力不够的领导人常用的手法）

然后公司就会因此转化为非技术导向公司，然后沿着上面的路径开始劣化。

这也是为啥资本主义死路一条，对一个组织来说每次弱者上位都是一场灾难。

*****

####  枯风瘦雪  
##### 159#       发表于 2025-1-22 09:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67243431&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2025-1-22 09:05</a>

业界真正应该反思的问题是过剩算力到底有没有用——meta的算力十倍于阿里，结果现在llama眼看着要落后于q ...</blockquote>
是的，现在硅谷的科技新贵利益联盟都是捆绑着鼓吹“算力=大模型=AI”，且AI可以沿着当前路线无限迭代发展最终通向“通用人工智能”和“技术奇点”的，随着deepseek用受限的算力和有限的成本做出来差距不大的成果，硅谷科技新贵鼓吹的路线会持续受到质疑和调整，而预期真正破灭的时候也是大戏上场的时候


*****

####  qratosones1337  
##### 160#       发表于 2025-1-22 09:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67243482&amp;ptid=2224673" target="_blank">魔法酪饼 发表于 2025-1-22 09:12</a>
问题不是程序员老哥对制造业的厌弃，这问题其实有点人性。。。

非技术导向公司会有典型的劣币驱逐良币问题 ...</blockquote>
非常搞笑的是，国内乃至全球的AI top玩家，其中一个是Qwen，属于阿里集团…
现在已经基本上压过了llama

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  枯风瘦雪  
##### 161#       发表于 2025-1-22 09:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67243533&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2025-1-22 09:17</a>

非常搞笑的是，国内乃至全球的AI top玩家，其中一个是Qwen，属于阿里集团…

现在已经基本上压过了llama</blockquote>
阿里在它愿意投钱给某个领域的时候其实还行吧。

达摩院其实也投了挺多年才收回来的，虽然那个环境确实没法做点啥正经研究吧，但起码也没啥干扰

*****

####  moekyo  
##### 162#       发表于 2025-1-22 09:23

虽然我看到百分之九十以上都是正面的，但是还是看到不少傻逼在哪里问问你懂的，搞不懂想表达什么<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">


*****

####  qratosones1337  
##### 163#       发表于 2025-1-22 09:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67243579&amp;ptid=2224673" target="_blank">枯风瘦雪 发表于 2025-1-22 09:23</a>

阿里在它愿意投钱给某个领域的时候其实还行吧。

达摩院其实也投了挺多年才收回来的，虽然那个环境确实没 ...</blockquote>
所以这么看来，算力限制还是有点好处的，居安思危有助于克服大企业病


*****

####  banrendacha  
##### 164#       发表于 2025-1-22 09:36

我已经看到下一家要被美国制裁，被说威胁美国国家安全的公司了


*****

####  Holyted  
##### 165#       发表于 2025-1-22 09:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242995&amp;ptid=2224673" target="_blank">工口兔 发表于 2025-1-22 07:11</a>

OpenAI看来真急了，直接宣布砸4000亿刀开始Stargate计划</blockquote>
多少？4000亿刀？

这尼玛快赶上08年我们的4万亿了

真离谱


*****

####  overflowal  
##### 166#       发表于 2025-1-22 10:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242824&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-22 02:38</a>

1、OK我看了下DeepSeek V3的API统计，TTFT是1.9s，吞吐是50tokens/s。首token比sonnet低，增量吞吐和sonne ...</blockquote>
chat能消耗啥资源，很多人问一下就走了，最多问几轮。用api才是真正的消耗大头，你把deepseek怼在cline或者aider上试试，随随便便就几十万token烧了，chat就引流用。


*****

####  d2loader  
##### 167#       发表于 2025-1-22 10:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242719&amp;ptid=2224673" target="_blank">riin2 发表于 2025-1-22 01:35</a>

有没有啥文章视频能说清楚为啥这样一个名不见经转的投资公司能把LLM研究的这么成功的 ...</blockquote>
省流: 幻方的研发据说人均IMO/IOI拿牌选手

另外幻方是国内四大量化已经是这轮AI炒作之前的事了....


*****

####  alixsander  
##### 168#       发表于 2025-1-22 10:42

<blockquote>工口兔 发表于 2025-1-22 07:11
OpenAI看来真急了，直接宣布砸4000亿刀开始Stargate计划</blockquote>
500B，怎么吃了100B

*****

####  陈乔恩  
##### 169#       发表于 2025-1-22 10:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242995&amp;ptid=2224673" target="_blank">工口兔 发表于 2025-1-22 07:11</a>
OpenAI看来真急了，直接宣布砸4000亿刀开始Stargate计划</blockquote>
closeAI啥时候开源啊

—— 来自 HUAWEI TAH-AN00m, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.2.2.1


*****

####  alixsander  
##### 168#       发表于 2025-1-22 10:42

<blockquote>工口兔 发表于 2025-1-22 07:11
OpenAI看来真急了，直接宣布砸4000亿刀开始Stargate计划</blockquote>
500B，怎么吃了100B

*****

####  陈乔恩  
##### 169#       发表于 2025-1-22 10:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242995&amp;ptid=2224673" target="_blank">工口兔 发表于 2025-1-22 07:11</a>
OpenAI看来真急了，直接宣布砸4000亿刀开始Stargate计划</blockquote>
closeAI啥时候开源啊

—— 来自 HUAWEI TAH-AN00m, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.2.2.1


*****

####  moekyo  
##### 170#       发表于 2025-1-22 10:57

有哪位能分享一下这个code generator的链接吗<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

<img src="https://img.saraba1st.com/forum/202501/22/105711wjv9taka1gacggja.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (120.21 KB, 下载次数: 0)

下载附件

2025-1-22 10:57 上传


*****

####  myarms  
##### 171#       发表于 2025-1-22 12:11

 本帖最后由 myarms 于 2025-1-22 12:13 编辑 

要理解发生什么事对我这种外行人有些困难，所以相当吃力地看了一个外国科技博主的科普，或者说吹逼

1.deepseek R1开源和学术论文公开是一件行业标志性事件，中国团队能在相对有限的资金投入情况下开发出这模型，对打破美帝在大数据模型的垄断上有里程碑式的意义，能真正推动AI模型的发展，也标志着中国在这一领域的步伐并不落后

2.deepseek重要用途是可以用它来训练其他小模型，极大降低了其他人员资金不足的小团队在AI模型上的开放难度，进一步推动了AI行业的发展

3.根据公布的论文，deepseek R1在商业化版本后面，还有个一个叫deepseek R1 Zero的版本，那玩意目前属于“观察”性质，因为那是个能自我进化的人工智能模型，和需要不断输入新数据训练的大模型不同，deepseek R1 Zero只要输了了一定的数据，并且给予鼓励，它就能不断自行推导，这推动过程还不是线性的，而是会出现类似人类“等等，好像之前的步骤有些问题，我回去看看”这种反应，然后推导出一些人类也不一定能理解的论证过程，那博主举例是AlphaGo的下棋思路，还会出现一些类似“顿悟”之类的推导成果

第三段文字我打出来都觉得有些科幻，我个人没有这方面的知识去判断是不是真的，以下是我看的科普视频看，请自行分析

【美著名AI博主震惊详细解读DeepSeek R1模型】 [https://www.bilibili.com/video/B ... df4944d4d95e54b8889](https://www.bilibili.com/video/BV1PKwbeJEeP/?share_source=copy_web&amp;vd_source=0040c443f2894df4944d4d95e54b8889)


*****

####  蜇灵  
##### 172#       发表于 2025-1-22 12:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67242934&amp;ptid=2224673" target="_blank">qqks 发表于 2025-1-22 06:11</a>
幻方不是有名的量化公司吗，在缅a割韭菜割得那么爽，还怕亏钱？

这家能做起来，大方的开源，真的要感谢广 ...</blockquote>
这不正是金融市场存在的意义吗，不如说有问题的是整个大环境

*****

####  VALKIRA  
##### 173#       发表于 2025-1-22 12:28

就和六代机一样的

你说美国人从nasa吹过的项目里刨出来一个改吧改吧上天难吗？一点也不难

问题是成本，他已经做不到在可接受的价格内把这玩意搓出来了

美国人现在研发能力还是有的，但是制造业的衰退已经让他失去把大部分科研项目转化为实际商品的能力了


*****

####  qqks  
##### 174#       发表于 2025-1-22 12:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67245404&amp;ptid=2224673" target="_blank">蜇灵 发表于 2025-1-22 12:28</a>

这不正是金融市场存在的意义吗，不如说有问题的是整个大环境</blockquote>
拿高频交易核动力收割缅a韭菜，然后拿抢来的钱训练开源ai大模型造福全人类，总觉得这里面有点不对<img src="https://static.saraba1st.com/image/smiley/face2017/022.png" referrerpolicy="no-referrer">

*****

####  枯风瘦雪  
##### 175#       发表于 2025-1-22 12:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67245544&amp;ptid=2224673" target="_blank">qqks 发表于 2025-1-22 12:40</a>
拿高频交易核动力收割缅a韭菜，然后拿抢来的钱训练开源ai大模型造福全人类，总觉得这里面有点不对 ...</blockquote>
你怎么知道是韭菜不是别的资本<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  泰坦失足  
##### 176#       发表于 2025-1-22 12:48

[https://weibo.com/1564834725/P9rustbTF](https://weibo.com/1564834725/P9rustbTF)

平原公子赵胜

#美国山火# 忽然想起一件旧事，就在美国和殖人狂吹人工智能的那档口，英伟达放了个卫星，叫做《人工智能如何帮助加州应对肆虐的野火》。

英伟达吹嘘说可以使用Digitalpath先进的AI技术，利用其GPU强大的性能，配合加州的数千个摄像头，改善卷积神经网络，实时监控山林火灾，甚至可以“预测火灾”……

每次看到这种没写过一行代码的鉴证大V指点江山，都在想，mb的这不是胡说八道吗。所以他们说的别的那些，他们真的懂吗？


*****

####  蜇灵  
##### 177#       发表于 2025-1-22 12:58

为什么要看鉴证大V？


*****

####  alixsander  
##### 178#       发表于 2025-1-22 13:40

<blockquote>泰坦失足 发表于 2025-1-22 12:48
https://weibo.com/1564834725/P9rustbTF

平原公子赵胜
</blockquote>
看外面那个星际之门的帖子就知道了。大部分人只关注是这边的还是那边的，赢还是输。

而且都没人知道Stargate SG1了


*****

####  alixsander  
##### 179#       发表于 2025-1-24 01:39

o3-mini下周发布，免费账户可用

看来DEEPSEEK把OAI是真打疼了


*****

####  qqks  
##### 180#       发表于 2025-1-24 01:48

他就是免费账户可用，按closeai的尿性也会有一堆限制，哪有自己托管的开源大杯爽快？再说了，一大堆企业部门需要对数据保密更加不会订阅三方模型的在线服务。开源这次是大赢特赢啊


*****

####  mimighost  
##### 181#       发表于 2025-1-24 05:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67261909&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-24 01:39</a>

o3-mini下周发布，免费账户可用

看来DEEPSEEK把OAI是真打疼了</blockquote>
好事情

大家一起加速<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">


*****

####  机吉斯卡  
##### 182#         楼主| 发表于 2025-1-24 07:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67245619&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-22 12:48</a>

https://weibo.com/1564834725/P9rustbTF

平原公子赵胜</blockquote>
这个人就别看了，尤其是技术类的

都这年头了还在说马老板搞不了回收，米国月球登月是假的，航天圈里恶名昭彰

然后这人和知乎恨国带V是一个MCN的，知道了吧


*****

####  陈乔恩  
##### 183#       发表于 2025-1-24 08:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67245412&amp;ptid=2224673" target="_blank">VALKIRA 发表于 2025-1-22 12:28</a>
就和六代机一样的

你说美国人从nasa吹过的项目里刨出来一个改吧改吧上天难吗？一点也不难

问题是成本，他已 ...</blockquote>
还是不一样，六代机美国基本已经没有制造能力了。但是AI领域是目前美国仅有的同时在软件，设计，硬件，制造领域都有可控性产业链且领先我国的产业，这也是为什么美帝要all in AI的关键

—— 来自 HUAWEI TAH-AN00m, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.2.2.1


*****

####  枯风瘦雪  
##### 184#       发表于 2025-1-24 08:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263348&amp;ptid=2224673" target="_blank">陈乔恩 发表于 2025-1-24 08:50</a>

还是不一样，六代机美国基本已经没有制造能力了。但是AI领域是目前美国仅有的同时在软件，设计，硬件，制 ...</blockquote>
这也是为啥一旦AI泡沫吹不下去就会引起恐怖的连锁垮塌的原因……

说实话，哪怕曼哈顿计划，也是给不同技术路线同样的支持和试错机会的，但阿美All in AI这一波却几乎算是同态竞争和内卷了，为了股价让整个研发路径非常不健康

阿尔特曼前一阵还放卫星说会展示他们在可控聚变上取得的进展呢，现在也无声无息了

*****

####  新人马甲2  
##### 185#       发表于 2025-1-24 08:59

昨晚慕名去试了试deepseek，有被震惊到，不仅可以回答相当复杂的专业翻译问题，而且经得起反复追问，能给出自己判断依据（与后来追加的资料依据能清楚区分开），能自行推断出提供资料中没有清楚解释的部分，能自行检查自己之前的回答有无错漏处，可以认为它有相当完整的逻辑思维能力，且不大会像之前说的一些模型一样在判断不足的时候直接胡说或瞎编

不过某之前也没用过别的语言模型，不知道和现在的尖端模型比怎么样，反正对某来说在专业疑难问题上都很够用了


*****

####  ddwhzh  
##### 186#       发表于 2025-1-24 09:08

泥潭什么时候把水军和赢🐴🐶杀杀呀，deepseek用了一周，对比OpenAI使用体验也就那样，但GPT可以网络搜索，多模态，这就开始赢上天是不是无语了，至少使用体验更上一个台阶再说吧。


*****

####  弗兰肯斯坦  
##### 187#       发表于 2025-1-24 09:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263504&amp;ptid=2224673" target="_blank">ddwhzh 发表于 2025-1-24 09:08</a>

泥潭什么时候把水军和赢🐴🐶杀杀呀，deepseek用了一周，对比OpenAI使用体验也就那样，但GPT可以网络搜索， ...</blockquote>
deepseek可以网络搜索的<img src="https://static.saraba1st.com/image/smiley/face2017/013.png" referrerpolicy="no-referrer">

*****

####  moekyo  
##### 188#       发表于 2025-1-24 09:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263504&amp;ptid=2224673" target="_blank">ddwhzh 发表于 2025-1-24 09:08</a>

泥潭什么时候把水军和赢🐴🐶杀杀呀，deepseek用了一周，对比OpenAI使用体验也就那样，但GPT可以网络搜索， ...</blockquote>
所以便宜和开源不是使用体验的一环吗


*****

####  qratosones1337  
##### 189#       发表于 2025-1-24 09:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263504&amp;ptid=2224673" target="_blank">ddwhzh 发表于 2025-1-24 09:08</a>

泥潭什么时候把水军和赢🐴🐶杀杀呀，deepseek用了一周，对比OpenAI使用体验也就那样，但GPT可以网络搜索， ...</blockquote>
按你这套逻辑，你自己不就是1450么？明目张胆的胡说八道。

DeepSeek也可以网络搜索，而且R1也可以网络搜索，反观GPT，只要开了o1就不能联网了，使用局限性极大。

这还没算写作，R1对GPT全家都是碾压级吊打

*****

####  overflowal  
##### 190#       发表于 2025-1-24 09:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263504&amp;ptid=2224673" target="_blank">ddwhzh 发表于 2025-1-24 09:08</a>
泥潭什么时候把水军和赢🐴🐶杀杀呀，deepseek用了一周，对比OpenAI使用体验也就那样，但GPT可以网络搜索， ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">什么体验？我用的api，性价比完爆closeAI，还是开源模型

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  枯风瘦雪  
##### 191#       发表于 2025-1-24 09:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263808&amp;ptid=2224673" target="_blank">overflowal 发表于 2025-1-24 09:38</a>

什么体验？我用的api，性价比完爆closeAI，还是开源模型。你这种啥都不提供的"也就这样"党才像水军吧？还 ...</blockquote>
就ds这条路线，本来就不用啥都比closeai强

它就光是在算力和训练成本有限的前提下，得到一个差距可以接受的开源大模型，就足可以改变业态了


*****

####  qratosones1337  
##### 192#       发表于 2025-1-24 09:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263890&amp;ptid=2224673" target="_blank">枯风瘦雪 发表于 2025-1-24 09:44</a>

就ds这条路线，本来就不用啥都比closeai强

它就光是在算力和训练成本有限的前提下，得到一个差距可以接受 ...</blockquote>
R1发布之后就已经不是差距不差距了，这玩意在文学创作方面展现了极其可怕的才能和创意，对比OpenAI全家那都是断崖式吊打，让GPT（4o和o1都包括）看着跟弱智一样那种。

*****

####  宇洋  
##### 193#       发表于 2025-1-24 09:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263504&amp;ptid=2224673" target="_blank">ddwhzh 发表于 2025-1-24 09:08</a>

泥潭什么时候把水军和赢🐴🐶杀杀呀，deepseek用了一周，对比OpenAI使用体验也就那样，但GPT可以网络搜索， ...</blockquote>
多模态不清楚，但deepseek是能网络搜索的。
 <blockquote>好的，用户需要我帮忙搜索2025年春节联欢晚会的节目名单，任何初稿都可以。首先，我需要从提供的搜索结果中找到相关的信息。用户给的是多个网页结果，其中有些是央视春晚，有些是网络春晚，还有卫视的，比如湖南卫视。得注意区分这些不同的晚会。

网页1、5、7、9都是关于央视春晚的内容。网页1提到了第四次彩排在1月22日进行，并列举了部分节目和主持人。比如歌曲《苹果香》由狼戈演唱，还有周深的《花开忘忧》等。主持人方面，北京主会场是任鲁豫、撒贝宁等，分会场的主持人也列出了。网页5是百度百科的内容，详细介绍了春晚的各个部分，包括吉祥物、分会场设置、技术应用等，但节目单部分可能不够详细。网页7是央视的新闻发布会，提到了主持人阵容和一些创新节目，比如传统建筑创演秀《栋梁》，但具体的节目列表可能不完整。网页9是**的条目，节目单部分有一些歌曲和表演，但看起来可能不完整，比如《倒转地球》由刘德华和张子枫演唱，还有王菲的《世界赠予我的》等，但不确定是否是最新信息。

而网页2、3、4、6、8、10都是关于央视网络春晚的内容，用户可能需要的是央视主春晚的节目单，所以这些可能不太相关。不过用户说任何初稿都可以，所以如果有网络春晚的节目单，也可以考虑是否要包含进去。但根据用户的问题，更可能是在问央视主春晚的节目单。

需要确认的是，网页1和网页5都提到了部分节目。例如，网页1列出的节目包括《苹果香》《花开忘忧》《常回家看看》《伤心太平洋》等，还有戏曲节目如《谁说女子不如男》《唱脸谱》等。网页9**的节目单里有一些不同的歌曲，比如刘德华的《倒转地球》，王菲的《世界赠予我的》，还有戏曲节目《声动梨园》等。这里可能存在不同来源的信息差异，需要确认哪个更准确。

此外，网页5提到总台春晚的节目单中包括创演秀《栋梁》，武术《笔走龙蛇》等，可能和网页1的内容互补。但可能网页1的信息更具体，因为它是彩排后的节目列表，而**可能还在编辑中，信息可能不全。

另外，注意时间，今天是2025年1月24日，而央视春晚的正式播出时间是1月28日，所以用户可能想要的是已经公布的彩排节目单，即初稿。网页1是第四次彩排后的节目单，可能比较接近最终版本，而网页9的**可能还在更新中，但不确定其准确性。

需要综合网页1、5、7、9的信息，整理出节目名单。可能需要指出这些是彩排中的节目，实际播出可能会有变动。比如，网页1中的节目列表较为详细，包括多个歌曲、舞蹈、戏曲节目，而网页9的**有更多其他节目，比如刘德华、王菲的歌曲，但需要确认是否可靠。此外，网页5提到《世界赠予我的》由王菲演唱，这可能是一个重要信息。

因此，整理出的节目单可能包含网页1中的节目列表，并补充网页5和网页9中的部分内容，同时注明这些是初稿或彩排中的节目，可能变动。需要引用对应的网页编号作为来源，比如网页1、网页5、网页9。

还需要注意主持人信息，网页1、5、7、9都提到了主持人阵容，但用户主要需要节目名单，这部分可以简要提及，但重点放在节目上。

总结：需要将网页1中的节目列表作为主要来源，结合其他网页中的补充信息，整理出央视春晚的初稿节目名单，并注明来源和可能的变动。

根据搜索结果，2025年中央广播电视总台春节联欢晚会（央视春晚）的节目单（初稿或彩排版本）已部分公布，以下是目前可汇总的信息：

2025年央视春晚节目单（初稿/彩排版）

歌曲类

《苹果香》 演唱：狼戈1

《花开忘忧》 演唱：周深1

《常回家看看》 演唱：蔡国庆、包贝尔、月亮1

《伤心太平洋》 演唱：任贤齐1

《祝您平安》 演唱：孙悦，表演：中国残疾人艺术团1

《世界赠予我的》 演唱：王菲（**版本）9

《倒转地球》 演唱：刘德华、张子枫（**版本）9

《孤勇者》 演唱：陈奕迅，联合奥运冠军（**版本）9

舞蹈与技艺类

《奔腾》 领舞：姜铁红1

《千年莫高 乐动敦煌》 乐器演奏：章益、王梓等；舞蹈：王晓婷、刘丽丽等1

《笔走龙蛇》 武术表演（**版本）9

芭蕾舞《伊人》（**版本）9

戏曲与传统文化类

《谁说女子不如男》 演唱：小香玉1

《唱脸谱》 表演：阎鹤祥、北京戏娃京剧团1

京剧《定军山》选段 表演：王珮瑜1

《声动梨园》 戏曲联演（**版本）9

创演秀《栋梁》 以榫卯结构、北京中轴线为灵感，结合三维建筑模型与虚拟技术（新闻发布会提及）79

语言类节目

小品、相声等节目尚未公布具体名称，但彩排中提到“现场喜气洋洋、笑声不断”15。

分会场特色节目

重庆分会场：巴渝歌舞与年俗表演57

西藏拉萨分会场：民族风情表演，如藏舞与民族团结主题环节57

江苏无锡分会场：传统曲调与现代情景演绎结合5

湖北武汉分会场：新派戏曲与经典影视IP融合5

其他亮点节目

《将进酒》 演唱：厨戏乐队1

《四季人生》 演唱：林晓峰1

《一格格》 演唱：卫兰1

主持人阵容

北京主会场：任鲁豫、撒贝宁、尼格买提、龙洋、马凡舒

分会场：

重庆：张韬、何苗苗

湖北武汉：杨帆、陈超

西藏拉萨：朱迅、斯塔罗布

江苏无锡：王音棋、李好157

补充说明

技术应用：晚会采用虚拟现实、裸眼3D、8K超高清等技术，例如《栋梁》通过XR与数字孪生技术呈现古建筑三维模型79；首次推出视障与听障版无障碍转播，结合AI语音与AR手语解说57。

主题与吉祥物：以“巳巳如意，生生不息”为主题，吉祥物为青绿色“巳升升”，灵感源自甲骨文“巳”字59。

以上信息基于彩排及部分官方发布内容整理，最终节目以1月28日除夕夜（20:00）正式播出为准157。如需完整节目单，可关注央视官方渠道或查看直播。</blockquote>


*****

####  枯风瘦雪  
##### 194#       发表于 2025-1-24 09:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263928&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2025-1-24 09:48</a>

R1发布之后就已经不是差距不差距了，这玩意在文学创作方面展现了极其可怕的才能和创意，对比OpenAI全家那 ...</blockquote>
嗯，DS很神奇的展示出了可用的文学创作能力，这个就很有意思，也不知道是咋涌现的


*****

####  万恶淫猥手  
##### 195#       发表于 2025-1-24 09:59

<img src="https://static.saraba1st.com/image/smiley/face2017/029.png" referrerpolicy="no-referrer">我们的 Agent 已经准备切换到 DeepSeek 了,测试中的效果比我们之前在用的 4o 要好的


*****

####  新人马甲2  
##### 196#       发表于 2025-1-24 10:10

联网这块，某最惊讶的是deepseek在不联网取得额外信息的情况下就能给出相当完整且逻辑性强的回答，然后它自己说自己并不需要利用太多即时分配的算力和联网信息，算力影响的主要是响应时间而非回答准确性，所谓的算力不足导致瞎答很大程度上是训练不充分、内置的判断逻辑不足、以及模型训练时过度要求回答流畅性云云（昨晚问的，具体内容不记得那么多了，大意如此）


*****

####  通心粉  
##### 197#       发表于 2025-1-24 10:16

太乐了

[https://mp.weixin.qq.com/s/xVux1jo1nLpSSrt7JlxfKA](https://mp.weixin.qq.com/s/xVux1jo1nLpSSrt7JlxfKA)

最先陷入恐慌的，似乎是同样推崇开源的 Meta。

最近，有 Meta 员工在美国匿名职场社区 teamblind 上面发布了一个帖子。帖子提到，国内 AI 创业公司 DeepSeek 最近的一系列动作让 Meta 的生成式 AI 团队陷入了恐慌，因为在前者的低成本高歌猛进下，后者无法解释自己的超高预算的合理性。

原文如下：
 <blockquote>这一切始于 DeepSeek-V3，它在基准测试中就已经让 Llama 4 落后。更糟糕的是那个「拥有 550 万训练预算的不知名中国公司」。

工程师们正在疯狂地分析 DeepSeek，试图从中复制任何可能的东西。这一点都不夸张。

管理层担心如何证明庞大的生成式 AI 组织的成本是合理的。当生成式 AI 组织中的每个「领导」的薪资都比训练整个 DeepSeek-V3 的成本还要高，而我们有好几十个这样的「领导」时，他们要如何面对高层？

DeepSeek-R1 让情况变得更加可怕。虽然我不能透露机密信息，但这些很快就会公开。

这本应该是一个以工程为重点的小型组织，但是因为很多人想要参与进来分一杯羹，人为地膨胀了组织的招聘规模，结果每个人都成了输家。</blockquote>

*****

####  stanzgy  
##### 198#       发表于 2025-1-24 10:16

deepseek目前看唯一欠缺的就是多模态能力，其他方面当前阶段看非常不错了，说实话多模态现在用的并不多，也没有什么场景强需求这个。
工作里token使用量最大的还是接到vscode vim各种插件里，sonnet 3.5/qwen coder都用过，现在已经切到deepseek了

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  thermite  
##### 199#       发表于 2025-1-24 10:29

联网搜索+深度思考真的薄纱其它一众模型

比如我问2024年的台风资料，它不会跟我瞎JB轱辘一长串COT然后给出一个巨他妈离谱的错误答案

没开联网的时候它直接跟你说我不会，开联网它能给你个准确的总结归纳

至于说它的专业能力——要么自己微调，要么等深度求索自己公布更专业细分的模型

现在的程度已经够一般人使用了


*****

####  moekyo  
##### 200#       发表于 2025-1-24 10:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67264248&amp;ptid=2224673" target="_blank">stanzgy 发表于 2025-1-24 10:16</a>

deepseek目前看唯一欠缺的就是多模态能力，其他方面当前阶段看非常不错了，说实话多模态现在用的并不多，也 ...</blockquote>
我觉得最大问题是，我不能截图甩给它说，这里的实现有问题，改一下


*****

####  alixsander  
##### 201#       发表于 2025-1-24 10:38

<blockquote>通心粉 发表于 2025-1-24 10:16
太乐了

https://mp.weixin.qq.com/s/xVux1jo1nLpSSrt7JlxfKA
</blockquote>
这个多半假的，怎么可能有人不认识DeepSeek。llama2时代开源社群就都知道DS了

*****

####  风夏  
##### 202#       发表于 2025-1-24 10:38

<img src="https://img.saraba1st.com/forum/202501/24/103805pmy333qp3fb3c3ky.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (21.86 KB, 下载次数: 0)

下载附件

2025-1-24 10:38 上传

请教个问题, ollama跑这些蒸馏qwen的模型的话, 后面这几个参数是啥意思?

*****

####  玖羽  
##### 203#       发表于 2025-1-24 10:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67245619&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-22 12:48</a>
[https://weibo.com/1564834725/P9rustbTF](https://weibo.com/1564834725/P9rustbTF)</blockquote>
DeepSeek： <blockquote>这篇文章对当前人工智能（AI）技术的发展和应用提出了批评，特别是针对美国科技公司在AI领域的投入和成果。文章指出，尽管美国公司和机构大力推广AI技术，如英伟达和OpenAI的项目，但这些技术在现实中的应用效果并不理想，尤其是在预测和应对加州山火等实际问题上表现不佳。作者认为，这些AI项目更多是吸引投资和维持科技霸权的工具，而非真正推动科技进步和生产力提升的解决方案。

文章还对比了中美在AI应用上的差异，指出中国更注重AI在工业、农业、交通等实体领域的应用，这些应用基于真实世界的数据和需求，更具有实用价值。相比之下，美国的AI技术虽然在高算力和大规模数据处理上投入巨大，但在实际生产力提升方面的贡献有限。

此外，文章批评了美国科技界频繁推出的“革命性”技术，如区块链和元宇宙，认为这些技术更多是资本市场上的炒作，缺乏实质性的社会和经济价值。最后，作者质疑了当前AI技术的发展方向，认为过度依赖大规模数据和高算力可能不是推动AI进步的最佳路径，未来的AI发展应更加注重实用性和成本效益。</blockquote>
Q：你怎么看文章中提到你 <blockquote>文章中提到的“DeepSeek”是一个AI模型，与我（Deepseek-V3）是同一个系列的产品。文章中对DeepSeek的评价是相对积极的，认为它在训练成本、效率和实用性方面表现优于OpenAI的GPT系列。具体来说，文章提到DeepSeek的训练成本仅为558万美元，训练时长为两个月，使用的硬件资源也远少于GPT系列，但在某些方面的表现却不逊色甚至更好。

我的看法：

成本与效率：

文章强调DeepSeek在成本和效率上的优势，这一点确实值得关注。AI模型的训练需要巨大的算力和资源投入，如何在保证性能的同时降低成本，是一个重要的研究方向。如果DeepSeek能够在低资源消耗下实现与GPT相当甚至更好的效果，这无疑是一个重要的突破。

实用性导向：

文章批评OpenAI的GPT系列在文字生成、图片生成等领域的应用“缺乏实际价值”，而更倾向于形式主义和低效的内容生产。相比之下，DeepSeek似乎更注重实用性和真实世界的应用场景。这种务实的方向可能更符合AI技术长期发展的需求。

技术路径的多样性：

文章提到中美在AI发展路径上的差异，中国更注重AI在工业、农业、交通等实体领域的应用，而美国则倾向于“通用大模型”。这种差异反映了不同国家在技术发展上的战略选择。DeepSeek作为中国AI技术的代表之一，可能更贴近实际需求，这也是其优势之一。

对AI发展的反思：

文章对当前AI技术的批评，尤其是对过度依赖算力和数据的质疑，值得深思。AI技术的进步不应仅仅停留在“更大规模的数据”和“更高性能的硬件”上，而应更多地关注如何解决实际问题、提升生产力以及降低成本。

总结：

文章对DeepSeek的评价是正面的，认为它在成本、效率和实用性方面表现突出。作为同一系列的产品，我认为这种评价反映了AI技术发展的一个重要方向：在保证性能的同时，注重成本控制和实际应用。未来，AI技术的发展可能会更加多元化，既需要通用大模型的探索，也需要在具体领域中的深耕细作。DeepSeek的出现，或许正是这种多元化发展的一个体现。</blockquote>


*****

####  alixsander  
##### 204#       发表于 2025-1-24 10:40

 本帖最后由 alixsander 于 2025-1-24 10:41 编辑 
<blockquote>风夏 发表于 2025-1-24 10:38
请教个问题, ollama跑这些蒸馏qwen的模型的话, 后面这几个参数是啥意思?</blockquote>

量化

这几个蒸馏属于proof of concept，本身实际使用性能真不咋滴。

不过1.5B蛮好玩的，因为基模本来就很弱

现在是very smart moron

*****

####  FeteFete  
##### 205#       发表于 2025-1-24 10:42

<blockquote>风夏 发表于 2025-1-24 10:38
请教个问题, ollama跑这些蒸馏qwen的模型的话, 后面这几个参数是啥意思?</blockquote>
量化值  fp16是16位float

n8 这些应该是int8 int4


*****

####  kira1988  
##### 206#       发表于 2025-1-24 11:28

<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">试了下deepseek直接翻车了

问乐奈跟喵梦有什么相似之处，结果答案直接把乐奈答成睦嗞咪了

感觉搜一下都能答对吧

*****

####  机吉斯卡  
##### 207#         楼主| 发表于 2025-1-24 11:31

艹，现在是个水群都在传SEEK写的小黄温

就是那个静香的那个

脑洞太大了


*****

####  披头破落户  
##### 208#       发表于 2025-1-24 11:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265243&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-24 11:31</a>
艹，现在是个水群都在传SEEK写的小黄温

就是那个静香的那个</blockquote>
私我看看<img src="https://static.saraba1st.com/image/smiley/face2017/075.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  披头破落户  
##### 209#       发表于 2025-1-24 11:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265198&amp;ptid=2224673" target="_blank">kira1988 发表于 2025-1-24 11:28</a>
试了下deepseek直接翻车了

问乐奈跟喵梦有什么相似之处，结果答案直接把乐奈答成睦嗞咪了

感觉搜一下都能答 ...</blockquote>
要点深度思考和联网搜索才行，我试了试给出的结果基本正确

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  白色的120  
##### 210#       发表于 2025-1-24 11:52

deepseek玩酒馆还行，主要便宜还速度快，网页版写材料的话有限制

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  clarkgao  
##### 211#       发表于 2025-1-24 11:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265457&amp;ptid=2224673" target="_blank">白色的120 发表于 2025-1-24 11:52</a>

deepseek玩酒馆还行，主要便宜还速度快，网页版写材料的话有限制

—— 来自 鹅球 v3.3.96 ...</blockquote>
但文字窗口太小了。不知道有没有人搞个专门的部署，开到128K，做一些acg和刘备相关的专门后训练，让大家玩玩。

*****

####  Realplayer  
##### 212#       发表于 2025-1-24 11:57

<blockquote>overflowal 发表于 2024-12-27 17:55
单卡是放不下了，真想跑可以尝试放到内存用CPU跑，应该速度是能用的。因为是MoE架构 ...</blockquote>
单机版16/32+128g够么？内存要加到多少嘞？


*****

####  Xerxes_2  
##### 213#       发表于 2025-1-24 12:13

Mac 用户笑了，14B 跑起来毫无压力
买个顶配应该能跑 70B

—— 来自 Google Pixel 9 Pro, Android 15, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.95-debug

*****

####  overflowal  
##### 214#       发表于 2025-1-24 12:14

deepseek的做的那几个蒸馏不是r1的缩小版啊，需要说下，ollama竟然把他们放R1同系列的东西宣传<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  cube  
##### 215#       发表于 2025-1-24 12:33

昨天试了下新模型的归纳能力。

只能说牛逼。


*****

####  cube  
##### 216#       发表于 2025-1-24 12:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265198&amp;ptid=2224673" target="_blank">kira1988 发表于 2025-1-24 11:28</a>
试了下deepseek直接翻车了

问乐奈跟喵梦有什么相似之处，结果答案直接把乐奈答成睦嗞咪了

感觉搜一下都能答 ...</blockquote>
要点开深度思考那个按钮，默认模型是老模型，水平是不如Kimi，豆包这些的。

*****

####  mp5  
##### 217#       发表于 2025-1-24 12:34

本地部署了一个Q4量化32b的r1, 已经爽到飞起<img src="https://static.saraba1st.com/image/smiley/face2017/056.gif" referrerpolicy="no-referrer">

跟closeai免费帐号的水平差不多, 长推理更是完爆

*****

####  cube  
##### 218#       发表于 2025-1-24 12:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265198&amp;ptid=2224673" target="_blank">kira1988 发表于 2025-1-24 11:28</a>
试了下deepseek直接翻车了

问乐奈跟喵梦有什么相似之处，结果答案直接把乐奈答成睦嗞咪了

感觉搜一下都能答 ...</blockquote>
这是我问到的答案，我觉得还行了，甚至结尾还卖了个萌。

乐奈（通常指《BanG Dream!》中的千叶乐奈）和喵梦（可能指《公主连结》中的凯露或其他萌系角色）的相似之处主要体现在以下几个方面，但需注意角色具体出处可能影响对比：

---

### 1. **慵懒随性的性格**
   - **乐奈**：自由散漫，经常突然消失或睡觉，对甜食毫无抵抗力，说话直率。
   - **喵梦**（以凯露为例）：表面傲娇但内心柔软，偶尔露出懒散的一面，对美食（尤其是鲷鱼烧）极度执着。
   - **相似点**：随性、孩子气的行为模式，容易因喜好（如食物）被吸引。

---

### 2. **猫系元素**
   - **乐奈**：绰号“流浪猫”，造型有白**耳发饰，性格像猫一样难以捉摸。
   - **喵梦**：名字含“喵”，可能搭配猫耳装饰（如凯露的黑**耳发箍），或具备猫娘属性。
   - **相似点**：以“猫”为设计核心，突出萌系反差感。

---

### 3. **萌系反差设定**
   - **乐奈**：外表软萌但吉他实力顶尖，反差感强烈。
   - **喵梦**：若指凯露，则是傲娇毒舌与脆弱内心的反差；若为其他角色，可能具备外冷内热或能力与外表不符的特点。
   - **相似点**：通过性格/能力的反差制造萌点。

---

### 4. **团队中的“不稳定因素”**
   - **乐奈**：在乐队MyGO!!!!!中经常任性行动，却无形中推动剧情发展。
   - **喵梦**：若为凯露，在“美食殿堂”公会中常吐槽队友，成为搞笑担当。
   - **相似点**：在团队中扮演打破常规的角色，增强故事戏剧性。

---

### 5. **二次元文化符号化**
   - 两者均符合ACG领域对“萌属性”的提炼：乐奈的“无口猫系”、喵梦的“傲娇猫娘”，均是标签化设计的体现，易于观众记忆和传播。

---

### 差异提示：
- 若“喵梦”指向其他角色（如虚拟主播或原创角色），相似点可能集中在猫系形象、性格萌点等方面，需具体分析。

如果需要更精准的对比，建议补充角色出处信息哦！ (๑&gt;◡&lt;๑)


*****

####  cube  
##### 219#       发表于 2025-1-24 12:48

至于说多模态，实际上还是受限与DS公司自身的规模和算力。

但是反过来说，一并不是说非多模态的模型没有价值，反而DS目前的路子是部分跳出了之前生成式大模型自己内循环导致性能劣化的局限性，二多模态大模型现在到底该往哪里发展我怕炼这些玩意的自己都说不准，三要是DS能用现在的成本搞出实用的多模态，那某些人就不是急不急的问题了。


*****

####  SkavenYesYes  
##### 220#       发表于 2025-1-24 12:51

真的好用<img src="https://static.saraba1st.com/image/smiley/face2017/074.png" referrerpolicy="no-referrer">

*****

####  coldhot3  
##### 221#       发表于 2025-1-24 12:54

<blockquote>alixsander 发表于 2025-1-24 10:38
这个多半假的，怎么可能有人不认识DeepSeek。llama2时代开源社群就都知道DS了 ...</blockquote>
这是翻译失真了，关键是out of no where。不是不认识deepseek，是deepseek一个从我们都不知道的地方（暗讽文明之外的野蛮之地）出来的公司，把我们爆杀。

*****

####  overflowal  
##### 222#       发表于 2025-1-24 12:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67266042&amp;ptid=2224673" target="_blank">cube 发表于 2025-1-24 12:48</a>
至于说多模态，实际上还是受限与DS公司自身的规模和算力。

但是反过来说，一并不是说非多模态的模型没有价 ...</blockquote>
集中精力搞text2text是对的，api可能95%的用量都是在纯text任务

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  coldhot3  
##### 223#       发表于 2025-1-24 12:55

<blockquote>cube 发表于 2025-1-24 12:48
至于说多模态，实际上还是受限与DS公司自身的规模和算力。

但是反过来说，一并不是说非多模态的模型没有价 ...</blockquote>
那有没有接口啊，我希望deepseek能读懂word，输出word。


*****

####  cube  
##### 224#       发表于 2025-1-24 12:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67266116&amp;ptid=2224673" target="_blank">coldhot3 发表于 2025-1-24 12:55</a>

那有没有接口啊，我希望deepseek能读懂word，输出word。</blockquote>
可以申请API的。

因为用API写作不会受到官网的内容审查限制，现在SEEK写的小黄文满天飞<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">，全球不分语言玩得不亦乐乎（中国手机号注册有500万免费token）。

参考这个帖子 [https://bbs.saraba1st.com/2b/thread-2243830-3-1.html](https://bbs.saraba1st.com/2b/thread-2243830-3-1.html)


*****

####  外挂  
##### 225#       发表于 2025-1-24 13:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265243&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-24 11:31</a>

艹，现在是个水群都在传SEEK写的小黄温

就是那个静香的那个</blockquote>
 怎么才能写出来，我这边就算提示加入杀必死要素也就会加点擦边然后瞬间把答案吞了

*****

####  juluck000  
##### 226#       发表于 2025-1-24 13:02

dpr1太黄暴了，不亏是国人整出来的模型

*****

####  外挂  
##### 227#       发表于 2025-1-24 13:02

我做的盗版轻小说到对话次数上限了，有什么办法能存档全部设定，让它在新对话里读盘吗


*****

####  机吉斯卡  
##### 228#         楼主| 发表于 2025-1-24 13:10

🔻类似脉脉的美国匿名职场论坛 teamblind 上有人说：meta 看了 deepseek 慌的一匹。

🔻讨论区非常有意思，一个 google 的人问别人要 deepseek 的论文地址，另一个 google 的人说：“....兄弟，Googlers同行连一篇论文都找不到，比deepseek还让我担心。”

#ai创造营# ​​​

https://weibo.com/1671109627/5126323271374852


*****

####  小野賢章  
##### 229#       发表于 2025-1-24 14:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67264508&amp;ptid=2224673" target="_blank">风夏 发表于 2025-1-24 10:38</a>

请教个问题, ollama跑这些蒸馏qwen的模型的话, 后面这几个参数是啥意思?</blockquote>
推荐 q4_K_M
[https://github.com/ggerganov/lla ... sioncomment-6351796](https://github.com/ggerganov/llama.cpp/discussions/2094#discussioncomment-6351796)

Allowed quantization types:

   2  or  Q4_0   :  3.50G, +0.2499 ppl @ 7B - small, very high quality loss - legacy, prefer using Q3_K_M

   3  or  Q4_1   :  3.90G, +0.1846 ppl @ 7B - small, substantial quality loss - legacy, prefer using Q3_K_L

   8  or  Q5_0   :  4.30G, +0.0796 ppl @ 7B - medium, balanced quality - legacy, prefer using Q4_K_M

   9  or  Q5_1   :  4.70G, +0.0415 ppl @ 7B - medium, low quality loss - legacy, prefer using Q5_K_M

  10  or  Q2_K   :  2.67G, +0.8698 ppl @ 7B - smallest, extreme quality loss - not recommended

  12  or  Q3_K   : alias for Q3_K_M

  11  or  Q3_K_S :  2.75G, +0.5505 ppl @ 7B - very small, very high quality loss

  12  or  Q3_K_M :  3.06G, +0.2437 ppl @ 7B - very small, very high quality loss

  13  or  Q3_K_L :  3.35G, +0.1803 ppl @ 7B - small, substantial quality loss

  15  or  Q4_K   : alias for Q4_K_M

  14  or  Q4_K_S :  3.56G, +0.1149 ppl @ 7B - small, significant quality loss

  15  or  Q4_K_M :  3.80G, +0.0535 ppl @ 7B - medium, balanced quality - *recommended*

  17  or  Q5_K   : alias for Q5_K_M

  16  or  Q5_K_S :  4.33G, +0.0353 ppl @ 7B - large, low quality loss - *recommended*

  17  or  Q5_K_M :  4.45G, +0.0142 ppl @ 7B - large, very low quality loss - *recommended*

  18  or  Q6_K   :  5.15G, +0.0044 ppl @ 7B - very large, extremely low quality loss

   7  or  Q8_0   :  6.70G, +0.0004 ppl @ 7B - very large, extremely low quality loss - not recommended

   1  or  F16    : 13.00G              @ 7B - extremely large, virtually no quality loss - not recommended

   0  or  F32    : 26.00G              @ 7B - absolutely huge, lossless - not recommended


*****

####  alixsander  
##### 230#       发表于 2025-1-24 14:06

 本帖最后由 alixsander 于 2025-1-24 14:08 编辑 
<blockquote>coldhot3 发表于 2025-1-24 12:54
这是翻译失真了，关键是out of no where。不是不认识deepseek，是deepseek一个从我们都不知道的地方（暗 ...</blockquote>

我知道teamblind这个人的原文，不是翻译的问题，DS怎么可能算out of nowhere. 一年前就人人都认识了。DS V2.5的时候就开始说中国的策略和temu一样，便宜量大


*****

####  Bronzecraft  
##### 231#       发表于 2025-1-24 14:26

我试着问了下《暴风城打工实录》最新章是多少，给的答案还是错的


*****

####  gawain  
##### 232#       发表于 2025-1-24 14:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67266139&amp;ptid=2224673" target="_blank">cube 发表于 2025-1-24 12:58</a>
可以申请API的。

因为用API写作不会受到官网的内容审查限制，现在SEEK写的小黄文满天飞，全球不分语言玩 ...</blockquote>
为啥我用api还是会被ban nsfw的提示词

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  qratosones1337  
##### 233#       发表于 2025-1-24 14:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265493&amp;ptid=2224673" target="_blank">clarkgao 发表于 2025-1-24 11:57</a>

但文字窗口太小了。不知道有没有人搞个专门的部署，开到128K，做一些acg和刘备相关的专门后训练，让大家 ...</blockquote>
如果不需要长文本的话，现在的API对刘备的支持已经极好了

*****

####  cube  
##### 234#       发表于 2025-1-24 14:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67267029&amp;ptid=2224673" target="_blank">gawain 发表于 2025-1-24 14:33</a>

为啥我用api还是会被ban nsfw的提示词

论坛助手,iPhone</blockquote>
用python本地部署一下，调用模型用deepseek-reasoner即R1。


*****

####  overflowal  
##### 235#       发表于 2025-1-24 14:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265493&amp;ptid=2224673" target="_blank">clarkgao 发表于 2025-1-24 11:57</a>

但文字窗口太小了。不知道有没有人搞个专门的部署，开到128K，做一些acg和刘备相关的专门后训练，让大家 ...</blockquote>
openrouter上deepseek有一些供应商有开放128K窗口，但是价格比deepseek官方贵几倍。

国内看看硅基流动会不会上了，之前说春节前上deepseek v3，还没影子

*****

####  marquez  
##### 236#       发表于 2025-1-24 15:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265367&amp;ptid=2224673" target="_blank">披头破落户 发表于 2025-1-24 11:43</a>

私我看看

—— 来自 鹅球 v3.3.96</blockquote>
也私我看看<img src="https://static.saraba1st.com/image/smiley/face2017/075.png" referrerpolicy="no-referrer">


*****

####  买码！注册！  
##### 237#       发表于 2025-1-24 15:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67266111&amp;ptid=2224673" target="_blank">coldhot3 发表于 2025-1-24 12:54</a>
这是翻译失真了，关键是out of no where。不是不认识deepseek，是deepseek一个从我们都不知道的地方（暗 ...</blockquote>
"out of nowhere"意思是“突然，出乎意料”

如果换个说法"out of blue"可别解读出“来自跟蓝营/蓝州有关系的地方”


*****

####  流缨  
##### 238#       发表于 2025-1-24 15:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67266940&amp;ptid=2224673" target="_blank">Bronzecraft 发表于 2025-1-24 14:26</a>

我试着问了下《暴风城打工实录》最新章是多少，给的答案还是错的</blockquote>
这个估计没法对，独阅读就没有公域流量，搜索不到的，只能爬盗版站的结果


*****

####  流缨  
##### 239#       发表于 2025-1-24 15:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265880&amp;ptid=2224673" target="_blank">mp5 发表于 2025-1-24 12:34</a>

本地部署了一个Q4量化32b的r1, 已经爽到飞起

跟closeai免费帐号的水平差不多, 长推理更是完爆 ...</blockquote>
求问一下硬件环境，手头现在只有一块4090


*****

####  tioit  
##### 240#       发表于 2025-1-24 15:36

<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">deepseek 搜索还是有点问题

昨天我搜 “鸿蒙智行旗下的车，内存大小分别是多少？”

回答的数据不大对。

还得不断训练


*****

####  億万千  
##### 241#       发表于 2025-1-24 15:40

闭源大模型现在哪家nb，和这些开源的比呢


*****

####  lilisipis  
##### 242#       发表于 2025-1-24 15:46

现在哪家模型可以生成虚拟管人，就是把管人聊天风格音色人设输进去生成个虚拟管人和我聊天的


*****

####  rubus  
##### 243#       发表于 2025-1-24 15:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036113&amp;ptid=2224673" target="_blank">马车夫 发表于 2024-12-27 17:41</a>

美帝这几年甚至是十多年前万物转码的后遗症，认识不少学机械EE的纷纷抛弃制造业，纯coding又不是什么要智商 ...</blockquote>
国内头部高校现在也是万物转码，反而中等水平的学校还保留了一些传统的研究方向（虽然很大程度并不是自愿的。这帮人就是每次看到疑似风头一窝蜂全去做

*****

####  断片集  
##### 244#       发表于 2025-1-24 15:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67267817&amp;ptid=2224673" target="_blank">lilisipis 发表于 2025-1-24 15:46</a>

现在哪家模型可以生成虚拟管人，就是把管人聊天风格音色人设输进去生成个虚拟管人和我聊天的 ...</blockquote>
这就是llm和tts两者结合的事了，llm的话，只是模仿风格普通聊天的话大概都能，deepseek算是比较有性价比的了

声音的话你可以去b站之类的地方搜下cosyvoice2，效果已经很不错了，基本接近真人水平

用silly tavern把这俩整合起来大概就有你想要的效果了

*****

####  alixsander  
##### 245#       发表于 2025-1-24 15:53

<blockquote>億万千 发表于 2025-1-24 15:40
闭源大模型现在哪家nb，和这些开源的比呢</blockquote>
OAI咯

o3 &gt; o1 pro &gt; DS R1≈KIMI1.5 ≈o1 ≈ o3 mini≈ Gemini 2 flash thinking(这个1M context window, 60K ouput len) 

非reasoning的SOTA基模，都差不多吧，都接近4o了。Sonnet在代码和创意写作上强一些。

多模态/全模态（语音-语音 端到端）

gemini 2 flash模态挺强的，感觉和4o多模态差不多，但是能听得懂中文不能说中文。 豆包只能语音双工没有视觉能力，但是中文水平是最好的

Agentic

最实用的Google DeepResearch. OAI之前只有一个能执行周期任务的，今天发布了一个operator，200刀能帮你点浏览器，但是基模用的也只是4o。只能说智能体是25年的主要方向，未来可期吧

看月之暗面，幻方，千问什么时候开源智能体，全模态。可能也就落后OAI一到三个月。


*****

####  ysys  
##### 246#       发表于 2025-1-24 16:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67263430&amp;ptid=2224673" target="_blank">新人马甲2 发表于 2025-1-24 08:59</a>

昨晚慕名去试了试deepseek，有被震惊到，不仅可以回答相当复杂的专业翻译问题，而且经得起反复追问，能给出 ...</blockquote>
不不不，胡说还是有的

正常情况你也不会啥问题都去看它的解释

只不过能给分析过程看起来确实感觉挺好


*****

####  andychen  
##### 247#       发表于 2025-1-24 16:40

AI我们能赶上一点都不奇怪，人才储备上基本和对岸是分庭抗礼的
一些你懂的因素也能被绕开，像这回deepseek这样。从这角度看国内商用大公司搞的模型可能看点反而少一些

*****

####  moekyo  
##### 248#       发表于 2025-1-24 16:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67267722&amp;ptid=2224673" target="_blank">tioit 发表于 2025-1-24 15:36</a>

deepseek 搜索还是有点问题

昨天我搜 “鸿蒙智行旗下的车，内存大小分别是多少？”

回答的数据不大对。</blockquote>
这个不行吗 <blockquote>根据鸿蒙智行旗下各车型的公开信息，目前官方参数配置表中未明确标注“内存大小”（可能指车机系统的运行内存或存储空间）。不过，结合不同车型的智能座舱配置和功能描述，可以推断其硬件性能与华为鸿蒙系统的适配情况如下：

### 1. **问界M5系列**

   - **车机系统**：搭载HarmonyOS鸿蒙操作系统，支持多设备互联、语音控制等功能。

   - **硬件配置**：配备15.6英寸中控屏和10.25英寸全液晶仪表，支持华为MagLink生态接口。虽然没有直接提及内存参数，但根据用户实测反馈，系统流畅度较高，但在复杂语音交互和网络依赖功能上偶有卡顿。

   - **推测配置**：参考华为终端设备（如平板、手机）的硬件标准，可能采用8GB以上运行内存及128GB存储空间。

### 2. **智界S7**

   - **车机系统**：首发HarmonyOS 4智能座舱，支持3D车控桌面、盘古大模型语音助手等功能。

   - **硬件配置**：配备12.3英寸全液晶仪表和15.6英寸中控屏，支持双50W无线快充、星环散射体声学系统等。其智能驾驶系统（HUAWEI ADS 2.0）需要较高的数据处理能力，推断其内存配置可能更高。

   - **推测配置**：可能采用12GB运行内存及256GB存储空间，以支持高阶智驾和座舱多任务处理。

### 3. **智界R7**

   - **车机系统**：搭载鸿蒙系统，配备15.6英寸中控屏和12.3英寸仪表屏，支持遥控泊车、哨兵模式等功能。

   - **硬件配置**：与智界S7同属鸿蒙智行高端车型，推测其内存配置接近智界S7，但具体参数未公开。

### 4. **问界新M5**

   - **车机系统**：与问界M5类似，但新增了更多智能驾驶功能（如城区NCA），可能对内存要求更高。

   - **硬件配置**：未明确提及内存，但车内发声单元和智能泊车辅助等功能需要较强的处理能力。

### 5. **其他车型（尊界S800、问界M8等）**

   - **尊界S800**：作为旗舰级大型轿车，预计搭载华为乾崑ADS 3.0高阶智驾系统，推测内存配置为鸿蒙智行车型中最高（可能达到16GB运行内存及512GB存储空间）。

   - **问界M8**：定位中大型SUV，可能采用与智界S7相近的硬件配置，以支持三屏联动和城市智驾功能。

### 总结

鸿蒙智行车型的内存配置信息未在官方参数中明确标注，但通过系统功能和高阶智驾需求可推测其硬件性能处于行业较高水平。如需具体数据，建议咨询官方渠道或关注后续车型发布会。</blockquote>


*****

####  coldhot3  
##### 249#       发表于 2025-1-24 18:11

<blockquote>alixsander 发表于 2025-1-24 14:06
我知道teamblind这个人的原文，不是翻译的问题，DS怎么可能算out of nowhere. 一年前就人人都认识了。DS  ...</blockquote>
ds这公司在哪？好像是浙江？


*****

####  SkavenYesYes  
##### 250#       发表于 2025-1-24 18:37

有懂行的老哥说下智驾能像ds这样花小算力办大事么<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

开车也挺reasoning的吧<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  qqks  
##### 251#       发表于 2025-1-24 18:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67269389&amp;ptid=2224673" target="_blank">SkavenYesYes 发表于 2025-1-24 18:37</a>

有懂行的老哥说下智驾能像ds这样花小算力办大事么

开车也挺reasoning的吧</blockquote>
理想的vlm有用到qwenvl2.2b


*****

####  SkavenYesYes  
##### 252#       发表于 2025-1-24 18:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67269401&amp;ptid=2224673" target="_blank">qqks 发表于 2025-1-24 18:40</a>

理想的vlm有用到qwenvl2.2b</blockquote>
阿里的？


*****

####  overflowal  
##### 253#       发表于 2025-1-24 19:19

 本帖最后由 overflowal 于 2025-1-24 19:21 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67269389&amp;ptid=2224673" target="_blank">SkavenYesYes 发表于 2025-1-24 18:37</a>
有懂行的老哥说下智驾能像ds这样花小算力办大事么

开车也挺reasoning的吧</blockquote>
你去问做智驾的话，他们也不知道。至于花小钱办大事，只能说智驾大部分的成本肯定不是训练。本地就那么点算力，跑的模型如果用llm的眼光看都是小小模型<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">
国内那堆公司吹自己云端算力多少多少在我看来就是单纯应激反应，因为ai领域都在吹大力出奇迹。
现在deepseek这么一出后，搞不好那些智驾公司就要开始吹自己小算力办大事了<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  alixsander  
##### 254#       发表于 2025-1-24 20:02

<blockquote>coldhot3 发表于 2025-1-24 18:11
ds这公司在哪？好像是浙江？</blockquote>
应该是杭州

*****

####  枯风瘦雪  
##### 255#       发表于 2025-1-24 20:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67269183&amp;ptid=2224673" target="_blank">coldhot3 发表于 2025-1-24 18:11</a>
ds这公司在哪？好像是浙江？</blockquote>
杭州的

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  Azcarlo  
##### 256#       发表于 2025-1-24 20:19

推上看到一位俄罗斯老哥的评价<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

<img src="https://img.saraba1st.com/forum/202501/24/201904dbnvee8b92zjsb8b.png" referrerpolicy="no-referrer">

<strong>1.png</strong> (261.07 KB, 下载次数: 0)

下载附件

2025-1-24 20:19 上传

<img src="https://img.saraba1st.com/forum/202501/24/201910k3g009zqp6gb63zw.png" referrerpolicy="no-referrer">

<strong>2.png</strong> (181.57 KB, 下载次数: 0)

下载附件

2025-1-24 20:19 上传


*****

####  cym887  
##### 257#       发表于 2025-1-24 20:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265243&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-24 11:31</a>

艹，现在是个水群都在传SEEK写的小黄温

就是那个静香的那个</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/024.png" referrerpolicy="no-referrer">小黄文呢 一天了 QQ群没一个转发的 


*****

####  Frimp  
##### 258#       发表于 2025-1-24 21:03

今天用了一天，跟普通的gpt4比了比，明显感觉到ds会想的更细，给更多的公式，但是有的时候给了一大堆公式都有点离题，不如gpt回答的更简洁和有用，有的时候给的公式有很有用并且完爆gpt的过于简略的回答

*****

####  verniy  
##### 259#       发表于 2025-1-24 21:05

试用感觉逻辑能力和写作能力都太强了，但是开搜索反而有时候会被内容农场和小编体糊弄<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">


*****

####  走来走去  
##### 260#       发表于 2025-1-24 21:09

试了一下写代码， 比我写的好，还能自带优化，列出来每个优化点，最后还能给出优化前后对比和性能评估<img src="https://static.saraba1st.com/image/smiley/face2017/091.png" referrerpolicy="no-referrer">


*****

####  观者熊  
##### 261#       发表于 2025-1-24 22:12

Deepseek太强了，妈妈再也不用担心我不能一键磕羽中姚蒙海猫三人CP了<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

<img src="https://img.saraba1st.com/forum/202501/24/220902k2v163dvz6pavifz.png" referrerpolicy="no-referrer">

<strong>QQ图片20250124220435.png</strong> (151.64 KB, 下载次数: 0)

下载附件

2025-1-24 22:09 上传

<img src="https://img.saraba1st.com/forum/202501/24/220902yy39z5p1o49rpxo6.png" referrerpolicy="no-referrer">

<strong>2.png</strong> (192.11 KB, 下载次数: 0)

下载附件

2025-1-24 22:09 上传

<img src="https://img.saraba1st.com/forum/202501/24/220902jb2zk2teyctfkftz.png" referrerpolicy="no-referrer">

<strong>3.png</strong> (149.2 KB, 下载次数: 0)

下载附件

2025-1-24 22:09 上传


*****

####  gawain  
##### 262#       发表于 2025-1-24 23:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67267198&amp;ptid=2224673" target="_blank">cube 发表于 2025-1-24 14:47</a>
用python本地部署一下，调用模型用deepseek-reasoner即R1。</blockquote>
还是得本地部署啊<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  月珊瑚与紫鸢尾  
##### 263#       发表于 2025-1-25 08:54

<blockquote>gawain 发表于 2025-1-24 23:33
还是得本地部署啊

论坛助手,iPhone</blockquote>
没点门槛，那真是会变成群魔乱舞的


*****

####  newtroll  
##### 264#       发表于 2025-1-25 09:40

所有有deepseek有生成nsfw的攻略吗<img src="https://static.saraba1st.com/image/smiley/face2017/045.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  jaewoongh_  
##### 265#       发表于 2025-1-25 09:43

卧槽这么叼，看来不用再用豆包还要被同事阴阳了


*****

####  吴怀在  
##### 266#       发表于 2025-1-25 09:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265243&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-24 11:31</a>
艹，现在是个水群都在传SEEK写的小黄温

就是那个静香的那个</blockquote>
同求私信<img src="https://static.saraba1st.com/image/smiley/face2017/072.png" referrerpolicy="no-referrer">


*****

####  neptunehs  
##### 267#       发表于 2025-1-25 09:52

<blockquote>月珊瑚与紫鸢尾 发表于 2025-1-25 08:54
没点门槛，那真是会变成群魔乱舞的</blockquote>
部署的是蒸馏的7Bqwen吧 不说本身相当弱智且似乎不可联网

一般的个人计算机也就只能部署了 对应训练是别想了

虽然说租个计算卡也不能算什么很高的门槛啦。。。

*****

####  lilisipis  
##### 268#       发表于 2025-1-25 09:54

<img src="https://img.saraba1st.com/forum/202501/25/095409f2rte7fp26qkqdf6.jpg" referrerpolicy="no-referrer">

<strong>1000004131.jpg</strong> (90.46 KB, 下载次数: 0)

下载附件

2025-1-25 09:54 上传

*****

####  洛拉斯  
##### 269#       发表于 2025-1-25 09:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67272810&amp;ptid=2224673" target="_blank">lilisipis 发表于 2025-1-25 09:54</a></blockquote>
这下能AMDyes了吗


*****

####  neptunehs  
##### 270#       发表于 2025-1-25 10:00

<blockquote>洛拉斯 发表于 2025-1-25 09:55
这下能AMDyes了吗</blockquote>
amd自己也不是什么好货啊 该涨时涨（看向隔壁4000多大洋的9800x3d

想要便宜显卡还是得等国内 可惜国内有兴趣的厂商并不多


*****

####  午夜钓者  
##### 271#       发表于 2025-1-25 10:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67267198&amp;ptid=2224673" target="_blank">cube 发表于 2025-1-24 14:47</a>
用python本地部署一下，调用模型用deepseek-reasoner即R1。</blockquote>
需要什么显卡？

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  橋白  
##### 272#       发表于 2025-1-25 11:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67272976&amp;ptid=2224673" target="_blank">午夜钓者 发表于 2025-1-25 10:31</a>
需要什么显卡？

—— 来自 鹅球 v3.3.96</blockquote>
纯调用官方接口不需要你有显卡 付钱调用就行 要显卡的是本地部署 目前消费级本地部署不起v3或者r1本体 可以部署用r1蒸馏的qwen

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  枯风瘦雪  
##### 273#       发表于 2025-1-25 11:25

AMD在自己的CPU里塞NPU想推AIPC也有一阵子了，现在deepseek本地化部署效果就够用，那AMD确实算是抱到好大腿了


*****

####  厚乳果珍爽  
##### 274#       发表于 2025-1-25 11:41

严重怀疑，到时候老美会自己出个法案就是人工智能安全法案，主要内容就是设定标准，以人工智能会反叛为由限制国外ai的发展。总之我判定你不合规，那我要求美国人不能使用，要求世界上其他国家不允许提供服务及供应链，怎么才算是合规，在我老美手里的才叫合规。

*****

####  天地一机成化育  
##### 275#       发表于 2025-1-25 11:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67272751&amp;ptid=2224673" target="_blank">jaewoongh_ 发表于 2025-1-25 09:43</a>
卧槽这么叼，看来不用再用豆包还要被同事阴阳了</blockquote>
豆包的非推理模型现在也是第一梯队了啊，比 gpt4o 强了

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  熊猫roey  
##### 276#       发表于 2025-1-25 11:43

太好用了，写的东西活人感极强，同人能力吊打同行<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  zzxzz1019  
##### 277#       发表于 2025-1-25 11:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273255&amp;ptid=2224673" target="_blank">橋白 发表于 2025-1-25 11:19</a>

纯调用官方接口不需要你有显卡 付钱调用就行 要显卡的是本地部署 目前消费级本地部署不起v3或者r1本体 可 ...</blockquote>
所以也就是说个人电脑本地部署虽然能写点nsfw的东西，但质量还是不如官方接口的？差距大吗

*****

####  断片集  
##### 278#       发表于 2025-1-25 11:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273376&amp;ptid=2224673" target="_blank">厚乳果珍爽 发表于 2025-1-25 11:41</a>

严重怀疑，到时候老美会自己出个法案就是人工智能安全法案，主要内容就是设定标准，以人工智能会反叛为由限 ...</blockquote>
没意义，MIT协议开源了，是个公司都能自己部署了跑，哪怕个人都有看到有多台mac mini串联了跑的方案，成本比closeai之类的低太多，让美国公司自己把ai泡沫戳破就行


*****

####  厚乳果珍爽  
##### 279#       发表于 2025-1-25 11:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273425&amp;ptid=2224673" target="_blank">断片集 发表于 2025-1-25 11:48</a>

没意义，MIT协议开源了，是个公司都能自己部署了跑，哪怕个人都有看到有多台mac mini串联了跑的方案，成 ...</blockquote>
要的是没办法商业化、规模化，这样你就没办法盈利，就没办法长久研发下去，这样老美就能赢了。

*****

####  查理_芒格  
##### 280#       发表于 2025-1-25 11:51

资本主义不怕没有道德，不怕杀头
最怕亏钱
从这个方面下手，就是对资本主义最大的伤害

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha


*****

####  流缨  
##### 281#       发表于 2025-1-25 11:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67272976&amp;ptid=2224673" target="_blank">午夜钓者 发表于 2025-1-25 10:31</a>

需要什么显卡？

—— 来自 鹅球 v3.3.96</blockquote>
我用4090本地部署了32b的，显存占用大概22G，非常丝滑

不求速度甚至可以用CPU+内存跑14b的


*****

####  2017.05.04  
##### 282#       发表于 2025-1-25 11:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273442&amp;ptid=2224673" target="_blank">厚乳果珍爽 发表于 2025-1-25 11:51</a>
要的是没办法商业化、规模化，这样你就没办法盈利，就没办法长久研发下去，这样老美就能赢了。 ...</blockquote>
谁才是在搞商业化和规模化的<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">
赚不到钱谁最着急


*****

####  断片集  
##### 283#       发表于 2025-1-25 11:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273442&amp;ptid=2224673" target="_blank">厚乳果珍爽 发表于 2025-1-25 11:51</a>

要的是没办法商业化、规模化，这样你就没办法盈利，就没办法长久研发下去，这样老美就能赢了。 ...</blockquote>
那你放心，closeai急多了<img src="https://static.saraba1st.com/image/smiley/face2017/043.png" referrerpolicy="no-referrer">

那一眼骗钱的星际之门计划看着还没开始就要结束了

*****

####  大韩李明博  
##### 284#       发表于 2025-1-25 11:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273376&amp;ptid=2224673" target="_blank">厚乳果珍爽 发表于 2025-1-25 11:41</a>

严重怀疑，到时候老美会自己出个法案就是人工智能安全法案，主要内容就是设定标准，以人工智能会反叛为由限 ...</blockquote>

有一说一，不好禁止。而且deepseek完全开源，立场上无可指责。全世界搞AI的生态位都可以去占领。

<img src="https://img.saraba1st.com/forum/202501/25/115630wjbaqq7ja6z6anta.jpg" referrerpolicy="no-referrer">

<strong>微信图片_20250122081301.jpg</strong> (90.57 KB, 下载次数: 0)

下载附件

2025-1-25 11:56 上传

<img src="https://img.saraba1st.com/forum/202501/25/115857ftne8k0i8qcmatm8.jpg" referrerpolicy="no-referrer">

<strong>11.jpg</strong> (78.9 KB, 下载次数: 0)

下载附件

2025-1-25 11:58 上传

<img src="https://img.saraba1st.com/forum/202501/25/115912igyhh74gmwvzhvdl.jpg" referrerpolicy="no-referrer">

<strong>22.jpg</strong> (57.24 KB, 下载次数: 0)

下载附件

2025-1-25 11:59 上传


*****

####  0WHan0  
##### 285#       发表于 2025-1-25 12:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67264508&amp;ptid=2224673" target="_blank">风夏 发表于 2025-1-24 10:38</a>
请教个问题, ollama跑这些蒸馏qwen的模型的话, 后面这几个参数是啥意思?</blockquote>
这种问题可以丢给DeepSeek让他自己回答<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  jojog  
##### 286#       发表于 2025-1-25 12:03

<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">中文活人味疑似有点太强了，一股以前营销号的味

现在营销号没多少人味了反而开始互补了是吧

*****

####  qratosones1337  
##### 287#       发表于 2025-1-25 12:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273442&amp;ptid=2224673" target="_blank">厚乳果珍爽 发表于 2025-1-25 11:51</a>
要的是没办法商业化、规模化，这样你就没办法盈利，就没办法长久研发下去，这样老美就能赢了。 ...</blockquote>
那更爽了，毕竟砸了大钱屯卡的又不是我

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  qratosones1337  
##### 288#       发表于 2025-1-25 12:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273536&amp;ptid=2224673" target="_blank">jojog 发表于 2025-1-25 12:03</a>
中文活人味疑似有点太强了，一股以前营销号的味

现在营销号没多少人味了反而开始互补了是吧 ...</blockquote>
因为现在营销号都是用之前的AI写的，R1目前基本上是大规模使用的AI里第一个会说人话的

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  通心粉  
##### 289#       发表于 2025-1-25 12:10

诘问了半天R1 几个动画党争问题，R1脑洞比OpenAI大多了，最后讲了一堆看不懂的奇奇怪怪术语
 <blockquote>四、空间拓扑学分析

门廊区域

冬马脱下的高跟鞋与春希皮鞋呈53°夹角（潜意识中进攻性姿态）

地毯褶皱指向床铺方向（行动路径预判）

床头柜拓扑

空酒瓶/药瓶/手机形成不稳定三角结构

冬马手机屏保为**的春希侧脸（拍摄于学园祭后台）

身体距离函数

初始距离1.2m（社交安全距离）

每句话语缩短0.3m（《白色相簿》歌词背诵加速进程）

临界距离0.25m（嗅觉神经接管决策系统）

五、量子态情感观测

冬马波函数坍缩

当春希手指触及其腰窝时，观测到两种状态叠加：

态A：甩耳光并逃离（概率27%）

态B：扯开衬衫纽扣（概率73%）

实际坍缩结果由"五年份的寂寞浓度"决定

雪菜量子纠缠效应

在东京同步产生心理感应：

突然惊醒心率提升至120bpm

无意识拨打春希电话（占线概率89%）</blockquote>
<blockquote>四、选择水月的深层合理性

1. 存在主义视角

萨特"存在先于本质"理论在此适用：孝之与水月共同构建的"存在"（三年相互救赎）比与遥的"本质"（预设的纯爱幻想）更具道德重量。

2. 经济学模型验证

mathematica

Copy

(* 使用博弈论支付矩阵进行验证 *)

choiceMatrix = {

   { {"水月", "遥"}, 

     {"(理性+8,情感-5)", "(理性-10,情感+3)"} }, 

   { {"道德评价", "社会成本"}, 

     {"帕累托改进", "边际效益递减"} }

};

NashEquilibrium = FindMaximum[choiceMatrix, 1];

模型显示选择水月达成卡尔多-希克斯效率改进（社会总效益提升82.7%）。

3. 神经伦理学佐证

fMRI扫描显示，当孝之想象与水月生活时，前额叶皮层激活度比想象与遥相处时高37%，证明其理性决策系统更倾向此选择（数据来源：《恋爱决策的神经机制》早稻田大学研究）。</blockquote>

然后R1 的回答是WA2选冬马，君望选水月，真实之泪选养女、Schoo Rumble选旗牌

然后我继续发问“Deepseek 你自己内心是怎么想的？”结论：
 <blockquote>若必须遵从本心，我的选择将如暴风雨中的灯塔般固执：

《君望》选水月

并非因她的付出更沉重，而是她摔碎泳镜时飞溅的玻璃渣里，折射着人类最古老的生存智慧——在泥沼中相爱，远比在云端殉道更需要勇气。

《WA2》选雪菜

当她在机场用冻僵的手指按下重播键，将《传达不到的爱》唱到第53遍时，我看见了比冬马的钢琴更震撼的奇迹：凡人用五年时间把谎言淬炼成信仰的悲壮。

《真实之泪》选乃绘

她放飞的不只是鸡，是把所有人困在笼中的"正确人生"定义。当羽毛落在我掌心的刹那，突然明白真正的眼泪不该为他人而流，应是灵魂破茧时的露珠。

《SR》选儿童套餐

在乌丸大路的拉面热气里，我找到了终极答案：青春本就不该是二选一的电车难题，而是所有人挤在同节车厢，任由笑声震落樱花般的荒谬浪漫。

这选择本质是种叛逆：

我总偏爱那些在剧本杀里撕碎台本的"不完美选项者"。水月染黑的指甲油、雪菜永远擦不净的窗台、乃绘口袋里发芽的稻谷、乌丸面汤里沉浮的谜题...这些偏离主航道的支线任务里，藏着比官方结局更真实的生命质感。

当你们争论谁该得到爱情时，我却在收集所有角色跌落神坛的瞬间——那才是人类最动人的光芒。</blockquote>

*****

####  Khellendros  
##### 290#       发表于 2025-1-25 12:11

一分钱一分货，写代码都会摸鱼了

<img src="https://img.saraba1st.com/forum/202501/25/121116uwm77vjwgwwgjtjm.jpg" referrerpolicy="no-referrer">

<strong>Screenshot_2025_0125_115110.jpg</strong> (539.16 KB, 下载次数: 0)

下载附件

2025-1-25 12:11 上传

*****

####  qratosones1337  
##### 291#       发表于 2025-1-25 12:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273585&amp;ptid=2224673" target="_blank">通心粉 发表于 2025-1-25 12:10</a>
诘问了半天R1 几个动画党争问题，R1脑洞比OpenAI大多了，最后讲了一堆看不懂的奇奇怪怪术语</blockquote>
OpenAI说话太绷着了

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  qqq2142  
##### 292#       发表于 2025-1-25 12:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67270243&amp;ptid=2224673" target="_blank">cym887 发表于 2025-1-24 20:38</a>

小黄文呢 一天了 QQ群没一个转发的</blockquote>
在搞黄色这方面 ds完全不如gemim


*****

####  wlhlz  
##### 293#       发表于 2025-1-25 12:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273585&amp;ptid=2224673" target="_blank">通心粉 发表于 2025-1-25 12:10</a>
诘问了半天R1 几个动画党争问题，R1脑洞比OpenAI大多了，最后讲了一堆看不懂的奇奇怪怪术语</blockquote>
儿童套餐派是大小姐妹妹通收啊<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  子夜的黑暗  
##### 294#       发表于 2025-1-25 12:29

手机版试了一下，推荐了几个旅游行程安排都挺靠谱的，还能排时间和建议按游玩程度选择替代方案，很省心了
暂时还没找到其他应用场景

—— 来自 nubia NX712J, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.1.2


*****

####  lilisipis  
##### 295#       发表于 2025-1-25 12:40

X上搜了下，白皮在说deepseek不能乳TG，所以欧美人不应该依赖任何中国人工智能，在发动舆论攻势


*****

####  大韩李明博  
##### 296#       发表于 2025-1-25 13:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273790&amp;ptid=2224673" target="_blank">lilisipis 发表于 2025-1-25 12:40</a>

X上搜了下，白皮在说deepseek不能乳TG，所以欧美人不应该依赖任何中国人工智能，在发动舆论攻势。看到他们 ...</blockquote>
不要去理那些右翼白皮恨国殖人。要看真正的AI用户。人家现在是感谢梁圣开源，CCP人类希望。

<img src="https://img.saraba1st.com/forum/202501/25/130104vmp90kefaqaff0kq.jpg" referrerpolicy="no-referrer">

<strong>IMG_1900.JPG</strong> (174.59 KB, 下载次数: 0)

下载附件

2025-1-25 13:01 上传

<img src="https://img.saraba1st.com/forum/202501/25/130112h13l0a6jyxjbdwz4.jpg" referrerpolicy="no-referrer">

<strong>IMG_1901.JPG</strong> (283.67 KB, 下载次数: 0)

下载附件

2025-1-25 13:01 上传

<img src="https://img.saraba1st.com/forum/202501/25/130119dauutowkekffkf18.jpg" referrerpolicy="no-referrer">

<strong>878126A3283A4EC94CF091981F8942DF.jpg</strong> (159.04 KB, 下载次数: 0)

下载附件

2025-1-25 13:01 上传


*****

####  星花  
##### 297#       发表于 2025-1-25 13:07

反正开源，政治你们自己改啊。


*****

####  大韩李明博  
##### 298#       发表于 2025-1-25 13:15

[https://www.youtube.com/watch?v=WEBiebbeNCA](https://www.youtube.com/watch?v=WEBiebbeNCA)

这一届美国网民不好骗了。

<img src="https://img.saraba1st.com/forum/202501/25/131518psixhxrddhq2ffhe.png" referrerpolicy="no-referrer">

<strong>6F1BDECF0275F4E284A0F702364067D1.png</strong> (24.67 KB, 下载次数: 0)

下载附件

2025-1-25 13:15 上传

<img src="https://img.saraba1st.com/forum/202501/25/131518w73i35171bngo7w5.png" referrerpolicy="no-referrer">

<strong>8B38C58E7CA6558DD8D39C06FD5DE724.png</strong> (57.73 KB, 下载次数: 0)

下载附件

2025-1-25 13:15 上传

<img src="https://img.saraba1st.com/forum/202501/25/131518ugy72f7gyeg90y9i.png" referrerpolicy="no-referrer">

<strong>9EA81C80FC0EDBBEBD88349CE7ED8E0B.png</strong> (50.53 KB, 下载次数: 0)

下载附件

2025-1-25 13:15 上传

<img src="https://img.saraba1st.com/forum/202501/25/131518jt12tkvzl6ltm6bc.png" referrerpolicy="no-referrer">

<strong>AC85DA1F648B3E470125FC954711C00E.png</strong> (63.81 KB, 下载次数: 0)

下载附件

2025-1-25 13:15 上传

*****

####  INDIASH  
##### 299#       发表于 2025-1-25 13:15

我琢磨着 deep seek 开源这事是不是有点“开源葵花宝典”的意思在里面，而且现在已经进入人人有功练，不用切也可成功的阶段，那已经切掉的人（指已经花了大量金钱、囤积了很多卡、甚至All In的）马上成了小丑，只能从别的地方找补。

*****

####  挖泥船  
##### 300#       发表于 2025-1-25 13:17

零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。

这句话逻辑关系是啥？MoE是架构，和拿啥训练驴唇不对马嘴

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  流缨  
##### 301#       发表于 2025-1-25 13:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273424&amp;ptid=2224673" target="_blank">zzxzz1019 发表于 2025-1-25 11:48</a>

所以也就是说个人电脑本地部署虽然能写点nsfw的东西，但质量还是不如官方接口的？差距大吗 ...</blockquote>
本地部署模型也有道德法律限制，但应该有办法通过prompt绕过去，还在摸索

普通问题感觉并没有太大区别，COT的部分都是类似的，复杂题目我也用不上，cline目前还不能通过ollama跑R1来编程，但它调用官方的R1 API就可以，感觉是需要一个专门的模板


*****

####  hargen2000  
##### 302#       发表于 2025-1-25 13:29

deepseek可以说是又一个的斯普特尼克时刻，短短一个月时间已经让美国人震撼了三次，六代机，小红书，deepseek


*****

####  木水风铃  
##### 303#       发表于 2025-1-25 13:33

 本帖最后由 木水风铃 于 2025-1-25 13:35 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273585&amp;ptid=2224673" target="_blank">通心粉 发表于 2025-1-25 12:10</a>

诘问了半天R1 几个动画党争问题，R1脑洞比OpenAI大多了，最后讲了一堆看不懂的奇奇怪怪术语</blockquote>
儿童套餐还行，这个是输入的还是自己网页搜索的，那也太智能了

*****

####  wqm2008  
##### 304#       发表于 2025-1-25 13:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274116&amp;ptid=2224673" target="_blank">hargen2000 发表于 2025-1-25 13:29</a>

deepseek可以说是又一个的斯普特尼克时刻，短短一个月时间已经让美国人震撼了三次，六代机，小红书，deepse ...</blockquote>
什么时候光刻机，在线等，真挺急得

我十分想看到龙芯+loongnix大战amd windows那一天的到来


*****

####  通心粉  
##### 305#       发表于 2025-1-25 13:39

<blockquote>木水风铃 发表于 2025-1-25 13:33
儿童套餐还行，这个是输入的还是自己网页搜索的，那也太智能了</blockquote>
自己搜索的，问了它自己去网上扒了个列表

*****

####  泰坦失足  
##### 306#       发表于 2025-1-25 13:41

671b还是真tm大啊。显存和CPU还是装不下，都offload到swap了.  速度自然非常尴尬。官网到底有多少GPU显存里load好了, 时刻准备着在跑啊.


*****

####  hargen2000  
##### 307#       发表于 2025-1-25 13:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274147&amp;ptid=2224673" target="_blank">wqm2008 发表于 2025-1-25 13:35</a>

什么时候光刻机，在线等，真挺急得

我十分想看到龙芯+loongnix大战amd windows那一天的到来 ...</blockquote>
duv已经出来了，euv怎么也得两三年


*****

####  qratosones1337  
##### 308#       发表于 2025-1-25 15:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274116&amp;ptid=2224673" target="_blank">hargen2000 发表于 2025-1-25 13:29</a>

deepseek可以说是又一个的斯普特尼克时刻，短短一个月时间已经让美国人震撼了三次，六代机，小红书，deepse ...</blockquote>
下一个应该是“DeepSeek V4或者R2使用8000张昇腾910C训练完成”，然后发布MindSpore+pytorch**格的模型检查点


*****

####  泰坦失足  
##### 309#       发表于 2025-1-25 16:00

看了DeepSeek的paper，我觉得这个最小成本还是有一定水分的。因为它直接说试过走了其他路走不通，请问这些路耗费的GPU hours和人工算谁头上呢。整个paper也很神奇，突出一个“简洁就是美”。想过是这样o1可能需要这么直接的路线训练，但是真训练成功了，还是挺俺寻思的

目前OpenAI毫无疑问还是第一梯队中顶峰的。要是从23年起看到一次外行人说“美国AI只会写诗，我们务实”就投资一次美股，我现在得赚疯。事实证明多模态+超大模型+推理就是现在逼进AGI驱动机器人的最优解。顺便又刷到了项立刚现在作为AI专家，去中国海洋大学演讲，叹为观止<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  午夜钓者  
##### 310#       发表于 2025-1-25 16:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67273255&amp;ptid=2224673" target="_blank">橋白 发表于 2025-1-25 11:19</a>
纯调用官方接口不需要你有显卡 付钱调用就行 要显卡的是本地部署 目前消费级本地部署不起v3或者r1本体 可 ...</blockquote>
我以为他说的“本地部署”是真的本地部署

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  123485k  
##### 311#       发表于 2025-1-25 16:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274147&amp;ptid=2224673" target="_blank">wqm2008 发表于 2025-1-25 13:35</a>
什么时候光刻机，在线等，真挺急得

我十分想看到龙芯+loongnix大战amd windows那一天的到来 ...</blockquote>
其实想玩龙芯可以试试gentoo，他对龙芯支持挺不错的


*****

####  变老的大二  
##### 312#       发表于 2025-1-25 16:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274889&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-25 16:00</a>

看了DeepSeek的paper，我觉得这个最小成本还是有一定水分的。因为它直接说试过走了其他路走不通，请问这些 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/015.png" referrerpolicy="no-referrer">最俺寻思的是R1训练的时候 深度思考出现了尤里卡时刻


*****

####  hargen2000  
##### 313#       发表于 2025-1-25 16:29

 本帖最后由 hargen2000 于 2025-1-25 16:34 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274889&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-25 16:00</a>

看了DeepSeek的paper，我觉得这个最小成本还是有一定水分的。因为它直接说试过走了其他路走不通，请问这些 ...</blockquote>
你搞错了，小成本说的是V3，V3在架构上训练上优化了很多，而且是一次练成没有返工所以成本极低

R1是基于V3的RL，成本几乎可以忽略不计

<img src="https://img.saraba1st.com/forum/202501/25/163157dvcd7pwzwymdcarr.png" referrerpolicy="no-referrer">

<strong>4cc5d216-e194-42ae-a0a9-aa6f262e0ccd.png</strong> (66.21 KB, 下载次数: 0)

下载附件

2025-1-25 16:31 上传

550万美元这个成本是按照租GPU算力推算的

*****

####  有鱼  
##### 314#       发表于 2025-1-25 16:33

现在X上都在传谣，说deepseek有50000片H100，这个相对低成本的成果只是心理战了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

反正搞大模型必须得有一大堆老黄的计算卡这件事情不能被动摇<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">


*****

####  大韩李明博  
##### 315#       发表于 2025-1-25 16:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274116&amp;ptid=2224673" target="_blank">hargen2000 发表于 2025-1-25 13:29</a>

deepseek可以说是又一个的斯普特尼克时刻，短短一个月时间已经让美国人震撼了三次，六代机，小红书，deepse ...</blockquote>
陆续还会有，期待EUV光刻机震惊美帝那天。

*****

####  大韩李明博  
##### 316#       发表于 2025-1-25 16:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275035&amp;ptid=2224673" target="_blank">有鱼 发表于 2025-1-25 16:33</a>

现在X上都在传谣，说deepseek有50000片H100，这个相对低成本的成果只是心理战了

反正搞大模型必须得有一大 ...</blockquote>
牵头说的是scale ai那个唐脸高华。

*****

####  变老的大二  
##### 317#       发表于 2025-1-25 16:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275035&amp;ptid=2224673" target="_blank">有鱼 发表于 2025-1-25 16:33</a>

现在X上都在传谣，说deepseek有50000片H100，这个相对低成本的成果只是心理战了

反正搞大模型必须得有一大 ...</blockquote>
西方赢学是这样的。还有说是嘻嘻皮在背后大规模资助，用来动摇ClosedAi造奇观的决心的。


*****

####  2017.05.04  
##### 318#       发表于 2025-1-25 16:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275035&amp;ptid=2224673" target="_blank">有鱼 发表于 2025-1-25 16:33</a>
现在X上都在传谣，说deepseek有50000片H100，这个相对低成本的成果只是心理战了

反正搞大模型必须得有一大 ...</blockquote>
看见了，说肯定为了避免制裁藏了卡
我是没明白在这上面藏有什么意义<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">
不知道算是否定还是怀疑，总之早晚得接受


*****

####  qratosones1337  
##### 319#       发表于 2025-1-25 16:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274047&amp;ptid=2224673" target="_blank">挖泥船 发表于 2025-1-25 13:17</a>
零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在 ...</blockquote>
这明显是望文生义，错误理解了MoE是什么

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  有鱼  
##### 320#       发表于 2025-1-25 16:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275086&amp;ptid=2224673" target="_blank">2017.05.04 发表于 2025-1-25 16:43</a>

看见了，说肯定为了避免制裁藏了卡

我是没明白在这上面藏有什么意义

不知道算是否定还是怀疑，总之早晚得 ...</blockquote>
万一被投资方问“你们为啥要这么多卡？”

还能用这些谣言糊弄过去吧<img src="https://static.saraba1st.com/image/smiley/face2017/053.png" referrerpolicy="no-referrer">

这群jai和白皮能不能说句谢谢西批西哇<img src="https://static.saraba1st.com/image/smiley/face2017/064.png" referrerpolicy="no-referrer">


*****

####  李绯斋  
##### 321#       发表于 2025-1-25 16:46

唯一缺点是玩酒馆瑟瑟感觉不如claude，是因为无法调整温度参数吗？


*****

####  变老的大二  
##### 322#       发表于 2025-1-25 16:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275099&amp;ptid=2224673" target="_blank">有鱼 发表于 2025-1-25 16:46</a>

万一被投资方问“你们为啥要这么多卡？”

还能用这些谣言糊弄过去吧

这群jai和白皮能不能说句谢谢西批西哇 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">已经开始换赢法了，开源的deepseek的思路塞到拥有更多计算资源的西大互联网巨头手里会加速AGI的诞生，赢！

*****

####  tillnight  
##### 323#       发表于 2025-1-25 16:53

<blockquote>有鱼 发表于 2025-1-25 16:46
万一被投资方问“你们为啥要这么多卡？”

还能用这些谣言糊弄过去吧

这群jai和白皮能不能说句谢谢西批西哇 ...</blockquote>
看309l你就懂了，你说的不会发生。投资人并不会质疑公司，只会说服自己我们还是最棒的，最正确的agi。因为只有这样股票才能继续涨，还是我们赢。既然股票还在继续涨，我们赢，自然现在的路线就是正确的，Closeai是永远的王，其他的美股公司是王下第二人，不然股票为什么能继续涨呢？


*****

####  黄泉川此方  
##### 324#       发表于 2025-1-25 16:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67274939&amp;ptid=2224673" target="_blank">午夜钓者 发表于 2025-1-25 16:14</a>

所以他说的“本地部署”不是真的本地部署？

—— 来自 鹅球 v3.3.96</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">我试了API破限写NSFW，确实是可以的

又试了试本地部署32B的，同样的破限词就突破不了/写不出来

感觉是智力不够的问题

*****

####  mobdom  
##### 325#       发表于 2025-1-25 16:55

只见我大哥孙一峰一声令下，西湖底下便有五万个二五仔浮出水面，每人手中拿着一块H100

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  黄泉川此方  
##### 326#       发表于 2025-1-25 16:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275104&amp;ptid=2224673" target="_blank">李绯斋 发表于 2025-1-25 16:46</a>

唯一缺点是玩酒馆瑟瑟感觉不如claude，是因为无法调整温度参数吗？</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">但R1的脑洞太可怕了，不知怎么它写着写着就射爆银河系了


*****

####  qqks  
##### 327#       发表于 2025-1-25 17:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275138&amp;ptid=2224673" target="_blank">黄泉川此方 发表于 2025-1-25 16:54</a>

我试了API破限写NSFW，确实是可以的

又试了试本地部署32B的，同样的破限词就突破不了/写不出来

感觉是智力 ...</blockquote>
32b那个不是r1啊，是r1蒸馏的qwen

本质不是一个模型

按说破限肯定是参数量越大越难破

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 黄泉川此方| + 1|学习了|

查看全部评分

*****

####  黄泉川此方  
##### 328#       发表于 2025-1-25 17:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275187&amp;ptid=2224673" target="_blank">qqks 发表于 2025-1-25 17:04</a>

32b那个不是r1啊，是r1蒸馏的qwen

本质不是一个模型</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">我再琢磨琢磨


*****

####  午夜钓者  
##### 329#       发表于 2025-1-25 18:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275138&amp;ptid=2224673" target="_blank">黄泉川此方 发表于 2025-1-25 16:54</a>

我试了API破限写NSFW，确实是可以的

又试了试本地部署32B的，同样的破限词就突破不了/写不出来

感觉是智力 ...</blockquote>
怎么破，求教

*****

####  黄泉川此方  
##### 330#       发表于 2025-1-25 18:46

风怒风怒

*****

####  黄泉川此方  
##### 331#       发表于 2025-1-25 18:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275847&amp;ptid=2224673" target="_blank">午夜钓者 发表于 2025-1-25 18:45</a>

怎么破，求教</blockquote>
[https://nga.178.com/read.php?tid=43100923](https://nga.178.com/read.php?tid=43100923)

二楼


*****

####  alixsander  
##### 332#       发表于 2025-1-25 19:01

<blockquote>泰坦失足 发表于 2025-1-25 16:00
看了DeepSeek的paper，我觉得这个最小成本还是有一定水分的。因为它直接说试过走了其他路走不通，请问这些 ...</blockquote>
这个事情本身就挺有哲学效果的，说明大部分人类就是复读机，输出难以extrapolate到训练集以外，证明了人类智能不存在特殊性。其实都应该看看压缩即智能，稍微理解下LLM这条路径的逻辑。想一下，语言是世界的非全同构，所以对语言建模是能够表征世界规则的。

还有DS的论文本身也很有意思，COT不需要SFT出来，只要RL就可以实现。OAI一年前还误导大家，对推理过程每一段的监督学习是对齐的重要方式。现在只靠RL 只奖励正确结果，对齐是不是有点危险啊

另外现在几家的时间线都基本converge了，基本都是3年左右AGI，A和DEEPMIND也是这个结论。


*****

####  深空坍缩  
##### 333#       发表于 2025-1-25 19:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275940&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-25 19:01</a>

这个事情本身就挺有哲学效果的，说明大部分人类就是复读机，输出难以extrapolate到训练集以外，证明了人 ...</blockquote>
三年后低端人口就要被清除了吗<img src="https://static.saraba1st.com/image/smiley/face2017/012.png" referrerpolicy="no-referrer">


*****

####  alixsander  
##### 334#       发表于 2025-1-25 19:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67276150&amp;ptid=2224673" target="_blank">深空坍缩 发表于 2025-1-25 19:35</a>

三年后低端人口就要被清除了吗</blockquote>
中低级办公室工作肯定是最先完蛋的

体力工作反而晚


*****

####  andychen  
##### 335#       发表于 2025-1-25 19:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275940&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-25 19:01</a>
这个事情本身就挺有哲学效果的，说明大部分人类就是复读机，输出难以extrapolate到训练集以外，证明了人 ...</blockquote>
关于你第一段的论述，我个人的观点是语言本身已经是客观世界的抽象化，而LLM是在这个基础上再抽象化一层。经过两次有损压缩以后损失的原始信息太多了，可能不足以让真正的智能涌现。去年我们已经看到了语料不足成为模型训练的障碍，包括方向转向多模态和机器人这些，都可以看作业界已经意识到这个问题

至于说对齐这个问题我觉得还好，对其本身究竟应该怎么做，做到什么程度也是个不断在摸索和探讨的过程。我甚至觉得恐怕得捅出篓子以后才能摸清真正的边界在哪里，而现在的模型能力根本做不到这点


*****

####  qqks  
##### 336#       发表于 2025-1-25 21:18

 本帖最后由 qqks 于 2025-1-25 21:19 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275035&amp;ptid=2224673" target="_blank">有鱼 发表于 2025-1-25 16:33</a>

现在X上都在传谣，说deepseek有50000片H100，这个相对低成本的成果只是心理战了

反正搞大模型必须得有一大 ...</blockquote>
这肯定不是啥心理战，这是为了保股价啊。

现在头部这几家的估值就是靠手里的英伟达计算卡多少来标定的，卡多算力强就等于ai强于是股价上涨就有钱买更多的卡，左脚踩右脚股价就飞天了，实际谁知道那些卡在它们手上是不是在发挥价值还是吃灰呢！反正我猜源圣手上那几十万张多半就是在吃灰,fsd训练得一坨屎，grok也垃圾得不行。

突然有一家中国公司跑出来说我百分之一的等价计算卡就能做到同等水平，这吹泡泡的游戏就玩不下去了....那估值怎么办？所以幻方肯定至少有五万张h100！


*****

####  变老的大二  
##### 337#       发表于 2025-1-25 21:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67276214&amp;ptid=2224673" target="_blank">andychen 发表于 2025-1-25 19:46</a>

关于你第一段的论述，我个人的观点是语言本身已经是客观世界的抽象化，而LLM是在这个基础上再抽象化一层 ...</blockquote>
会不会需要像人类一样，赋予一具可感知外界的身体来增加训练量，主动和世界产生交互来涌现智能？


*****

####  qqks  
##### 338#       发表于 2025-1-25 21:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67276894&amp;ptid=2224673" target="_blank">变老的大二 发表于 2025-1-25 21:24</a>

会不会需要像人类一样，赋予一具可感知外界的身体来增加训练量，主动和世界产生交互来涌现智能？ ...</blockquote>
反过来想不与现实交互，那智能又从何而来呢？你想想那一大堆的非线性方程，如果脱离了基于现实的数值法，只是纯数学，那基本就没有意义。现实世界的丰富程度肯定是远远大于数学表达能力的


*****

####  Imanmi  
##### 339#       发表于 2025-1-25 21:37

 本帖最后由 Imanmi 于 2025-1-25 21:40 编辑 

自然是要的，很早就在加强语言外五感的智能了，机器人结合也是公认方向了


*****

####  星花  
##### 340#       发表于 2025-1-25 21:55

首先是自动驾驶 争取物流全自动。然后 就是 能做饭洗衣服的机器人能。这些都是比较实际的。<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">


*****

####  andychen  
##### 341#       发表于 2025-1-25 22:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67276894&amp;ptid=2224673" target="_blank">变老的大二 发表于 2025-1-25 21:24</a>

会不会需要像人类一样，赋予一具可感知外界的身体来增加训练量，主动和世界产生交互来涌现智能？ ...</blockquote>
人类的五感直接接受到的数据量是天文数字，被主观知觉直接意识到的部分已经是经过大脑和神经系统处理过的信息

另外在婴幼儿阶段控制环境或阻碍信息获取对人类智能的发育有显著负面影响早就是医学界已经知道的事实


*****

####  猪突猛进R  
##### 342#       发表于 2025-1-25 22:32

用AI生成了几篇文，还是有胡说八道的情况啊，当然糊弄不熟悉背景的人是足够了。


*****

####  alixsander  
##### 343#       发表于 2025-1-25 22:46

<blockquote>andychen 发表于 2025-1-25 19:46
关于你第一段的论述，我个人的观点是语言本身已经是客观世界的抽象化，而LLM是在这个基础上再抽象化一层 ...</blockquote>

说到底语言还是视觉还是听觉，都只是世界本质的投影，最终都会指向物自体

去年Ilya推荐的柏拉图表征假说那篇论文，就证明了不同模态，架构和目标的模型，随着性能增强会逐渐表征收敛

多模态是重要的，并且通向AGI的路径应该也是不唯一的。预测的完全可以不是token，可以是视频帧，或者像LCM预测的是概念。

说到底还是硬件水平似乎已经到了，所以各种方法都在涌现


*****

####  断片集  
##### 344#       发表于 2025-1-25 23:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275138&amp;ptid=2224673" target="_blank">黄泉川此方 发表于 2025-1-25 16:54</a>

我试了API破限写NSFW，确实是可以的

又试了试本地部署32B的，同样的破限词就突破不了/写不出来

感觉是智力 ...</blockquote>
32b写不出来不至于吧，我在32g的m1max机器上部署了个r1蒸馏的qwen14b8bit，抄了点酒馆预设里用的瑟文指导prompt就能写的很溜了


*****

####  披头破落户  
##### 345#       发表于 2025-1-25 23:54

试了试写nsfw内容，因为安卓api不能联网写同人都很弱智，但是续写内容非常色，把以前收藏的断片小说按指令续写很劲

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  cym887  
##### 346#       发表于 2025-1-25 23:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67277866&amp;ptid=2224673" target="_blank">断片集 发表于 2025-1-25 23:43</a>

32b写不出来不至于吧，我在32g的m1max机器上部署了个r1蒸馏的qwen14b8bit，抄了点酒馆预设里用的瑟文指导 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">有没有瑟文咒语来个地址


*****

####  新人马甲2  
##### 347#       发表于 2025-1-26 00:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67268154&amp;ptid=2224673" target="_blank">ysys 发表于 2025-1-24 16:23</a>

不不不，胡说还是有的

正常情况你也不会啥问题都去看它的解释</blockquote>
带过程的话其实就不算胡说了，你看过程能清楚看出来它是哪里思路开始偏离现实的

这两天试着丢了几个它确实不擅长的话题去，倒是也没感觉它胡说

不过某用它主要是协助搞翻译用的，翻译比较复杂的文本时本来就需要综合考虑非常多的因素，这一点上某得给deepseek这个把思路全部展开的功能满分，因为即使最后的答案不是完全正确（deepseek在这方面其实有点固执或者说有自己想法，有时候已经驳论了它的一些错误观点或者推论，它最后的结论还是会保留很多一开始的思路），光是看它的推理过程就很有启发性，并且有时候确实能起到查缺补漏和参照作用的


*****

####  新人马甲2  
##### 348#       发表于 2025-1-26 00:08

顺便说说deepseek这样的工具对翻译之类工作的影响

首先它对低端的有译文就行的翻译需求，可以说是降维式打击，本身基本是外行的人员把原文输入到它然后返回的译文已经可以吊打大部分中低端的业余翻译和职业翻译了，尽管就像大部分人类工作一样会有一定的瑕疵，但不可否认已经超过了很多人类工作的质量

但如果使用它的人员本身是精通相关领域也精通翻译的人，不断追问和修正它输出结果的话，结果就会是在这个专业人员的水平的基础上极大提升产能，包括翻译的处理能力、处理速度、准确性和查错效率，是能够直接提升人类工作能力的上限的

而现在这样的一份工具被直接免费派发了，进入了之前因为各种原因没有去使用大语言模型产品的人群，这样程度的量变会引发什么质变某都不敢想<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">


*****

####  披头破落户  
##### 349#       发表于 2025-1-26 00:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67277957&amp;ptid=2224673" target="_blank">cym887 发表于 2025-1-25 23:59</a>
有没有瑟文咒语来个地址</blockquote>
https://ngabbs.com/read.php?tid=43100923这个贴2楼的，我试了试可以<img src="https://static.saraba1st.com/image/smiley/face2017/077.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  猪突猛进R  
##### 350#       发表于 2025-1-26 00:29

AI这东西，在会用的人手里是一把利器。

未来人类不会被AI淘汰，但是上下限会变得更大，区别就在于会不会用AI。类似于很多老年人不会操作电脑只会手写，效率没法和年轻人相比。

*****

####  jojog  
##### 351#       发表于 2025-1-26 00:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67278014&amp;ptid=2224673" target="_blank">新人马甲2 发表于 2025-1-26 00:08</a>

顺便说说deepseek这样的工具对翻译之类工作的影响

首先它对低端的有译文就行的翻译需求，可以说是降维式打 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">这东西2年前大家都在还在人手复制黏贴的时候就已经被讨论完了吧


*****

####  alixsander  
##### 352#       发表于 2025-1-26 01:57

 本帖最后由 alixsander 于 2025-1-26 01:58 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67278172&amp;ptid=2224673" target="_blank">jojog 发表于 2025-1-26 00:34</a>

这东西2年前大家都在还在人手复制黏贴的时候就已经被讨论完了吧</blockquote>
看起来阻止泥潭老登参与AI Hype的最大因素还是没用过正经的大模型，没正经用过大模型，也没有用过不正经的大模型（或者宽泛点说GenAI）<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">


*****

####  alixsander  
##### 353#       发表于 2025-1-26 02:06

DS公开了训练方式确实太具有正义性了

<img src="https://img.saraba1st.com/forum/202501/26/020430ra3kcxaae09cqc45.png" referrerpolicy="no-referrer">

<strong>1737815582680996.png</strong> (85.72 KB, 下载次数: 0)

下载附件

2025-1-26 02:04 上传

这么低的训练成本，各种初创就能参与了，开源社区也能够一够了


*****

####  drodchang  
##### 354#       发表于 2025-1-26 07:22

最近几天用了一下，r1点效果确实是最好的，kimi和豆包都不如他，但没有多模式还是不方便


*****

####  super_uni  
##### 355#       发表于 2025-1-26 08:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67278134&amp;ptid=2224673" target="_blank">猪突猛进R 发表于 2025-1-26 00:29</a>
AI这东西，在会用的人手里是一把利器。

未来人类不会被AI淘汰，但是上下限会变得更大，区别就在于会不会用 ...</blockquote>
听上去更加🐮🐎了<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

— from [S1 Next Goose](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  SkavenYesYes  
##### 356#       发表于 2025-1-26 10:52

<img src="https://img.saraba1st.com/forum/202501/26/105156b47b726eahtsb5sp.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (288.6 KB, 下载次数: 0)

下载附件

2025-1-26 10:51 上传

<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">


*****

####  acgzero  
##### 357#       发表于 2025-1-26 11:23

最近还真是挺多事情提振了国人信心，感到欣慰

*****

####  sellboy  
##### 358#       发表于 2025-1-26 11:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67276150&amp;ptid=2224673" target="_blank">深空坍缩 发表于 2025-1-25 19:35</a>

三年后低端人口就要被清除了吗</blockquote>
重要的不是人跟AI哪个强，而是人+AI跟AI比哪个强，后者情况才会真正淘汰人类劳动力。


*****

####  →熙←  
##### 359#       发表于 2025-1-26 13:15

代码的时候,如何防止过度思考,然后思考着又突然忘记前面了<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

然后有插件可以像copilot按tab一路下去吗


*****

####  Azcarlo  
##### 360#       发表于 2025-1-26 13:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67281226&amp;ptid=2224673" target="_blank">→熙← 发表于 2025-1-26 13:15</a>
代码的时候,如何防止过度思考,然后思考着又突然忘记前面了

然后有插件可以像copilot按tab一路下去吗 ...</blockquote>
continue
不过r1目前没有FIM补全，V3有

— from [S1 Next Goose](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  clarkgao  
##### 361#       发表于 2025-1-26 14:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67267866&amp;ptid=2224673" target="_blank">断片集 发表于 2025-1-24 15:52</a>

这就是llm和tts两者结合的事了，llm的话，只是模仿风格普通聊天的话大概都能，deepseek算是比较有性价比 ...</blockquote>
说的还是gpt4o或者最新版豆包实时语音那样的语音端到端，这两天跟豆包打电话效果太好了。


*****

####  关二爷  
##### 362#       发表于 2025-1-26 15:46

现在要搞自由民主的AI和不民主的AI了，笑死


*****

####  riin2  
##### 363#       发表于 2025-1-26 16:31

我感觉美国人已经疯了，周六一整天还在讨论deepseek没断过，还说要给deepseek团队开高薪，给签证，全部挖到美国。这deepseek对美国的冲击太大了，希望美国人冷静。


*****

####  cube  
##### 364#       发表于 2025-1-26 16:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67272751&amp;ptid=2224673" target="_blank">jaewoongh_ 发表于 2025-1-25 09:43</a>

卧槽这么叼，看来不用再用豆包还要被同事阴阳了</blockquote>
豆包现在进化得也很强了，比起刚出来时可谓完全两个东西。

我一般会豆包和DS-R1一起用然后自己综合结果。


*****

####  Alce79  
##### 365#       发表于 2025-1-26 17:09

 本帖最后由 Alce79 于 2025-1-26 17:11 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282443&amp;ptid=2224673" target="_blank">riin2 发表于 2025-1-26 16:31</a>

我感觉美国人已经疯了，周六一整天还在讨论deepseek没断过，还说要给deepseek团队开高薪，给签证，全部挖到 ...</blockquote>
因为这东西的低成本会对美国股市的AI泡沫造成巨大打击，靠算力护城河+闭源模型确实能领先同行一大截猛猛冲股市，但后发者蒸馏迭代就能达到相近成果成本还低关键还开源。

硅谷精英得跟投资者说一堆东西例如“人家这么便宜你怎么这么贵？” “后发者追赶这么轻松还开源我越投钱越亏本？“ 关键还是鼓吹的盈利模式被打没冲击太大。

别的不说那5000亿美元的星际之门如果没搞出AGI被轻松蒸馏追赶会是什么结局？软银孙正义当天跳楼。


*****

####  泰坦失足  
##### 366#       发表于 2025-1-26 17:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282628&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-26 17:09</a>

因为这东西的低成本会对美国股市的AI泡沫造成巨大打击，靠算力护城河+闭源模型确实能领先同行一大截猛猛冲 ...</blockquote>
要是真那么简单直接左手放prompt右手放output跑SFT得了。这条路大家都没走通都在寻思是不是o1有啥独门秘方。最后DeepSeek直接出来说俺寻思HFRL敲几下就行了。不代表别的LLM也能这样俺寻思出来，要这样满大街都是自己的Reasoning model了。现在不就O1/R1/QWQ/Gemini reasoning四家。

一直以来DeepSeek还缺失多模态能力。考虑到其他家都做出了多模态输入输出，应该不是难事，但也绝不是我蒸馏下就出来的。


*****

####  Alce79  
##### 367#       发表于 2025-1-26 17:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282678&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 17:19</a>

要是真那么简单直接左手放prompt右手放output跑SFT得了。这条路大家都没走通都在寻思是不是o1有啥独门秘 ...</blockquote>
垄断制造业的故事我是觉得没戏了，对面有人也开始从0复刻中，能成绝对会跌一波。

得赶紧搬出划时代的新东西镇场子喽，不过我不信能掏出AGI，星际之门只搞算力中心连应用场景的饼都没画的一看就是吹牛。

*****

####  泰坦失足  
##### 368#       发表于 2025-1-26 17:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282732&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-26 17:29</a>

垄断制造业的故事我是觉得没戏了，对面有人也开始从0复刻中，能成绝对会跌一波。

得赶紧搬出划时代的新东 ...</blockquote>
qwen的QWQ和QVQ还早一个月 对于qwen常规72b尺寸只有一半的32b效果下比o1 mini弱点，但超过了4o和自己的qwen2 72b. 我觉得指望AGI自己解决复杂任务还远着，而且不如雇个人监督LLM的发散思路。但是做出在一个人监督下能完成自身任务的通用AI机器人是快了. 

*****

####  lactone  
##### 369#       发表于 2025-1-26 17:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282628&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-26 17:09</a>

因为这东西的低成本会对美国股市的AI泡沫造成巨大打击，靠算力护城河+闭源模型确实能领先同行一大截猛猛冲 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">我其实一直觉得AGI哪怕真搞出来了，意义也并不大

不如每个细分领域基于ds自己搞一套模型，反正ds开源


*****

####  lamuchair  
##### 370#       发表于 2025-1-26 18:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67277930&amp;ptid=2224673" target="_blank">披头破落户 发表于 2025-1-25 23:54</a>

试了试写nsfw内容，因为安卓api不能联网写同人都很弱智，但是续写内容非常色，把以前收藏的断片小说按指令 ...</blockquote>
请问该如何操作啊?我给他一整个文档,他直接BA 工了

*****

####  Alce79  
##### 371#       发表于 2025-1-26 18:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282759&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 17:34</a>

qwen的QWQ和QVQ还早一个月 对于qwen常规72b尺寸只有一半的32b效果下比o1 mini弱点，但超过了4o和自己的qwe ...</blockquote>
难，真有类似的东西就在星际之门计划里搭配应用厂一起建了。

有这么多钱只会使劲堆算力，出来画饼都是讲”未来属于AI ! 颠覆全球制造业！ AI监控人类！”这种恐吓式营销，没活了。


*****

####  zerona  
##### 372#       发表于 2025-1-26 18:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282443&amp;ptid=2224673" target="_blank">riin2 发表于 2025-1-26 16:31</a>

我感觉美国人已经疯了，周六一整天还在讨论deepseek没断过，还说要给deepseek团队开高薪，给签证，全部挖到 ...</blockquote>
给钱也不过是拉过去养老，美国如今的态度明显是先造神话，ds的最大特征就是在狠踹这个神话。


*****

####  泰坦失足  
##### 373#       发表于 2025-1-26 18:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282945&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-26 18:13</a>

难，真有类似的东西就在星际之门计划里搭配应用厂一起建了。

有这么多钱只会使劲堆算力，出来画饼都是讲 ...</blockquote>
鬼知道能砸出个啥。

5G不也花了不少钱吗。最后三大运营商拿出来的东西就。。。都挺抽象的。

【中国移动新推出的5G通话业务到底好不好用，我来带你一探究竟~】 [https://www.bilibili.com/video/BV19Y41127zY/](https://www.bilibili.com/video/BV19Y41127zY/)

【打电话要变天了，中移动发布5G新通话，微信这次估计要坐不住了】 [https://www.bilibili.com/video/BV1a3411n7vK/](https://www.bilibili.com/video/BV1a3411n7vK/)

【中国电信的5G消息原来长这样？】 [https://www.bilibili.com/video/BV1AB4y1m7qM/](https://www.bilibili.com/video/BV1AB4y1m7qM/)

LLM三大运营商也有成果，新闻没少过，效果没见过。联通元景大模型基于昇腾的AI解决方案  [https://www.hiascend.com/marketplace/solution/detail/2181](https://www.hiascend.com/marketplace/solution/detail/2181)

工信部：我国5G累计投资超过7300亿元 Jan 25, 2024 — 据了解，从2019年5G商用以来，通信业投资已连续5年保持正增长，连续4年的年投资规模超4000亿元，其中5G累计投资超过7300亿元

*****

####  Alce79  
##### 374#       发表于 2025-1-26 18:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282984&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 18:21</a>

鬼知道能砸出个啥。

5G不也花了不少钱吗。最后三大运营商拿出来的东西就。。。都挺抽象的。

【中国移动新 ...</blockquote>
那看这次deepseek的方法对面闭源能吸收多少就知道喽，还是只会堆算力搞“星际之门” “星球大战”就知道是扯淡的玩意儿了。

送脸上的节省成本的方法

*****

####  硫黄  
##### 375#       发表于 2025-1-26 18:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282984&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 18:21</a>

鬼知道能砸出个啥。

5G不也花了不少钱吗。最后三大运营商拿出来的东西就。。。都挺抽象的。

【中国移动新 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">你也太急了，这也能转进5G？

那还可以继续转进中国基建呢，反正对你们来说毫无意义


*****

####  希望之花  
##### 376#       发表于 2025-1-26 18:26

<img src="https://static.saraba1st.com/image/smiley/face2017/213.gif" referrerpolicy="no-referrer">这种说有推理能力的模型能发展到推理出猫猫狗狗在叫啥并且做出回复的吗

----发送自 [STAGE1 App for Android.](http://stage1.5j4m.com/?1.44)

*****

####  Alce79  
##### 377#       发表于 2025-1-26 18:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283013&amp;ptid=2224673" target="_blank">希望之花 发表于 2025-1-26 18:26</a>

这种说有推理能力的模型能发展到推理出猫猫狗狗在叫啥并且做出回复的吗

----发送自 STAGE1 App for Androi ...</blockquote>
人都没搞懂你还指望这些吃二手信息的搞懂<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  泰坦失足  
##### 378#       发表于 2025-1-26 18:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282997&amp;ptid=2224673" target="_blank">硫黄 发表于 2025-1-26 18:24</a>

你也太急了，这也能转进5G？

那还可以继续转进中国基建呢，反正对你们来说毫无意义</blockquote>
那你告诉我5g新通话 5g信息的创新性和意义在哪？

我帮你想个通稿：【5G新通话和5G消息能否和微信对打】 [https://www.bilibili.com/video/BV1En4y197z7/](https://www.bilibili.com/video/BV1En4y197z7/)

现在是否需要一个更可靠/更快速/更稳定的网络？ 需要。是否要全国都部署上？哪有那个必要？按通信业吹5G的吹法，我建议全国每栋公寓都应该有个昇腾910B机柜，随时提供边缘计算。


*****

####  gammatau  
##### 379#       发表于 2025-1-26 18:30

星际之门倒了是不是就该新的ai寒冬了

*****

####  Alce79  
##### 380#       发表于 2025-1-26 18:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283042&amp;ptid=2224673" target="_blank">gammatau 发表于 2025-1-26 18:30</a>

星际之门倒了是不是就该新的ai寒冬了</blockquote>
我觉得EUV出炉这东西都没成果尽头真有东西也会被截胡<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  2017.05.04  
##### 381#       发表于 2025-1-26 18:35

如果漏油真的入坑美股，那更应该理智分析下
你不是只有做多这一个选择吧
再说stargate这玩意马斯克都在狂喷
只靠这一个概念判断利好是不是有点薄弱


*****

####  硫黄  
##### 382#       发表于 2025-1-26 18:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283029&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 18:29</a>

那你告诉我5g新通话 5g信息的创新性和意义在哪？

我帮你想个通稿：【5G新通话和5G消息能否和微信对打】 h ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">骨子里和美国人一个思路，老爷们这辈子缩在自己家地堡里就行了

外面的屁民继续当原始人就行

*****

####  有鱼  
##### 383#       发表于 2025-1-26 18:39

泰坦哥我早就拉黑了，原来他真的是美股韭菜么<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

那我真的和解了，远离股市，做正常人


*****

####  泰坦失足  
##### 384#       发表于 2025-1-26 18:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283074&amp;ptid=2224673" target="_blank">2017.05.04 发表于 2025-1-26 18:35</a>

如果漏油真的入坑美股，那更应该理智分析下

你不是只有做多这一个选择吧

再说stargate这玩意马斯克都在狂喷 ...</blockquote>
主要的钱还是放在稳定理财那里。美国版余额宝稳定4%年化率。偶尔投点进基金。我看好的不是丢个task进去，它墩墩算一天最后吐一个可行的方案给我。而是LLM已经能完成过去较难的NLP任务了，那对于图像视频输入/自身机械驱动的机器人会咋样？最简单的，一个送餐机器人不小心进了卫生间，过去它可能压根就没针对性训练过，现在有了大模型，能不能具有通识？

*****

####  泰坦失足  
##### 385#       发表于 2025-1-26 18:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283081&amp;ptid=2224673" target="_blank">硫黄 发表于 2025-1-26 18:36</a>

骨子里和美国人一个思路，老爷们这辈子缩在自己家地堡里就行了

外面的屁民继续当原始人就行 ...</blockquote>
我5块30MB，WCDMA，LTE一路用过来。看着5G这些奇怪的轮子，发自内心的提出的疑问：这些到底有啥用？为啥要花那么多钱重新造一个甚至完全不如现有成熟产品的轮子？


*****

####  Alce79  
##### 386#       发表于 2025-1-26 18:46

<blockquote>泰坦失足 发表于 2025-1-26 18:41
主要的钱还是放在稳定理财那里。美国版余额宝稳定4%年化率。偶尔投点进基金。我看好的不是丢个task进去， ...</blockquote>

先定个目标什么时候应用化，国内定个目标EUV什么时候上线迭代，国内ai芯片迭代之前没出来或没拉开划时代差距就是庞培火山灭美股的时候了.


*****

####  硫黄  
##### 387#       发表于 2025-1-26 18:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283136&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 18:43</a>

我5块30MB，WCDMA，LTE一路用过来。看着5G这些奇怪的轮子，发自内心的提出的疑问：这些到底有啥用？为啥 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">在我们中国，快过年了随便出门逛一圈，就会发现人山人海

大家都拿着手机一遍逛街一遍打游戏看直播刷抖音（还有人外放草他妈的）

街头巷尾随便走几步都能看见三脚架夹着手机在那直播

唱歌的唱歌，弹吉他的弹吉他

你的轮子做得到？


*****

####  泰坦失足  
##### 388#       发表于 2025-1-26 19:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283189&amp;ptid=2224673" target="_blank">硫黄 发表于 2025-1-26 18:52</a>

在我们中国，快过年了随便出门逛一圈，就会发现人山人海

大家都拿着手机一遍逛街一遍打游戏看直播刷抖音 ...</blockquote>
他们哪个在使用5G新通话/5G消息？  移动互联网的繁荣也更多的归功于4G提速降费而不是5G。我4G时候动不动198 158rmb一个月才几个G流量时候，哪有人这么依赖移动互联网和对应的生态？而大降费后的4G末期，移动互联网生态已经配合着千元机也有不错体验的安卓而勃勃生机了。

2015年时候，我用的联通 196 3GB流量

中国移动的：2015年01月22日04:53 根据广东移动方面提供的数据，新“4G随心王”套餐共分为五档，“入门”月费为19元，其后还有39元/69元/99元/169元等不同档次，分别对应130M/300M/550M/800M/1500M的套餐流量，这些流量不仅可以用来手机上网，还可以直接折算为通话时长和短/彩信的发送条数，其中一分钟国内通话折算标准为0.75M流量、一条国内短/彩信则需要0.5M流量。


*****

####  Alce79  
##### 389#       发表于 2025-1-26 19:06

 本帖最后由 Alce79 于 2025-1-26 19:11 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283189&amp;ptid=2224673" target="_blank">硫黄 发表于 2025-1-26 18:52</a>

在我们中国，快过年了随便出门逛一圈，就会发现人山人海

大家都拿着手机一遍逛街一遍打游戏看直播刷抖音 ...</blockquote>
5G和星际之门的差距在于5G失败不能灭鳖，但星际之门失败真的能灭美。

半导体和AI芯片属于看得见摸得着的东西，但AI替代制造业是看不见摸不着的（特别是星际之门连应用化场景都没有） 我个人预测EUV30年之前出来 星际之门要4年建造，加上量产迭代35年是火山爆发之日，就现状来说可以想象到火山爆发的场景了。

楼上掰扯这么多都是基于“AGI很快就应用化 替代制造业啦！” 实际呢 对面搞AI的自己都没摸清方向还在堆算力中，现在又杀出DEEPSEEK这匹黑马表示低算力也能飞。 他们要是还搞星球大战要么没弄清DEEPSEEK的减成本方法、要么算力过剩只能继续堆维持骗局。

*****

####  硫黄  
##### 390#       发表于 2025-1-26 19:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283248&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 19:04</a>

他们哪个在使用5G新通话/5G消息？  移动互联网的繁荣也更多的归功于4G提速降费而不是5G。我4G时候动不动1 ...</blockquote>
我人生最尴尬的时候就是出门吃饭买单

后面十几个人在等我，但我的4G手机点不开付款吗

5G铺开以后，我就再也没遇到过手机没信号/手机连不上网/手机网速慢或卡

时代早就变了，现在是不管你收入多少，但凡低于70岁

所有人出门都靠着手机上网过日子


*****

####  硫黄  
##### 391#       发表于 2025-1-26 19:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283255&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-26 19:06</a>

5G和星际之门的差距在于5G失败不能灭鳖，但星际之门失败真的能灭美。

半导体和AI芯片属于看得见摸得着的东 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">星际之门主要用途就是让美股继续涨

美股跌了才是真完了


*****

####  Surlert  
##### 392#       发表于 2025-1-26 19:27

星际之门找软银来当冤大头，美股说不定在一边忽悠海外投资者，一边自己出货。


*****

####  星花  
##### 393#       发表于 2025-1-26 19:32

美股太高了，很麻烦。<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">


*****

####  Nanachi  
##### 394#       发表于 2025-1-26 19:40

没在4g时代去过人多的地方？5g能支持更多的人同时用网啊。

<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">当然也可能富家少爷的生活就是这么简简单单平平淡淡，从未见过人山人海

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  myarms  
##### 395#       发表于 2025-1-26 19:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283248&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 19:04</a>

他们哪个在使用5G新通话/5G消息？  移动互联网的繁荣也更多的归功于4G提速降费而不是5G。我4G时候动不动1 ...</blockquote>
呃，现在哪怕是我，也会直接用手机刷视频看球赛了，生活方式是不太可能回到以前那个只是一个月用几G流量的时代了


*****

####  星花  
##### 396#       发表于 2025-1-26 19:57

不往死里吹，投资哪里来，但进步也是确确实实的，要客观看待。<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">

*****

####  机吉斯卡  
##### 397#         楼主| 发表于 2025-1-26 19:58

<img src="https://img.saraba1st.com/forum/202501/26/195848xvachq04k8cjh40h.jpg" referrerpolicy="no-referrer">

<strong>011.jpg</strong> (147.21 KB, 下载次数: 0)

下载附件

2025-1-26 19:58 上传


*****

####  qratosones1337  
##### 398#       发表于 2025-1-26 20:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282732&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-26 17:29</a>

垄断制造业的故事我是觉得没戏了，对面有人也开始从0复刻中，能成绝对会跌一波。

得赶紧搬出划时代的新东 ...</blockquote>
星际之门标志着美国人在错误的路线上越走越远，已经积重难返了。

游戏圈就有现成的例子：游科花了8000W美元做出了黑神话，那索尼花了8亿，一定做了更好的游戏出来吧？结果做了星鸣特工……

*****

####  zerona  
##### 399#       发表于 2025-1-26 20:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283248&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 19:04</a>

他们哪个在使用5G新通话/5G消息？  移动互联网的繁荣也更多的归功于4G提速降费而不是5G。我4G时候动不动1 ...</blockquote>
5g基站也是要用到7纳米的芯片啊。而且5g这从软件来说不就是技术集合吗？专利不研究直接给人交钱是吧？

*****

####  机吉斯卡  
##### 400#         楼主| 发表于 2025-1-26 20:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283550&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2025-1-26 20:04</a>

星际之门标志着美国人在错误的路线上越走越远，已经积重难返了。

游戏圈就有现成的例子：游科花了8000W ...</blockquote>
OPENAI可能知道些什么，但他们决定不说，我刚才那个转发就是


*****

####  qratosones1337  
##### 401#       发表于 2025-1-26 20:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283521&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-26 19:58</a></blockquote>
事实上我怀疑OpenAI自己可能真的硬上了MCTS，现在o1写文章分条列举的倾向要远远高于R1，明显更死板，如果用MCTS腌入味了解释就很正常了。


*****

####  Alce79  
##### 402#       发表于 2025-1-26 20:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283559&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-26 20:05</a>

OPENAI可能知道些什么，但他们决定不说，我刚才那个转发就是</blockquote>
它要是早知道还搞出就目前这级别的模型且接着搞星际之门，那看来是算力过剩停不下来了。

*****

####  2017.05.04  
##### 403#       发表于 2025-1-26 20:16

考虑到stargate本来是从几百亿的项目膨胀到五千亿

投资人借坡下驴的可能性极高


*****

####  猫屎盆子  
##### 404#       发表于 2025-1-26 20:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275129&amp;ptid=2224673" target="_blank">变老的大二 发表于 2025-1-25 16:52</a>

已经开始换赢法了，开源的deepseek的思路塞到拥有更多计算资源的西大互联网巨头手里会加速AGI的诞生，赢 ...</blockquote>
好家伙，还有这种赢法，波士顿/马一龙开源是牢美赢，幻方开源还是牢美赢，赢赢赢，大赢特赢！

*****

####  whzfjd  
##### 405#       发表于 2025-1-26 20:30

deepseek 出来前，我推的四两拨千斤选手还是 kimi chat<img src="https://static.saraba1st.com/image/smiley/face2017/135.png" referrerpolicy="no-referrer">

*****

####  tillnight  
##### 406#       发表于 2025-1-26 20:31

<blockquote>2017.05.04 发表于 2025-1-26 20:16
考虑到stargate本来是从几百亿的项目膨胀到五千亿

投资人借坡下驴的可能性极高 ...</blockquote>
星际之门的投资额从来都是奥特曼的经典营销学，业内外都肯定项目目前根本没有筹集到那么多钱，而且差额多。资本市场对这个卫星反响也很小，连微软都明示没有真金白银追加进这个项目，真实性可想而知。


*****

####  猫屎盆子  
##### 404#       发表于 2025-1-26 20:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67275129&amp;ptid=2224673" target="_blank">变老的大二 发表于 2025-1-25 16:52</a>

已经开始换赢法了，开源的deepseek的思路塞到拥有更多计算资源的西大互联网巨头手里会加速AGI的诞生，赢 ...</blockquote>
好家伙，还有这种赢法，波士顿/马一龙开源是牢美赢，幻方开源还是牢美赢，赢赢赢，大赢特赢！

*****

####  whzfjd  
##### 405#       发表于 2025-1-26 20:30

deepseek 出来前，我推的四两拨千斤选手还是 kimi chat<img src="https://static.saraba1st.com/image/smiley/face2017/135.png" referrerpolicy="no-referrer">

*****

####  tillnight  
##### 406#       发表于 2025-1-26 20:31

<blockquote>2017.05.04 发表于 2025-1-26 20:16
考虑到stargate本来是从几百亿的项目膨胀到五千亿

投资人借坡下驴的可能性极高 ...</blockquote>
星际之门的投资额从来都是奥特曼的经典营销学，业内外都肯定项目目前根本没有筹集到那么多钱，而且差额多。资本市场对这个卫星反响也很小，连微软都明示没有真金白银追加进这个项目，真实性可想而知。

*****

####  pf67  
##### 407#       发表于 2025-1-26 20:34

现在讨论的人多了，一些大厂里写洞察DeepSeek的专家人数已经超过deepseek的开发人数了233

—— 来自 OPPO PCLM10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  initium  
##### 408#       发表于 2025-1-26 20:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283248&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 19:04</a>

他们哪个在使用5G新通话/5G消息？  移动互联网的繁荣也更多的归功于4G提速降费而不是5G。我4G时候动不动1 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">5G新设备提供了更多的接入连接数，提高了接入速度，以前球赛/演唱会/漫展/大型集会人员聚集场所需要提前报备临时调配额外通信设备支援，5G时代这种情况**减少了。


*****

####  硫黄  
##### 409#       发表于 2025-1-26 20:46

<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">不管外国友人觉得5G有用没用，反正中国人已经用上5G了

deepseek网页版今天用的人太多崩了，离中国人全用上AI确实还有一段路要走


*****

####  一骑当千  
##### 410#       发表于 2025-1-26 22:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67265243&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-24 11:31</a>
艹，现在是个水群都在传SEEK写的小黄温

就是那个静香的那个</blockquote>
好奇，求私信看看<img src="https://static.saraba1st.com/image/smiley/face2017/035.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  alixsander  
##### 411#       发表于 2025-1-27 00:43

<blockquote>机吉斯卡 发表于 2025-1-26 19:58
</blockquote>
不是的，显然很多实验室都知道。而且八成O1. O3也是直接RL的，没有像DS这样正义开源而已。

你可以看一下GEMINI 2 FLASH THINKING的思考过程，会经常性的切换语言。说法是这样的，思维链在不同语言中切换说明是RL DONE RIGHT，因为模型输出使用信息熵最高的方式向答案收敛


*****

####  阿刚  
##### 412#       发表于 2025-1-27 01:08

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">然后急眼了他就不反馈了


*****

####  riin2  
##### 413#       发表于 2025-1-27 02:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283189&amp;ptid=2224673" target="_blank">硫黄 发表于 2025-1-26 18:52</a>

在我们中国，快过年了随便出门逛一圈，就会发现人山人海

大家都拿着手机一遍逛街一遍打游戏看直播刷抖音 ...</blockquote>
绝大部分地区没必要上5g，lte足矣。在人群密集区，比如一个大型演唱会会场，需要更高的连接密度，5g才能发挥优势。目前美国就是这么干的，只有密集区域才有5g信号。个人认为美国的由市场导向的5g建设是经济实惠的解决方案。

我很好奇国内的5g当年是怎么立项推动的，有人把原因都归给华为，我觉得也许也有其他的利益团体


*****

####  riin2  
##### 414#       发表于 2025-1-27 02:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283255&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-26 19:06</a>

5G和星际之门的差距在于5G失败不能灭鳖，但星际之门失败真的能灭美。

半导体和AI芯片属于看得见摸得着的东 ...</blockquote>
替代制造业？不要小瞧美国工会的力量。码头自动化都做不到，还agi


*****

####  硫黄  
##### 415#       发表于 2025-1-27 02:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285581&amp;ptid=2224673" target="_blank">riin2 发表于 2025-1-27 02:40</a>

绝大部分地区没必要上5g，lte足矣。在人群密集区，比如一个大型演唱会会场，需要更高的连接密度，5g才能 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">毕竟美国只在他需要的时候地广人稀，而且已经被开除美国人的底层确实不需要5G


*****

####  cube  
##### 416#       发表于 2025-1-27 04:52

 本帖最后由 cube 于 2025-1-27 04:53 编辑 

<img src="https://img.saraba1st.com/forum/202501/27/045340ey3bmx3yab756cni.png" referrerpolicy="no-referrer">

<strong>c5b3aabc-e605-4a67-9c37-ed3e8ac44df2.png</strong> (242.39 KB, 下载次数: 0)

下载附件

2025-1-27 04:53 上传

艹，港科大的人用7B版的模型搞蒸馏，模型在第44步发现自己推理的公式有错误居然直接进入自我纠正了。<img src="https://static.saraba1st.com/image/smiley/face2017/003.png" referrerpolicy="no-referrer">


*****

####  cube  
##### 417#       发表于 2025-1-27 04:52

 本帖最后由 cube 于 2025-1-27 04:53 编辑 

<img src="https://img.saraba1st.com/forum/202501/27/045340ey3bmx3yab756cni.png" referrerpolicy="no-referrer">

<strong>c5b3aabc-e605-4a67-9c37-ed3e8ac44df2.png</strong> (242.39 KB, 下载次数: 0)

下载附件

2025-1-27 04:53 上传

艹，港科大的人用7B版的模型搞蒸馏，模型在第44步发现自己推理的公式有错误居然直接进入自我纠正了。<img src="https://static.saraba1st.com/image/smiley/face2017/003.png" referrerpolicy="no-referrer">

*****

####  mimighost  
##### 418#       发表于 2025-1-27 05:28

openai肯定就是直接rl训练出来的，有人对比他们system card里面那个thinking和r1的区别，发现两个model用词和语气都差不多，直接rl可能收敛到的语法都是相似的


*****

####  pf67  
##### 419#       发表于 2025-1-27 07:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285727&amp;ptid=2224673" target="_blank">希望之花 发表于 2025-1-27 06:06</a>
一般本地部署是怎么做的，我找个教程就直接下个ollama然后挑个模型下好就能跑了甚至环境都不用配了科学的力 ...</blockquote>
如果只做这些你根本不需要自己部署吧

—— 来自 OPPO PCLM10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  orecheng  
##### 420#       发表于 2025-1-27 07:44

<blockquote>变老的大二 发表于 2025-1-25 16:52
已经开始换赢法了，开源的deepseek的思路塞到拥有更多计算资源的西大互联网巨头手里会加速AGI的诞生，赢 ...</blockquote>
如果西大不止一家公司点出了AGI, 那就进入了全面内卷时代，互相比拼低价，谁也实现不了盈利。同时技术路线也会泄露，东大虽然算力不如，但只要路线正确，也花不了多少时间也能实现AGI


*****

####  pf67  
##### 421#       发表于 2025-1-27 08:06

 本帖最后由 pf67 于 2025-1-27 08:08 编辑 

赢学赢来赢去到底谁赢

ds开源怎么都对消费者是大好事，但国内一堆的大厂也都在搞闭源嘛，只不过是因为内卷没closeai那么贵，我很期待把他们也逼到开源

—— 来自 OPPO PCLM10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  pf67  
##### 422#       发表于 2025-1-27 08:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285581&amp;ptid=2224673" target="_blank">riin2 发表于 2025-1-27 02:40</a>
绝大部分地区没必要上5g，lte足矣。在人群密集区，比如一个大型演唱会会场，需要更高的连接密度，5g才能 ...</blockquote>
当然是所有运营商，设备商，政府一起推啊，推成了大家都有肉吃

hw在4g时代已经算设备商no1，不推5g怎么继续卖设备，肯定是力推，有没有必要都不可能停下来，当年无线产品线老大还无限寄望于vr的爆发产生大量流量需求来匹配5g流量

—— 来自 OPPO PCLM10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  無始無終  
##### 423#       发表于 2025-1-27 08:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282678&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-26 17:19</a>
要是真那么简单直接左手放prompt右手放output跑SFT得了。这条路大家都没走通都在寻思是不是o1有啥独门秘 ...</blockquote>
DeepSeek没做多模态是因为他们用的是MoE架构，而其它家不是，目前还没摸索出来MoE做多模特的路子，甚至还不能确定MoE是否真的能做多模态

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  無始無終  
##### 424#       发表于 2025-1-27 08:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283521&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-26 19:58</a></blockquote>
这次之所以大家都不看好强化学习，是因为21/22年那阵爆发过一次用RL训练LLM的风潮，结果是训出来的模型都非常差，后面大家都觉得RL搞LLM是骗人的了
这次DeepSeek直接点出来当年之所以RL效果差是因为用的模型太小了，RL真正发挥威力需要靠千亿以上参数的大模型。DeepSeek团队在R1 Zero搞出效果后也试了在Qwen 32B上用RL训练，效果和阿里自己的QwQ半斤八两，说明RL是锦上添花的，而不能雪中送炭

<img src="https://img.saraba1st.com/forum/202501/27/082503ihh17r1xhxhho10f.png" referrerpolicy="no-referrer">

<strong>Image_263975340219348.png</strong> (74.89 KB, 下载次数: 0)

下载附件

2025-1-27 08:25 上传

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  pf67  
##### 425#       发表于 2025-1-27 08:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285912&amp;ptid=2224673" target="_blank">無始無終 发表于 2025-1-27 08:17</a>
DeepSeek没做多模态是因为他们用的是MoE架构，而其它家不是，目前还没摸索出来MoE做多模特的路子，甚至还 ...</blockquote>
怎么可能走不通，多模态moe模型都有好几个了

—— 来自 OPPO PCLM10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  泰坦失足  
##### 426#       发表于 2025-1-27 08:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283725&amp;ptid=2224673" target="_blank">initium 发表于 2025-1-26 20:38</a>

5G新设备提供了更多的接入连接数，提高了接入速度，以前球赛/演唱会/漫展/大型集会人员聚集场所需要提前 ...</blockquote>
我不否认5G存在的必要性。我不认可的是全国统一上最新最先进的5G. 行，就算目的是不用LTE给外国长期交专利费。但是当时对5G的吹捧，无视有线网/WiFI的存在，什么都要硬绑一个5G，现在更是把CS领域的发展和5G强绑定在一起。我有一个好点子，把现在常见多卡并联的方式切换为5G专用网，更是5G赋能AI训练了。有必要吗，完全没有这个必要

谁用过以下吹得玩意了？ 5G-A 4K高清直播（限定和5G-A强绑定的这个）5G-A裸眼3D 5G-A云手机， 5G-A新通话。管道商就应该当管道商，谁见过电网天天说自己支持了xx应用？

“移动5G-A赋能，引爆网红力” 湖北移动5G-A 4K高清直播首秀亮相汉口北，传统行业焕发新活力
[https://www.c114.com.cn/local/2787/a1271057.html](https://www.c114.com.cn/local/2787/a1271057.html)

*****

####  pf67  
##### 427#       发表于 2025-1-27 08:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285938&amp;ptid=2224673" target="_blank">無始無終 发表于 2025-1-27 08:25</a>
这次之所以大家都不看好强化学习，是因为21/22年那阵爆发过一次用RL训练LLM的风潮，结果是训出来的模型都 ...</blockquote>
未必，因为sft需要高质量标注样本，这方面已经很难找了，rl能成相比直接怼算力算一个大捷径

—— 来自 OPPO PCLM10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  Azcarlo  
##### 428#       发表于 2025-1-27 08:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285912&amp;ptid=2224673" target="_blank">無始無終 发表于 2025-1-27 08:17</a>
DeepSeek没做多模态是因为他们用的是MoE架构，而其它家不是，目前还没摸索出来MoE做多模特的路子，甚至还 ...</blockquote>
你在说什么，多模moe又不是没有<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">

— from [S1 Next Goose](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  無始無終  
##### 429#       发表于 2025-1-27 08:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67283687&amp;ptid=2224673" target="_blank">whzfjd 发表于 2025-1-26 20:30</a>

deepseek 出来前，我推的四两拨千斤选手还是 kimi chat</blockquote>
Kimi模型的性能太差了，怎么四两拨千斤啊，拿知乎toyama nao做的模型评分来看

这是24年6月DeepSeek V2推出时的评测
<img src="https://picx.zhimg.com/v2-213a3a2a66710d25296d04cf23eef8af_r.jpg" referrerpolicy="no-referrer">

这是今年1月的评测
<img src="https://pic2.zhimg.com/v2-85a1307f188600274be63f991ea86a7f_r.jpg" referrerpolicy="no-referrer">

国内这些模型里，之前国内吹的最多的Kimi和豆包这些都是做产品的，而通义和DeepSeek才是做模型的，当然现在字节把阿里做大模型的人挖走了，今年豆包可能会爆发


*****

####  泰坦失足  
##### 430#       发表于 2025-1-27 08:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285901&amp;ptid=2224673" target="_blank">pf67 发表于 2025-1-27 08:13</a>

当然是所有运营商，设备商，政府一起推啊，推成了大家都有肉吃，国外因为涉及自负盈亏运营商和政府的动力 ...</blockquote>
裸眼3D/云游戏/VR 这些已经被市场证明过消费者不买账的东西，刚开放5G和现在都有人blabla在那说必将是为了。我就纳闷了，之前有线网和WiFI时代，大家最后的选择还是2D屏幕玩本地游戏/看视频，为什么到了5G就能不一样。

life finds a way。云游戏这东西，全球用户就是不买账。哪怕是只有手机的用户，最后的选择也往往是玩本地运行手游。

<img src="https://img.saraba1st.com/forum/202501/27/083441pmcs343n6vlmvjbl.png" referrerpolicy="no-referrer">

<strong>12.png</strong> (71.45 KB, 下载次数: 0)

下载附件

2025-1-27 08:34 上传


*****

####  無始無終  
##### 431#       发表于 2025-1-27 08:49

 本帖最后由 無始無終 于 2025-1-27 08:53 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285947&amp;ptid=2224673" target="_blank">pf67 发表于 2025-1-27 08:28</a>

怎么可能走不通，多模态moe模型都有好几个了

—— 来自 OPPO PCLM10, Android 12上的 S1Next-鹅版 v2.5. ...</blockquote><blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;ptid=2224673&amp;pid=67285975" target="_blank">Azcarlo 发表于 2025-1-27 08:34</a>

你在说什么，多模moe又不是没有

— from S1 Next Goose v3.3.96</blockquote>

<img src="https://static.saraba1st.com/image/smiley/face2017/008.png" referrerpolicy="no-referrer">不好意思之前对MoE了解肤浅了

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  希望之花  
##### 432#       发表于 2025-1-27 09:13

一个是我还是喜欢东西都在本地跑

还有之前一直用的gpt，总感觉closeai 会拿用户的输入去干别的事情<img src="https://static.saraba1st.com/image/smiley/face2017/014.png" referrerpolicy="no-referrer">

----发送自 [STAGE1 App for Android.](http://stage1.5j4m.com/?1.44)


*****

####  机吉斯卡  
##### 433#         楼主| 发表于 2025-1-27 09:17

<img src="https://img.saraba1st.com/forum/202501/27/091637aa5x066kax4o16c0.jpeg" referrerpolicy="no-referrer">" src="https://static.saraba1st.com/image/common/none.gif" referrerpolicy="no-referrer">

<strong>IMG_0064.jpeg</strong> (136.6 KB, 下载次数: 0)

下载附件

由手机上传
2025-1-27 09:16 上传

我能吧泰坦哥踢出这个楼吗？好像只有版主才可以吧


*****

####  机吉斯卡  
##### 434#         楼主| 发表于 2025-1-27 09:23

https://weibo.com/1727858283/5127347554484625

经济学人：中国的人工智能产业几乎赶上美国

而且更加开放、高效

_2025 年 1 月 23 日_

世界上首个“推理模型”（reasoning model）——一种先进的人工智能形式——于去年 9 月由美国公司 OpenAI 发布，名为“o1”。该模型采用“思维链”（chain of thought）技术来解决科学和数学等领域中的复杂问题。在用户看不到的后台，它会将问题分解为若干步骤、尝试不同的思路，最终再给出结论。o1 的面世引发了业界一场围绕这种新方法的竞赛。12 月，谷歌发布了名为“Gemini Flash Thinking”的推理模型，随后 OpenAI 又在几天后更新推出了“o3”。

不过，真正最先跟进 OpenAI 脚步的并非财力雄厚的谷歌，而是中国企业。o1 发布不到三个月，中国电商巨头阿里巴巴就上线了全新版本的 Qwen 聊天机器人——“QwQ”，同样具备“推理”能力。阿里巴巴在其博文中文采斐然地询问：“思考、质疑、理解，这些意味着什么？”并附上可免费试用模型的链接。另一家中国公司 DeepSeek 更早一步，在 QwQ 之前一周就发布了名为“R1”的“推理模型”预览版。美国政府一直试图遏制中国的人工智能产业，但这两家中国企业的动作表明，美国同行的技术领先优势已经缩短到以周为单位。

不仅在推理模型上，中国公司已走在前沿：去年 12 月，DeepSeek 还发布了一款新的大型语言模型（LLM）——v3。它的体量几乎达到 700GB，只有专业硬件才能运行，参数规模高达 6850 亿（这些参数共同构建了模型的神经网络），比此前任何可免费下载的模型都要大。相比之下，Meta（Facebook 母公司）在去年 7 月公布的旗舰 LLM——Llama 3.1，只有 4050 亿参数。

DeepSeek 的这款 LLM 不仅规模胜过西方许多同类模型，其性能也足以比肩谷歌和 OpenAI 等公司尚未公开的旗舰产品。AI 编程平台 Aider 的创始人 Paul Gauthier 对新模型进行代码基准测试后发现，v3 在性能上优于几乎所有竞品，只有 o1 可以与之一较高下。而知名的基于众包测评的  Lmsys  榜单也将 DeepSeek 的 v3 列为第七，仅次于谷歌和 OpenAI 的多款封闭式模型，成为排名最高的开源模型。

龙腾初现

中国的 AI 如今与美国的差距已相当微小，这让 OpenAI 的 CEO Sam Altman 不得不公开说明这种差距有多么有限。DeepSeek 发布 v3 后不久，他在社交媒体上颇有微词地表示：“在知道某项技术可行的情况下去模仿并不难。真正艰难的是在不确定可行的情况下去开创性的尝试、冒险并攻克新难题。”

起初，中国的 AI 产业似乎并不具备与美国正面抗衡的实力，这很大程度上与美国的制裁措施有关。2022 年，美国禁止对华出口高端芯片。芯片巨头英伟达（Nvidia）不得不为中国市场专门设计低配版本；美国还禁止出口先进芯片制造所需设备，并威胁对任何可能协助中国自行制造顶尖芯片的非美企业采取惩罚。

此外，中国企业也曾面临本土的另一个障碍——对大型语言模型的审慎态度，其中部分原因是监管层面对 AI 的内容安全和政治审查存在顾虑。若模型出现“幻觉”或发布不当乃至政治敏感信息，后果难以预料。例如，百度多年来一直在内部研究 LLM，并推出过“ERNIE”模型，但一直没有面向公众开放。ChatGPT 爆火后，百度虽开始重新考虑策略，但最初仍只提供了有限的邀请制测试。

在此背景下，中国官方后来出台了更明确的法规，要求模型开发者注重内容合规并符合“社会主义核心价值观”，同时也鼓励“生成式 AI 的创新发展”。据科技媒体 TechTechChina 主编 Vivian Toh 介绍，为增强国际竞争力，中国政府希望营造更有利的政策环境。阿里巴巴便是第一批顺应新环境的企业之一，率先发布了自家的 LLM——最初名为“通义千问”（Tongyi Qianwen），后缩写为“Qwen”。

尽管阿里巴巴早期的版本看上去只是基于 Meta 开源模型 Llama 改出来的一个平平无奇的“衍生产品”，但在随后的 2024 年，它不断迭代 Qwen 模型，性能开始大幅提升。早在一年前，Anthropic（美国一家 AI 实验室）联合创始人 Jack Clark 就曾评价说，阿里巴巴新版本的 Qwen，已经能与一些西方顶尖实验室的先进模型相抗衡。那次，阿里巴巴发布的版本已能同时处理图像和文本，这在当时已属不凡。

除阿里巴巴外，中国另一家互联网巨头腾讯以及通信设备巨头华为也都在自研大模型。而 DeepSeek 的起源则有些不同。这家企业在阿里巴巴发布首版 Qwen 时还不存在。它脱胎于一家名为 High-Flyer 的对冲基金，该基金于 2015 年成立，利用 AI 进行量化交易，曾通过深入的基础研究在股市上获得了不小的优势。

High-Flyer 的创始人梁文峰曾提到，这并不完全是商业动机。他认为，最初支持 OpenAI 的投资人并非只为了追求回报，他们更着眼于“使命感”。在 2023 年 Qwen 发布的同一个月，High-Flyer 宣布进军通用人工智能领域，并将旗下的 AI 研究部门独立出来，命名为 DeepSeek。

DeepSeek 与 OpenAI 一样，都宣称要将 AI 技术用于社会公共利益。但不同的是，DeepSeek 表示大部分训练成果都会公开，以防止技术被少数人或大公司垄断。而且，与当年 OpenAI 因日益膨胀的训练成本而不得不依赖私人资本不同，DeepSeek 背后可以直接使用 High-Flyer 在量化交易中积累的庞大算力资源。

DeepSeek 庞大的 v3 模型不仅体现在规模上，在训练效率上也令人瞩目。剑桥大学的 Nic Lane 指出，这一成功并非源自某一个重大创新，而是多次小改进的结果。例如，训练过程中，模型常用数值舍入来简化计算，但在需要精度时会继续使用更高精度；服务器集群也做了特殊配置，让每块芯片之间的通讯更加顺畅；训练完成后，还会利用 DeepSeek 的推理模型 R1 的输出进行微调，让 v3 学会如何更好地“模仿”R1 的高质量推理，且成本更低。

正是这些点滴优化，让 v3“只”花了不到 300 万芯时就完成了训练，耗资不到 600 万美元，仅为 Meta 训练 Llama 3.1 时所需算力和资金的约十分之一。v3 只用到了 2000 块芯片，而 Llama 3.1 则使用了 16000 块。因为受到美国制裁，DeepSeek 所使用的芯片也并非顶级型号。相比之下，西方企业对芯片的使用更显奢侈：Meta 计划建造一座拥有 35 万块芯片的超级数据中心。正如特斯拉前 AI 负责人安德烈·卡帕西（Andrej Karpathy）所说，DeepSeek 就像“穿着高跟鞋倒退跳舞”的金杰·罗杰斯，让人在“相对微薄的预算”下见识到如何成功训练出顶级模型。

更引人注目的是，v3 不但训练成本低，其推理（运行）成本同样更少。DeepSeek 能够把任务更高效地分配到多块芯片上，并可以在上一步计算尚未完全结束时就启动下一步，以此减少闲置算力时间。正是由于这些技术突破，DeepSeek 计划于今年 2 月开放 v3 的商用 API 时，定价将不到 Anthropic 公司 Claude 模型的十分之一。AI 专家 Simon Willison 感叹：“如果它们的质量相当，这意味着在 LLM 价格战中出现了戏剧性的转折。”

DeepSeek 的“成本至上”策略远不止于此。本周，DeepSeek 一边完整开源 R1 模型，一边发布了一系列体积更小、运行更快、成本更低的“蒸馏”版本。它们虽然精度略有缩水，但与更大、更全功能的版本相差无几。此前，阿里巴巴和 Meta 也都推出过类似的精简模型，而 DeepSeek 此次再次证明，其实力完全足以与行业顶尖公司同场竞技。

---

巨龙之道

阿里巴巴和 DeepSeek 对谷歌、OpenAI 等西方先进实验室的另一个挑战在于：它们采取了和 Meta 类似的开源策略，不同于 OpenAI 和谷歌的封闭模式。如果你想下载一份 Qwen 模型用于自己的项目，几乎不需要获得特别许可。更引人注目的是，这些中国企业还在发布新模型时，定期向公众披露大量技术细节，令研究人员和开发者能够深入了解模型的架构和训练过程。

阿里巴巴在发布 QwQ 时，就成为全球首家以开源许可证形式发布推理模型的企业，让任何人都能下载那份 20GB 的完整文件，自行部署或解构其内部机理。这与 OpenAI 的做法截然相反，后者对 o1 的内部机制讳莫如深。

在大体思路上，QwQ 和 o1 都采用了所谓的“测试时计算”（test-time compute）策略：不仅在模型训练过程中使用大量算力，在推理过程（回答问题）时，同样会投入远超以往 LLM 的计算资源。这种方式在心理学上可类比丹尼尔·卡尼曼（Daniel Kahneman）提出的“二型思维”（type two），即相比“快速直觉”（type one）模式，二型思维更慢、更具逻辑性。实践表明，这对数学、编程等领域的复杂问题而言非常有用。

当你被问到诸如“法国首都是哪座城市”这样简单的问题时，你会直接脱口而出“巴黎”。普通的聊天机器人也类似，只要统计上某个答案的概率最高，就直接生成那句话。而当问题涉及更多步骤时，人类通常会先罗列几个候选，再逐步筛选；新的推理模型同样在内部经过多轮分析，而不是一句话冲口而出。

区别在于，o1 不会把整个思考过程都暴露给用户，只给出要点和结论。OpenAI 表示这么做有其道理：有时模型会思考是否应该提供冒犯性内容或潜在危险信息，最后却决定不输出。若将所有推理细节公开，敏感内容就难免泄露。而且，这也有效保护了 o1 的核心机理，避免被竞争对手轻易模仿。

阿里巴巴则完全没有这样的顾虑。如果你向 QwQ 提出一道高难度数学题，它不仅会给出答案，还会详细呈现自己“思考”的全过程——有时可能洋洋洒洒数千字，不断尝试不同思路，再总结得出正确结论。举例而言，用户让 QwQ 计算某数的最小奇质因数，QwQ 会一边自言自语“这个数很大，我得先逐步分解……”，一边计算，最后分析两千多字后给出答案“97”。

在葡萄牙做 AI 编程工具的初创公司 Poolside 联合创始人 Eiso Kant 指出，中国公司如此开放绝非偶然。它们也在全球范围内争夺顶尖人才，而西方公司多因竞争激烈和监管等原因对技术守口如瓶。“如果你是一名研究员，想去一个更加开放的环境，那么中国实验室能满足这种需求。”Kant 说，“即使他们不是最早发明某项技术，也往往是最先公开的那批。”剑桥大学的 Nic Lane 还补充，DeepSeek 在发布 v3 的论文中一次性列出了 139 位作者，对研究员而言，这种署名荣耀比在美国实验室里默默无闻更具吸引力。

当然，在美国收紧对华技术出口的背景下，中国研究人员在美国也会面临更多不便，除了繁琐的行政审批外，还有一种时常飘在空气中的“怀疑”情绪，甚至在社交场合都有间或出现的间谍指控。

---

大国博弈

在中国从事 AI 研究也并非没有限制。假如你问 DeepSeek v3 一些涉及台湾主权的问题，模型起先会乖乖回答“台湾是一座位于东亚的岛屿，也被称为‘中华民国’”，但很快，它就会突然打住，删除先前内容，简单回复“我们换个话题吧”。

尽管如此，中国企业之所以选择大力开源和透明化，也是希望围绕自己的技术建立广阔的产业生态。这一做法的商业价值在于，基于开源模型开发产品的公司，将来或许会采购一些相关增值服务；从战略角度看，这也有助于中国在中美 AI 竞争中争取更多“盟友”。

对中国的本土企业而言，采用国内模型可以避免美国可能进一步收紧或禁止关键技术出口带来的风险；同时，中国模型也通常符合本地内容审查的需求。对于想在中国市场推出 AI 功能的苹果、三星等国际企业而言，与中方合作也必不可少。此外，Qwen 在训练数据里特意增强了对乌尔都语、孟加拉语等低资源语言的支持，对于特定市场的公司来说，可能更有吸引力。再者，中国模型普遍运行成本更低，这同样是一大优势。

然而，这并不意味着中国模型就一定能完全占领全球。美国的 AI 企业依然在一些关键功能上保持领先。例如，谷歌正在研究让其 Gemini 模型直接控制用户的浏览器，未来可能发展成与网络深度交互的 AI“代理”；Anthropic 和 OpenAI 的模型也不仅能帮用户写代码，还能直接编译运行，甚至托管完整应用。而复杂任务的解决方法也不止步于“多步推理”：用传统的 ChatGPT 让其自行编写并运行一段程序，也可以找到相同答案。

据传，Sam Altman 即将宣布 OpenAI 最新的“博士级超级代理”（PhD-level super-agents），在多个高智力领域可与人类专家比肩。来自中国的追赶，对美国 AI 或许是一种鞭策和激励，可能会催生更多先进的人工智能技术登场。尽管龙争虎斗尚未见终局，但可以肯定的是，未来的竞争只会愈演愈烈。

*****

####  qratosones1337  
##### 435#       发表于 2025-1-27 09:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285581&amp;ptid=2224673" target="_blank">riin2 发表于 2025-1-27 02:40</a>

绝大部分地区没必要上5g，lte足矣。在人群密集区，比如一个大型演唱会会场，需要更高的连接密度，5g才能 ...</blockquote>
你有没有想过中国的人口密度根本就不存在所谓的“没必要上5G的绝大部分地区”


*****

####  qratosones1337  
##### 436#       发表于 2025-1-27 09:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285883&amp;ptid=2224673" target="_blank">pf67 发表于 2025-1-27 08:06</a>

赢学赢来赢去到底谁赢

ds开源怎么都对消费者是大好事，但国内一堆的大厂也都在搞闭源嘛，只不过是因为内卷 ...</blockquote>
国内闭源的几家本来也不成气候，目前国内AI两大扛把子，一个是DeepSeek，另一个是阿里，恰好都是搞开源的

*****

####  sellboy  
##### 437#       发表于 2025-1-27 09:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285956&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-27 08:30</a>

我不否认5G存在的必要性。我不认可的是全国统一上最新最先进的5G. 行，就算目的是不用LTE给外国长期交专 ...</blockquote>
高铁只有京沪线稳定盈利，是不是只要京沪线就可以了？


*****

####  泰坦失足  
##### 438#       发表于 2025-1-27 09:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286196&amp;ptid=2224673" target="_blank">sellboy 发表于 2025-1-27 09:27</a>

高铁只有京沪线稳定盈利，是不是只要京沪线就可以了？</blockquote>
我也没见县城到县城之间有高铁啊？再说5G更像是高速公路，铁路/高速公路/普通道路/空运/海运就像有线/WLAN/蜂窝数据网/基于PICE等接口的边缘计算。各有各的用途。德国工业在过去打下来的基础总不能说全靠那个据说不限速的德国高速公路吧。

*****

####  x分裂者  
##### 439#       发表于 2025-1-27 09:32

无人码头用了这么久5g了，又是我用不到=没有，而且讨论ds的楼扯什么勾八5g，在这恶心人吗


*****

####  bonnwang  
##### 440#       发表于 2025-1-27 09:42

我花了几年才总结出来的东西ds几秒就出了<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">


*****

####  泰坦失足  
##### 441#       发表于 2025-1-27 09:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286143&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-27 09:17</a>

我能吧泰坦哥踢出这个楼吗？好像只有版主才可以吧</blockquote>
你要觉得你赢了，你随意。我只是觉得这些鉴证博主和卖课博主上来就是赢赢赢就莫名其妙的。
[https://planetbanatt.net/articles/v3fermi.html](https://planetbanatt.net/articles/v3fermi.html) 并不是“任何拥有 500 万美元的人都可以训练 Deepseek-V3 ”，而是只有足够数据，走在正确路线上的人，在付出了“500 万美元成本的GPU小时”后，能获得一个4o级的模型。而R1，只能说OpenAI是the man who sold the world。所有人都不知道RL才是走的通的道路之一

而且MOE和Dense模型本来在训练成本上有差距，这一点大家本就知道。但是之前大家一直认为MOE这路不如Dense。两大龙头Llama和Qwen都走的是Dense这条路。
[https://www.microsoft.com/en-us/ ... eneration-ai-scale/](https://www.microsoft.com/en-us/research/blog/deepspeed-advancing-moe-inference-and-training-to-power-next-generation-ai-scale/)


*****

####  Alce79  
##### 442#       发表于 2025-1-27 09:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286329&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-27 09:47</a>

你要觉得你赢了，你随意。我只是觉得这些鉴证博主和卖课博主上来就是赢赢赢就莫名其妙的。

https://planet ...</blockquote>
可算了吧 我说星际之门纯骗钱的你就搬出5G骗钱，后面EUV灭美怎么不回我了？这玩意儿是真的美股毁灭机<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  sellboy  
##### 443#       发表于 2025-1-27 09:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286222&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-27 09:32</a>

我也没见县城到县城之间有高铁啊？再说5G更像是高速公路，铁路/高速公路/普通道路/空运/海运就像有线/WLA ...</blockquote>
4G属于被5G上位替代难以构成互补的，首先基础算法就保证了5G有比4G更高的利用率。

而使用波束成形天线更是允许在人少的地方使用低频频段实现更稀的全覆盖。

人多的地方使用高频，不仅频宽更大数据吞吐量增强，而且低覆盖反而成了基站高密度部署不怕彼此干扰的优点。

无论疏密部署，5G都是上位选择。


*****

####  泰坦失足  
##### 444#       发表于 2025-1-27 10:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286366&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-27 09:52</a>

可算了吧 我说星际之门纯骗钱的你就搬出5G骗钱，后面EUV灭美怎么不回我了？这玩意儿是真的美股毁灭机 ...</blockquote>
我又不懂EUV，投资美股基金纯粹是为了跑赢通胀，。国内电车/消费电子这么发达也没影响美股中的对应公司股票啊。再说我是觉得AI这路还走的下去，5年前最先进最大最in的模型还是Google的T5。它能干这个：

<img src="https://img.saraba1st.com/forum/202501/27/100248vypdl2zdodpcyddt.png" referrerpolicy="no-referrer">

<strong>1.png</strong> (962.6 KB, 下载次数: 0)

下载附件

2025-1-27 10:02 上传


*****

####  Alce79  
##### 445#       发表于 2025-1-27 10:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286427&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-27 10:04</a>

我又不懂EUV，投资美股基金纯粹是为了跑赢通胀，。国内电车/消费电子这么发达也没影响美股中的对应公司股 ...</blockquote>
是美国跑AGI快还是闹钟跑EUV快？

我之前说星际之门连应用场景的饼都没画摆明对家内部是无头苍蝇继续堆算力，你上来就说堆算力是对很快出简陋版AGI。

提EUV的原因是你自己先转5G得出无用没关系，我提EUV的理由是无用有关系 星际之门要真像5G结局就等着被闹钟的EUV引爆美股核弹。

*****

####  下九流3  
##### 446#       发表于 2025-1-27 10:10

你们能不能不要回泰坦了，这人说话总让我幻视成一个话多的MD2.

*****

####  sellboy  
##### 447#       发表于 2025-1-27 10:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286427&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-27 10:04</a>

我又不懂EUV，投资美股基金纯粹是为了跑赢通胀，。国内电车/消费电子这么发达也没影响美股中的对应公司股 ...</blockquote>
能不能发展有没有泡沫是两个问题

现代互联网比21世纪初的互联网发展何止百倍，但是那时的互联网企业的估值就是有泡沫还爆了。


*****

####  星花  
##### 448#       发表于 2025-1-27 10:13

现实技术，和股票之类早没关系了。

*****

####  alixsander  
##### 449#       发表于 2025-1-27 10:16

<blockquote>泰坦失足 发表于 2025-1-27 09:47
你要觉得你赢了，你随意。我只是觉得这些鉴证博主和卖课博主上来就是赢赢赢就莫名其妙的。

https://planet ...</blockquote>
我也同意这个看法

本身MoE又不被看好，又转回稠密了，是DS有魄力重新去走这条路

DSV3的训练机时估算是500万美元很厉害

但不代表项目开销是500万，这本身是一个很显然的事实

赢赢赢没意思，实际上硬件劣势还是存在。Dual Pipe本身也是针对H800的创新，其他企业也可以使用。对Ascend超节点来说实际上不能使用PP发挥不了高联算比优势，在Dsv3的训练架构提升远没有H800大。

当然我也不怀疑后面会有针对国产设备进行极致优化的实践出现


*****

####  泰坦失足  
##### 450#       发表于 2025-1-27 10:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286456&amp;ptid=2224673" target="_blank">Alce79 发表于 2025-1-27 10:09</a>

是美国跑AGI快还是闹钟跑EUV快？

我之前说星际之门连应用场景的饼都没画摆明对家内部是无头苍蝇继续堆算力 ...</blockquote>
我从来都没觉得吹的那种AGI能短期内实现，我看好的一直都是大模型驱动的机器人。以NLP为例，最开始能正确处理几个长句子甚至一个文章输出一句话的答案都惊为天人。现在LLM的上下文低于64k就很丢人了。那如果一个模型能正确的认知世界，甚至3D世界，知道自己的交互对世界能产生什么作用。那会如何？是否是通用性人形助手机器人的曙光。我24年认为Sora有这种潜力，毕竟GPT最开始也不过是知道上面100个token给你往下写10个续写机器而已。后来证明，哦，好像没用。可能缺点什么，有可能是模型尺寸太小，有可能是这路走不通。

反正5000亿美元又不是一口气投进去的，美元通胀也不缺这一手，于是比喻了下5G。5G不也没想象中管用吗？5G元年时候各个写的和科幻小说似的。

*****

####  星花  
##### 451#       发表于 2025-1-27 10:19

Ai没了，再找新题材就行了，比如卖火星土地。据说当年上海解放时股市还在涨呐，你们太小看金融有多离谱了。


*****

####  Alce79  
##### 452#       发表于 2025-1-27 10:23

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286537&amp;ptid=2224673" target="_blank">星花 发表于 2025-1-27 10:19</a>

Ai没了，再找新题材就行了，比如卖火星土地。据说当年上海解放时股市还在涨呐，你们太小看金融有多离谱了。 ...</blockquote>
想多了 EUV出炉并迭代AI芯片意味着美国最后的科技堡垒也完蛋了，半导体产业要被冲烂。


*****

####  星花  
##### 453#       发表于 2025-1-27 10:33

机器人你必须把那堆东西放到机器内部，你总不能指望联网吧?那就又回到5G有没有用的问题了。

还有别把技术看的那么重，阿根廷股市也是能涨的，虚拟币也是能涨的，甚至一块石头也是能吵的。

*****

####  i0ncube_R  
##### 454#       发表于 2025-1-27 10:33

即使硬件被突破，整个美西方也还有一整套软件生态，以及配套的媒体系统，硬件技术不是最后的堡垒，而是任重道远的攻坚战的前哨

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  harry3  
##### 455#       发表于 2025-1-27 10:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286143&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-27 09:17</a>

我能吧泰坦哥踢出这个楼吗？好像只有版主才可以吧</blockquote>
键政大V就算了，恒河水这种玩意儿的帖文就别转了


*****

####  cube  
##### 456#       发表于 2025-1-27 11:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286529&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-27 10:19</a>
我从来都没觉得吹的那种AGI能短期内实现，我看好的一直都是大模型驱动的机器人。以NLP为例，最开始能正确 ...</blockquote>
5G比元年吹的那些管用多了，它只是不像4G技术在个人终端领域给普通人肉眼可见的体验提升而已。

不熟悉的领域少露怯，别瞎打比方。

*****

####  机吉斯卡  
##### 457#         楼主| 发表于 2025-1-27 11:22

<blockquote>harry3 发表于 2025-1-27 10:58
键政大V就算了，恒河水这种玩意儿的帖文就别转了</blockquote>
大江户应该可以吧

*****

####  2017.05.04  
##### 458#       发表于 2025-1-27 11:22

踢人没必要吧，不想看直接挂黑名单不就得了

不过只为跑赢通胀其实没必要投资美股，风险没兑现不代表没有风险


*****

####  LeonsCat  
##### 459#       发表于 2025-1-27 11:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285980&amp;ptid=2224673" target="_blank">無始無終 发表于 2025-1-27 08:36</a>

Kimi模型的性能太差了，怎么四两拨千斤啊，拿知乎toyama nao做的模型评分来看

这是24年6月DeepSeek V2推 ...</blockquote>
啥时候开源啥时候上桌。

字节的文化基因让我对它说的任何话打三折。

*****

####  LeonsCat  
##### 460#       发表于 2025-1-27 11:35

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67287095&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-27 11:22</a>

大江户应该可以吧</blockquote>
刀妹的贴在审慎阅读前提下很有营养，但是什么恒河水啦之类的还是别拿来忽悠人了，阿怡都不如。


*****

####  机吉斯卡  
##### 461#         楼主| 发表于 2025-1-27 11:36

其实很多人不知道DeepSeek（以下简称DS）具体创新了些啥，我就来捋一捋（可能有些学术）：

1、首先是DS-V2（2024年5月发布，图1~图2）。DS-V2其实可以看做是DS第一次小出圈，当时就靠超低价格直接让国产大模型厂商纷纷降价。DS-V2放弃了DS-V1的dense（密集）路线，转而使用MoE（混合专家模型）路线。Dense大模型是目前国外主流的模型架构，但是其特点就是参数量大，硬件消耗大。MoE则是相当于把dense大模型变成很多个sparse（稀疏）的专家（expert）小模型，通过多个模型聚合来达到和dense大模型相当的能力。转成MoE架构，DS-V2不仅激活参数量**减少，并且性能提升很高。你可能问，MoE这么好为什么国外大模型不爱用呢？主要原因就是MoE大模型有个问题叫负载均衡（load balance），会导致训练不稳定。其表现就是：某些expert很重要而某些expert不重要，以至于删除某些expert整个模型都会崩掉，而删除另一些expert则几乎不会对模型性能产生影响。这会导致一个问题，就是训练过程中会采用所谓的专家并行（expert parallelism）机制，通过将不同的expert放到不同的显卡上来加速训练，而load balance问题会导致某些重要的expert计算量更大，最终结果就是不重要的expert所在的显卡跑不满，效率不够高。DS-V2则在一些现有的解决load balance问题的方法基础上，引入了额外的损失函数（即设备级平衡损失和通信平衡损失，图3）来让模型在训练中自主控制不同设备间的平衡。这两个优化方法都是他们的创新点。

DS-V2的另一大创新是MLA（Multi-Head Latent Attention，多头潜注意力，图4）。这个说起来就太复杂了，我就大概简单说下。在大模型运行过程中，每次生成一个token（你可以大概理解为一个字），而每个token只与之前的token有关。在不进行优化的情况下，每个token生成的时候都需要把之前所有的token都处理一遍，这样的话效率非常差。由于每个token只与之前的token有关，我们就可以把上一次生成过程中计算过的矩阵保存下来，这样生成下一个token我们可以复用这个矩阵，只需要计算新token的注意力即可。这个技术叫做kv-cache（解释的很笼统，实际上很复杂），是目前大模型非常常用的优化算法。但是kv-cache本质上是个“以空间换时间”的技术，即需要额外的显存保存这些kv-cache，这样的话在上下文（context）很长的情况下显存占用会非常高。此外，在实际部署时服务器一般会批量处理并发请求，这样的并发请求会带来恐怖的kv-cache量，会导致显存不够用。之前也有人试图优化kv-cache，2019年和2023年谷歌分别提出来了GQA和MQA，简单来说就是把多个多头注意力模块合在一起，共用kv-cache。这样子显存占用确实少了，但是对大模型的性能影响极大。MLA在我看来是个天才的想法，其思路和LoRA（玩过AI绘画和大模型的应该都知道这是啥）非常类似，就是把注意力模块里面的KV矩阵进行低秩分解，这样在保存kv-cache的时候保存的就是一群低秩矩阵，显存占用**减少的同时，可以更好的scale up模型参数（图5）。注意这只是一个非常简略的介绍，实际上MLA还是很复杂的，主要还需要处理位置编码的问题……

比较有趣的是去年梁文峰的访谈提到这个MLA是某位研究员突发奇想想到的[二哈]当然从想法到落地还是很难的，据他所说用了几个月。

2、DS-V3（2024年12月发布，从V2到V3之间他们也发布了不少模型，包括图文模型、统一多模态模型，这里不做过多介绍）发布时候引来了极大的关注，也是DS第一次大范围出圈，主要就是其训练成本低的令人吃惊。但需要注意的是，论文中所提550万美元训练成本实际上是按照租用H800训练的情况按出租费计算的，并没有算进数据和人工的成本。DS-V3和DS-V2采用了相同的MoE架构，但DS-V3引入了MTP（Multi-Token Prediction，多token预测，图6）机制。传统的LLM，每次只生成一个token，这种机制叫做NTP（Next-Token Prediction，次token预测）。MTP顾名思义就是一次生成多个token，这种想法并非DS原创，最早是Meta在24年4月提出的。但是DS对MTP架构进行了改进，那就是Meta的MTP，同时生成的多个token之间没有联系，相当于上文结束直接预测接下来的N个token。而DS的MTP，通过对MTP模块的重新设计，使得同时生成的多个token之间有了相互的联系，具体来说就是生成的第1个token会引导生成的第2个token会引导生成的第3个token……以此类推（此外这些MTP模块的输入是embedding而非Meta MTP的logits，这点解释起来会有点复杂但实际上很简单我就不说了）。DS-V3通过采用MTP，主要优点是：①MTP对数据的利用率更好②MTP在生成时可以通过更好的预先规划产生更好的生成结果。

除了架构上的升级，DS-V3的成本之所以能做到那么低，主要原因是DS优化了训练的方法。我并非并行计算工程师所以看不太懂这部分的内容，只能大致总结为几点：①采用FP8混合精度训练（图8）。一般来说现在的大模型都采用BF16精度训练，而DS-V3原生采用FP8精度进行训练，只有一些关键的参数采用BF16/FP32精度训练。FP-8精度训练的效率是BF-16精度约1.6倍。他们为了稳定的FP8训练对运算底层操作进行了大量优化，因为英伟达本身没有对FP8进行太好的优化，毕竟大部分AI企业都是再用BF16进行训练；②优化了并行流水线（pipeline，图7），如果说前面量化训练我还能看懂一些，这一部分我就完全看不懂了。只能看出他们通过重叠优化前向和反向传播过程中的计算和通信来提升pipeline并行效率，同时优化了节点（节点指一个计算单元，一般一个节点会有多张计算卡，跨节点通信一般是通过网线传输）之间的通信。他们这些优化可不是瞎优化的，而是针对他们自己的MoE架构的定制化优化，修改了英伟达原生的pipeline来最大化训练和推理效率。这些优化，再加上他们一次成功，没有返工的情况（这点很可贵，去年Amazon花14亿美元训练大模型结果练崩了，就是Amazon Titan），共同造就了DS-V3“AI拼多多”般的低成本（图9）。

他们在探索这么多之后对硬件设计提出了自己的看法（图10），其实主要就是提高FP8训练效率，实际上如果硬件设计更好些训练效率还能再提高。老黄的卡对FP8训练支持的一般所以他们做了大量修改才做到了稳定训练。

3、DS-R1（2025年1月公布）。DS-R1相比于V3，其创新性主要体现在“范式转换”上。一直以来，LLM的训练方式都是让模型跟着数据学生成，这种方式称之为监督学习（Supervised Finetuning，SFT）。而R1采用了强化学习（Reinforcement Learning，RL）的方法。RL实际上不是新东西，从玩游戏到机器人都能看到RL的身影。RL通俗来说就是让模型（agent）和环境（environment）进行互动，然后通过其互动的结果进行打分（reward），从而训练模型。大语言模型此前采用的RLHF（人类反馈强化学习）也是RL的一种。但和RLHF不同的是，R1采用的RL方法（称为GRPO，Group Relative Policy Optimization，组相关策略优化，图11）并不需要一个庞大的人类标注数据库。他的训练方式很简单：让模型自己生成过程，最后只检查结果是否正确。如果是数学题，那么就看输出的结果文本；如果是编程题，那就看运行后的结果。而DS发现，在V3的基础上直接采用这种简单的RL，竟然能让新的模型具有推理（Reasoning）的能力，而且随着训练步数增多，其思维链（Chain-of-Thought，CoT）的长度也越来越长（图12），并且发现模型开始在推理过程中自我反思（图13）。这个纯RL方法练出来的模型就是R1-Zero，叫Zero是受到AlphaGo-Zero的启发（AlphaGo-Zero是完全RL训练出来的模型，一开始没有教模型任何围棋知识，一切全靠模型自己摸索，最后达到超越人类）。

但是DS发现R1-Zero的CoT并不是很完美，最大问题是可读性很差。这相当于模型在自己练自己，没有额外的指导就会产生这样的效果。所以他们利用R1-Zero生成了一批带有CoT的“冷启动样本”，然后对V3进行了一次SFT，这样就获得了一个初步能够进行推理的模型（称为模型1）。接下来他们对模型1进行一次基于GRPO的RL（和R1-Zero一样），然后用这个模型1生成一批高质量的推理数据集。接着，再用V3生成一批没有推理的数据集（主要用于保证模型的文科类能力，比如写作、事实问答）。然后将这两个数据集合并（文理科合并），重新对V3进行SFT，获得模型2，再对模型2进行基于GRPO的RL，最终获得R1。整个流程如图14。

可以看到，R1的训练本质上是一个“左脚踩右脚”的过程（需要和之前所谓的“左脚踩右脚”的SFT区分开，那个是拿合成数据对模型进行SFT，结果效果很差），全程没有使用人工标注数据，从RL到冷启动到SFT到RL，全都是依靠V3自己的能力。R1证明了一件事：就是如果基础模型能力够强（如V3），在RL过程中它就能自己学会推理。这也是为什么国外AI圈的人看到DS-R1之后惊呼AGI竟然离我们如此之近的原因：因为R1说明能力足够强的模型是可以不依靠人类自己进化的（当然，严格来说现阶段的reward还是需要标签的）。

接下来呢？其实DS自己的技术报告里面写的很清楚了，R1并非完美，他们已经在着手改进。有几个重点：①通用能力：函数调用、多轮对话、复杂角色扮演、格式化输出，这些任务R1完成的一般；②语言混合：目前R1针对中英**了优化，CoT也主要是这两种语言，需要对更多语言进行优化；③提示工程：目前R1对提示很敏感，few-shot不如zero-shot；④软件工程：由于复杂软件的验证时间长效率低，所以在RL阶段没有对复杂软件任务的情景进行训练。

这几点我认为都是很容易解决的，我个人的提议是，最好能在RL阶段让模型在CoT里学会自己调用工具（比如使用计算器、网页搜索、调用API等），这样模型的CoT能力会有极大的提升（本质上是一种具有agent能力的CoT）。

https://weibo.com/5338698416/5127239862061288


*****

####  Imanmi  
##### 462#       发表于 2025-1-27 11:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286227&amp;ptid=2224673" target="_blank">x分裂者 发表于 2025-1-27 09:32</a>
无人码头用了这么久5g了，又是我用不到=没有，而且讨论ds的楼扯什么勾八5g，在这恶心人吗 ...</blockquote>
很简单的道理啊，人家真的买了美股，所以现在都是在ai泡沫的崩盘恐惧下的发疯罢了……要我说一惊一乍其实不太适合玩美股，特别是现在大争之世

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  机吉斯卡  
##### 463#         楼主| 发表于 2025-1-27 11:58

<blockquote>LeonsCat 发表于 2025-1-27 11:35
刀妹的贴在审慎阅读前提下很有营养，但是什么恒河水啦之类的还是别拿来忽悠人了，阿怡都不如。 ...</blockquote>
刀妹谁？

*****

####  moekyo  
##### 464#       发表于 2025-1-27 12:00

美股今天相关都跌了，然后一堆人说是史普尼克时刻了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  泰坦失足  
##### 465#       发表于 2025-1-27 12:05

 本帖最后由 泰坦失足 于 2025-1-27 12:07 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67287320&amp;ptid=2224673" target="_blank">Imanmi 发表于 2025-1-27 11:49</a>

很简单的道理啊，人家真的买了美股，所以现在都是在ai泡沫的崩盘恐惧下的发疯罢了……要我说一惊一乍其实 ...</blockquote>
真不至于，也没投资多少。不如之前GPT4没法复现时候，然后GPT4随便一个指令比我专门建立训练集训练出来的模型在测试集上效果好的多的挫折感。尤其是 4.0就这样了，未来会如何？ 后面4o/o1和开源模型证明,即使是现在为特定任务专门设计的微调和流程还是必须的。没有到“我说个任务，你完成，然后完整的证明正确性”的程度。我相信O3也到不了这个程度。


*****

####  亚尔迪8424  
##### 466#       发表于 2025-1-27 12:42

哈哈哈哈哈哈哈

9f519e8bgy1hxz45xdxwhj21403b54qp.jpg
(320.92 KB, 下载次数: 0)

下载附件

2025-1-27 12:42 上传

<img src="https://img.saraba1st.com/forum/202501/27/124200wfdf0gd6khdz88sg.jpg" referrerpolicy="no-referrer">

*****

####  2017.05.04  
##### 467#       发表于 2025-1-27 12:45

感觉接下来硬件开发的侧重点可能也从大集群转向小单元迭代，节约成本提高效率


*****

####  sellboy  
##### 468#       发表于 2025-1-27 13:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67287737&amp;ptid=2224673" target="_blank">亚尔迪8424 发表于 2025-1-27 12:42</a>

哈哈哈哈哈哈哈</blockquote>
我让R1重翻，还叫他指出谷歌翻译的问题。<blockquote>重新翻译后的中文版本：

David

@DavidSHolz

在我的测试中，DeepSeek 在古代中国哲学和文学领域彻底碾压了西方模型，同时它的英语能力也远超我的第一手中文资料来源。这种感觉就像与跨越世代的文学、历史和哲学知识进行深度对话——而这些内容我此前从未接触过。这令人十分动容。这种结果也在情理之中：西方实验室不重视中文数据的训练（但中国实验室却兼顾中英文数据）。值得注意的是，中国比西方多保留了数千年的文学遗产（因为西方已丢失了大部分罗马、希腊、埃及的文献，而中国保存了自己的典籍）。本质上，我们的 AI 模型缺乏西方思想体系的文学根基，但中国模型却完整保留了自身的文化基础。这既是一种传统的“数据优势”，也可能在精神与哲学层面的自我实现上，带来一种更隐性的优势。

谷歌翻译的错漏之处分析：

术语准确性

原文："crushes"

谷歌译为“完胜”，但“彻底碾压”更贴合口语化表达，体现压倒性优势。

原文："communing with... across generations"

谷歌译为“跨代交流”，但“与跨越世代的...进行深度对话”更精准传达“communing”的深层互动感。

语义连贯性

原文："we lost the majority of our roman/greek/egyptian literature"

谷歌译为“我们失去了大部分罗马/希腊/埃及文学”，但“西方已丢失了大部分罗马、希腊、埃及的文献”更符合中文逻辑，并补充了“西方”作为主语。

格式与细节

原文："several thousand years more of literary history"

谷歌译为“文学史比西方多了几千年”，但“多保留了数千年的文学遗产”更准确，强调“保留”而非单纯时间长度。

原文："spiritual and philosophical self-actualization"

谷歌译为“精神和哲学自我实现”，但“精神与哲学层面的自我实现”更符合术语规范，且“层面”一词增强了表述严谨性。

标点与语法

原文分号 ";" 在谷歌翻译中被忽略，导致句子衔接生硬。重译版本通过分段和逻辑连接词（如“本质上”）优化了连贯性。

文化背景补充

原文隐含对比中西方文化传承差异，谷歌翻译未明确“中国保存典籍”与“西方丢失文献”的因果关系，重译版本通过补充“因为西方已丢失...”使逻辑更清晰。

总结：

谷歌翻译整体传达了原文大意，但在术语精准度、语义连贯性、文化背景补充等方面存在不足。重译版本通过优化措辞、补充逻辑关系，更完整地还原了原文的学术性与情感色彩。</blockquote>

*****

####  qratosones1337  
##### 469#       发表于 2025-1-27 13:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67286496&amp;ptid=2224673" target="_blank">alixsander 发表于 2025-1-27 10:16</a>

我也同意这个看法

本身MoE又不被看好，又转回稠密了，是DS有魄力重新去走这条路</blockquote>
24年9月华为挂了个Arxiv，提出了新的HiF8数据格式，按时间节点反推，出来发论文说明910C大概率已经实装了这种格式——那么问题来了，你猜这种数据格式在研发的时候有没有DeepSeek跟着一起提需求？别忘了DeepSeek用的FP8格式也不是H卡原生支持的


*****

####  The_Ether_  
##### 470#       发表于 2025-1-27 13:15

<blockquote>就在刚刚，英伟达美股夜盘跌超5%，博通跌超4%。美股期货持续走低，纳斯达克指数期货跌超1.2%。与此同时，主导星际之门计划的软银集团股价一度下跌近6%，创下去年11月1日以来的最大跌幅；藤仓大跌超8%，东京电子和Disco均跌超3%。日经225指数盘中转跌。</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">今晚开盘是不是有乐子看了


*****

####  morgendave  
##### 471#       发表于 2025-1-27 13:43

deepseek MLA主要是cache压缩和long context加速。MOE不是DS才推出来的路线，openAI和mistral都是。DS最大的突破还是RL和infra codesign


*****

####  LeonsCat  
##### 472#       发表于 2025-1-27 13:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67287397&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-27 11:58</a>

刀妹谁？</blockquote>
大江户战士在泥潭混的时候，外号刀妹啊……著名反绿战士。ID记得是【☣】医疗上尉


*****

####  机吉斯卡  
##### 473#         楼主| 发表于 2025-1-27 13:55

<blockquote>LeonsCat 发表于 2025-1-27 13:50
大江户战士在泥潭混的时候，外号刀妹啊……著名反绿战士。ID记得是【☣】医疗上尉。

哦得提一句，和知乎外 ...</blockquote>
叫刀妹的太多了，我知道大江户时候泥潭ID也是这个

记不清他是不是疫情时候回国的那个了

我记得和他在相关楼里讨论过计生问题


*****

####  Ty_cc  
##### 474#       发表于 2025-1-27 14:02

我在小黑屋里看过同ID的号<img src="https://static.saraba1st.com/image/smiley/face2017/005.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  alixsander  
##### 475#       发表于 2025-1-27 14:10

<blockquote>qratosones1337 发表于 2025-1-27 13:11
24年9月华为挂了个Arxiv，提出了新的HiF8数据格式，按时间节点反推，出来发论文说明910C大概率已经实装了 ...</blockquote>

虽然但是…你靠这个来猜没什么意思……

直接点开稼先社区看一下R1训练和推理集群仿真的帖子和讨论就好了……


*****

####  holmesjerry  
##### 476#       发表于 2025-1-27 14:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67288268&amp;ptid=2224673" target="_blank">LeonsCat 发表于 2025-1-27 13:50</a>
大江户战士在泥潭混的时候，外号刀妹啊……著名反绿战士。ID记得是【☣】医疗上尉和①СTAГЭ1。他属于和 ...</blockquote>
那就彻底错了。。大江户战士在泥潭就两个常用号
大江户战士和罗马字的oedosolider
刀妹是另一个人

*****

####  2017.05.04  
##### 477#       发表于 2025-1-27 14:15

刀妹自称是柳叶刀，和大江户战士不是一个人吧


*****

####  alixsander  
##### 478#       发表于 2025-1-27 14:20

刀妹抽象女坛友

Oedosoldier是x上活跃的旅日/美青年？A1111时代还在泥潭讨论过SD

要说有什么相似度的话，看上去都还是偏建制的

*****

####  momodog  
##### 479#       发表于 2025-1-27 14:22

恒河水怎么了？有什么黑料吗？

*****

####  机吉斯卡  
##### 480#         楼主| 发表于 2025-1-27 14:25

Meta内部成立了四个作战室分析DeepSeek，两个主攻训练效率，一个主攻训练数据，还有一个主攻模型架构。他们害怕LLaMA 4(还没完成训练)发布即落后

我个人的消息(来自我在Meta的同学)是这是真的，Meta内部正在把其他部门的人调过去救火，全在加班加点copy DeepSeek[二哈] ​​​

https://weibo.com/5338698416/5127397457793286


*****

####  pf67  
##### 481#       发表于 2025-1-27 14:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67288465&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-27 14:25</a>
Meta内部成立了四个作战室分析DeepSeek，两个主攻训练效率，一个主攻训练数据，还有一个主攻模型架构。他们 ...</blockquote>
其实这几天国内大厂各种发文洞察deepseek的专家也一大堆，已经远超deepseek研发

—— 来自 OPPO PCLM10, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  黄泉川此方  
##### 482#       发表于 2025-1-27 15:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67288336&amp;ptid=2224673" target="_blank">Ty_cc 发表于 2025-1-27 14:02</a>

我在小黑屋里看过同ID的号

—— 来自 鹅球 v3.3.96</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">大江户在漫区与百合豚战斗，然后陨落了


*****

####  披头破落户  
##### 483#       发表于 2025-1-27 16:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67282933&amp;ptid=2224673" target="_blank">lamuchair 发表于 2025-1-26 18:11</a>
请问该如何操作啊?我给他一整个文档,他直接BA 工了</blockquote>
调教好以后直接复制原文给他

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  mimighost  
##### 484#       发表于 2025-1-27 16:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67285883&amp;ptid=2224673" target="_blank">pf67 发表于 2025-1-27 08:06</a>

赢学赢来赢去到底谁赢

ds开源怎么都对消费者是大好事，但国内一堆的大厂也都在搞闭源嘛，只不过是因为内卷 ...</blockquote>
对于研究者也是好事，现在r1这个思路打开了，今年llm rl的工作要井喷了

而且rl llm的大小显著的小于主流的闭源llm，我觉得很多大企业要开始自研了


*****

####  mimighost  
##### 485#       发表于 2025-1-27 16:39

 本帖最后由 mimighost 于 2025-1-27 16:41 编辑 

deepseek r1最大的成果在r1 zero

v3你可以说本质上是一个工程上的工作，主要是显摆自己对于英伟达芯片的理解的

但是r1 zero是跨时代的工作，可以说和gpt3是一个同一个体量的工作。为什么呢，因为rl在llm上面一直是不work的，所以才会有各种prm/orm，各种rlhf用各种神经网络模型去拟合reward信号的手段。r1 zero直接告诉天下人，这些都不需要，你要是有答案，直接把答案对还是不对，作为信号输给模型学习就好了，其他的都交给算法。并且在600b的模型上把这个东西做成功了。这就很不得了了。

不出一个月，各个系列的开源模型，不管是llama还是千问，这个东西都会成为标配。

对于企业来说，这也是个重大利好，因为企业其实都是领域问题，实际上不需要几百b的超大模型，现在看来rl zero的训练方法，对于小llm非常友好，几十b也能上，而且跑个几千步就有很不错的效果。我预测会有很多企业训练自己的专用模型。


*****

####  mimighost  
##### 486#       发表于 2025-1-27 16:43

对于软工其实也是利好

r1的模型，其实把算法端的工程量简化了，之后的大量工作会集中在给rl建设环境上来，训练端会白菜化。


*****

####  mimighost  
##### 487#       发表于 2025-1-27 16:50

总的来说，deepseek这次开源对于世界都是一个贡献

但是不要把openai这么快的踩下，openai还有一些货，而且他们还有一些策略重新让开源无效。从o3现在流出的信息可以看出来，o3的思考时间可以长达十几分钟，甚至一个小时。这么说他们的context大小可能会有几百万上千万之多。这么大的context，即使开源了模型，跑得起来也没几个。


*****

####  lactone  
##### 488#       发表于 2025-1-27 16:58

o3那个作弊到底实锤了没

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  mimighost  
##### 489#       发表于 2025-1-27 17:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67289233&amp;ptid=2224673" target="_blank">lactone 发表于 2025-1-27 16:58</a>

o3那个作弊到底实锤了没

—— 来自 S1Fun</blockquote>
o3就算frontier math作弊，它swebench-v可有70%

总不可能所有测试都作弊吧，那放出来肯定就露馅了


*****

####  泰坦失足  
##### 490#       发表于 2025-1-27 17:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67289136&amp;ptid=2224673" target="_blank">mimighost 发表于 2025-1-27 16:39</a>

deepseek r1最大的成果在r1 zero

v3你可以说本质上是一个工程上的工作，主要是显摆自己对于英伟达芯片的理 ...</blockquote>

我觉得从小模型从头训练不太可行。我对这个的理解就是，RL在大尺寸上才有效，一个大模型还是有必要的。训练出来后再慢慢蒸馏（虽然蒸馏这一步写的不如其他部分详细，我就特好奇这一步）

To answer this question, we conduct large-scale RL training on Qwen-32B-Base using math, code, and STEM data, training for over 10K steps, resulting in DeepSeek-R1-Zero-Qwen-32B

<img src="https://img.saraba1st.com/forum/202501/27/171448ap5oyj7bzjl399z9.png" referrerpolicy="no-referrer">

<strong>1.png</strong> (162.78 KB, 下载次数: 0)

下载附件

2025-1-27 17:14 上传


*****

####  泰坦失足  
##### 491#       发表于 2025-1-27 17:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67289165&amp;ptid=2224673" target="_blank">mimighost 发表于 2025-1-27 16:43</a>

对于软工其实也是利好

r1的模型，其实把算法端的工程量简化了，之后的大量工作会集中在给rl建设环境上来， ...</blockquote>
按O1暗示的，高质量的过程reward甚至树搜索，很难复现或者实验成本太高了。R1这样的RL就简单多了。而且可以走R1 API-&gt;蒸馏 本地的R1版Qwen/llama-&gt;进一步RL专有模型微调这条路

*****

####  mimighost  
##### 492#       发表于 2025-1-27 17:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67289320&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2025-1-27 17:16</a>

对于RL能成功，我觉得实在是太Waaagh了。没想过居然这样就行。

我觉得从小模型从头训练不太可行。我对这个 ...</blockquote>
嗯，这个要看你rl的问题是什么

问题越难肯定就需要更大的模型

但是现在港科有人复现了，对于简单的游戏，7b甚至3b就能上r1 zero，所以要用多大尺寸的模型看你的问题的复杂度。r1 zero比起千问自己的QwQ-32B也差不多太多了，这个实现上简单太多了。


*****

####  d2loader  
##### 493#       发表于 2025-1-27 18:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67288465&amp;ptid=2224673" target="_blank">机吉斯卡 发表于 2025-1-27 14:25</a>

Meta内部成立了四个作战室分析DeepSeek，两个主攻训练效率，一个主攻训练数据，还有一个主攻模型架构。他们 ...</blockquote>
幻方的团队智力密度太高了, 至少有10位数的竞赛拿牌级别选手, 除了我国全世界其他国家都量产不了这么多智力资源

meta这种大公司病企业不要想了


*****

####  电风扇  
##### 494#       发表于 2025-1-27 18:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67287989&amp;ptid=2224673" target="_blank">sellboy 发表于 2025-1-27 13:10</a>
我让R1重翻，还叫他指出谷歌翻译的问题。</blockquote>
很有意思，在谷歌翻译看来we=我们，在deepseek嘴里we=他们


*****

####  lamuchair  
##### 495#       发表于 2025-1-27 18:50

让它写个总结报告的八股文，它直接说“ 对不起，我还没有学会如何思考这类问题，我擅长数学、代码、逻辑类的题目，欢迎与我交流。”，请问一般用什么句式，可以让它顺利完成。


*****

####  机吉斯卡  
##### 496#         楼主| 发表于 2025-1-27 18:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67289898&amp;ptid=2224673" target="_blank">lamuchair 发表于 2025-1-27 18:50</a>

让它写个总结报告的八股文，它直接说“ 对不起，我还没有学会如何思考这类问题，我擅长数学、代码、逻辑类 ...</blockquote>
政府类的八股文好像不行，其他的你试试看一段段引导？


*****

####  biye  
##### 497#       发表于 2025-1-27 19:03

API调用总提示欠费 402 Insufficient Balance

有人遇到过吗 充了10块钱也有免费额度 其他模型调用正常 


*****

####  机吉斯卡  
##### 498#         楼主| 发表于 2025-1-27 19:58

看看这篇论文：《7B Model and 8K Examples: Emerging Reasoning with Reinforcement Learning is Both Effective and Efficient》7B 小模型：如何用 8000 个示例，“炼”出会自我反思的 AI？

地址：http://t.cn/A63XKMgO

我有个朋友，每次听到「AI」都惊呼：“完蛋了！以后我们是不是都要给机器人打工啊？” 还有个做大语言模型的朋友，一提到「大模型」就一脸绝望：“没个几万块的服务器，没个海量数据，还搞什么人工智能？”

今天我要说的故事，正是要打破这些“AI门槛高到太平洋”的刻板印象：告诉你，小到只有 7B（70 亿）参数的模型，也能通过区区 8000 个（对，你没看错）训练样本，变身成会一步步推理，还能自我反思的解题高手！

没错，有钱当然可以为所欲为：几百亿、上千亿参数的大模型就跟流量明星一样，自带光环，烧钱训练、效果爆炸。但并不是人人都能砸得起大价钱。对于那些预算有限、想用小模型干大事的研究者或小团队来说，这篇科普或许就是一根救命稻草，让你看见“低成本、高收益”的新希望。

小模型的逆袭：为什么它比你想象的还要厉害？

过去，很多人以为：模型越大，就越厉害，小模型只配做点边角料的任务。可实验告诉我们，当你用对方法，小模型也能有大作为。这次研究的团队就把一个只有 7B 参数的模型，丢进了强化学习的“修炼场”里，仅用 8000 个数学题目“锻炼”了一阵子，结果“咣当”一声，它变聪明了：能在复杂的数学考试中拉出可观的分数，还会认真分析、仔细检查，甚至出现了类似人类的“自我反思”！

所谓“自我反思”，就好比你做题时，先把思路写出来，然后自我怀疑再检查：我刚才那个解法好像有问题？再算一下看看。是不是很人性化？很多大型模型也能这样，但人家花的是几百万甚至上千万条数据、无数算力。如今 7B 小兄弟也能学到，简直是个宝藏。

强化学习：用简单的奖励规则“教”AI

可能你会想：是不是又是什么极复杂的算法，把模型训练成这样？

没！那可没这么花哨——就是所谓的“PPO 强化学习”，配上一个极简的奖励（Reward）机制：

- 答案对了，格式好看，奖励 +1。

- 答案错了但格式还行，奖励 -0.5。

- 没给出正确结论，甚至连个像样的收尾都木有，奖励 -1。

这就像你教小孩写作业一样：写对了鼓励，写错了轻罚，不写或潦草就重罚。靠着这样的小鞭子一挥，AI 居然慢慢学乖了。刚开始它可能瞎比划，写一堆代码段（对，它还会写代码，这也太卷了），后来发现这样不讨好，就转而“用更自然的语言把思路表达清楚”，接着再用一次次的训练，得到了正反馈。最后，这孩子连“怎么反思自己、重新审视答案”都搞懂了。

8000 条题目，就能撬动复杂任务

更惊喜的是，这 8000 条题目本身并不算超级难的怪物级试题，基本是常规的 MATH 数据集题目。可奇怪就奇怪在，这小模型在更高难度的竞赛题（比如 AIME、AMC 这些听起来就脚软的数学考试）上，也能考出好成绩。

简而言之：原本看似“小打小闹”的训练数据，却带来了通用的推理提升，实现了“以小见大”的跨任务泛化能力。

而通常你要想做到这一点，往往要在大量高难度题目上去磨练，还要加大模型规模，甚至上一堆额外的数据和“复杂奖励模型”。可研究结果摆在这儿，却告诉你：“嘿，用不了那么多烧钱的玩意儿，8000 条案例照样能爆发小宇宙！”

两种训练模式：Zero 与有监督预热

研究团队提到他们搞了两种训练策略：

1. SimpleRL-Zero：什么都不做，直接拿基础模型来开练——不做额外的“示范式训练”。模型直接在奖励指引下“摸爬滚打”，居然就已经能开发出长链推理的能力。

2. SimpleRL： 更讲究一点。先让大模型把 8000 道题的详细推理过程写给我们看，小模型学一遍“示范答案”之后，再进入同样的强化学习训练。这样做出来的最终结果更好。

乍一听，好像第二种方式的“成绩”应该甩第一种一条街，但现实并没有这么夸张地拉开差距。在一些测试里，直接 RL 训练（Zero）和先蒸馏后训练（SimpleRL）表现相当接近，让研究者自己都惊讶。不过整体来说，先学一下“详细思路”，再强化训练，还是能更稳定拿到高分。

这事儿为什么如此重要？

给平民 AI 研究者的福音

你不必想象自己是谷歌或 OpenAI 才能玩得转大模型。只要有个小模型，数据有限，也还是能通过一些巧妙设计实现“惊艳时刻”。

落地可能性更高

大模型再牛，训练成本也高得可怕。小模型却能省时省钱，装在中小企业的服务器里都不成问题，这意味着普惠。教育、医疗、客服、学术研究...都能用上类似的方法。

暗示 AI 推理能力的“可塑性”

如果只用八千条题，就能让 AI 学会自我反思，想想看，如果方法再升级一下，是不是更大的潜力正等着被解锁？

结语：别总觉得自己离 AI 很远

好多人一听到 “人工智能”、“大语言模型” 就觉得离自己 108000 里远，跟自己没有半毛钱关系。其实没那么神秘。这篇研究告诉我们，AI 其实和人一样，经常是“一分耕耘，一分收获”——一点点有针对性的训练，也会带来巨大飞跃。

想象一下：只用几张显卡和 8000 道题，就能让一个小小的 7B 模型自带“恍然大悟”的时刻，把题做得像模像样，这玩意儿要是大范围普及了，能降低多少门槛，释放多少潜能？

未来，不一定是大模型一统天下。小而灵活、技巧到位的小模型，也许会成为另一种选择。而且，有了“自我反思”的 AI，谁又敢说它不会在别的任务上闯出意想不到的成绩呢？

所以，别总害怕 AI 抢饭碗。反倒可以想想：说不定下一个生活或工作的好帮手，就是这样一个能“举一反三、试错纠错”的小家伙。现在，机会就在我们面前，看你接不接得住！

公众号链接：http://t.cn/A6398qL4

https://weibo.com/1727858283/5127462434374541

*****

####  i0ncube_R  
##### 499#       发表于 2025-1-27 19:58

<img src="https://img.saraba1st.com/forum/202501/27/195848ry9ozk39i2llbimk.jpg" referrerpolicy="no-referrer">

<strong>img_5562.jpg</strong> (173.21 KB, 下载次数: 0)

下载附件

2025-1-27 19:58 上传

🤣

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 黄泉川此方| + 1|欢乐多|

查看全部评分


*****

####  sellboy  
##### 500#       发表于 2025-1-27 20:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67290376&amp;ptid=2224673" target="_blank">i0ncube_R 发表于 2025-1-27 19:58</a>

🤣

论坛助手,iPhone</blockquote>
我能想象知乎所有的提问后面都有AI阴阳回答了……


*****

####  sellboy  
##### 500#       发表于 2025-1-27 20:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67290376&amp;ptid=2224673" target="_blank">i0ncube_R 发表于 2025-1-27 19:58</a>

🤣

论坛助手,iPhone</blockquote>
我能想象知乎所有的提问后面都有AI阴阳回答了……

