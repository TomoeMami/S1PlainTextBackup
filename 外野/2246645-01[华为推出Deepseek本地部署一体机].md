
*****

####  ltycomputer  
##### 1#       楼主       发表于 2025-2-18 16:11

 本帖最后由 ltycomputer 于 2025-2-18 16:12 编辑 

[原帖](https://www.szw.org.cn/20250218/69016.html)

最近DeepSeek R1的火爆，引起了本地部署的热潮，但大部分个人用户，受到设备的限制，一般只能在个人电脑上部署小尺寸的1.5B或7B等轻量版。要本地部署完整版的R1 671B版本，至少需要500GB内存，以及约800GB(FP8精度)或1.4TB(FP16/BF16精度)显存。

对于企业用户而言，本地部署能够有效保护数据安全和隐私，避免将核心数据传输至第三方云端。针对企业需求，近期DeepSeek一体机也开始快速进入市场，帮助企业或个人客户AI应用快速落地。

华为在上周推出了昇腾DeepSeek大模型一体机，提供从服务器、推理卡、到加速模组等丰富的DeepSeek一体机产品形态。而2月17日华为DCS AI解决方案针对DeepSeek本地部署又推出了一系列FusionCube A3000训练/推理超融合一体机，深度适配DeepSeek V3/R1.以及蒸馏模型，支持私有化部署。

据介绍，FusionCube A3000分为三个版本，一是面向“满血版”DeepSeek R1和V3(671B)的FusionCube A3000 Ultra，支持模型推理，内置2个Atlas800I A2推理服务器，根据官网的操作维护指南，Atlas800I A2是一款4U形态的推理服务器，CPU支持4路鲲鹏920处理器，最多32个DDR4内存插槽，支持最高8个昇腾910 AI加速卡;存储方面使用OceanStor Dorado 5500全闪存存储系统，最大缓存384GB~4TB。

二是面向32B、70B蒸馏模型的FusionCube A3000 Pro，使用一个Atlas800I A2推理服务器和OceanStor Dorado 2100全闪存存储系统。

三是面向1.5B、7B、14B等蒸馏轻量版模型的FusionCube A3000 Lite，采用1个Atlas800 3000(4个Atlas 300I Duo)，没有配备全闪存存储系统，满足一些智能办公、个性推荐等简单应用。

*****

####  ltycomputer  
##### 2#         楼主| 发表于 2025-2-18 16:12

（根据《中华人民共和国数据安全法》，就算不搞网安等保测评，数据安全所有实体都要遵守，本地部署不上云是很多场景的刚需）

*****

####  i0ncube_R  
##### 3#       发表于 2025-2-18 16:14

铲子企业又要大卖特卖铲子了

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  一骑当千  
##### 4#       发表于 2025-2-18 16:15

虽然知道买不起，但还是好奇价格是多少？

*****

####  a4ac7  
##### 5#       发表于 2025-2-18 16:16

 本帖最后由 a4ac7 于 2025-2-18 16:18 编辑 

新闻是有了，就是购买链接还没找到

主要是看下面英伟达的对比样机说3000美元的，有点想法
<blockquote>英伟达表示，GB10超级芯片让Project DIGITS只需使用标准电源插座就能提供强大的性能。借助 Project DIGITS，用户则可以使用自己的桌面系统开发和运行模型推理，并在加速的云或数据中心基础设施上无缝部署模型。同时，用户还可以通过英伟达技术将两台Project DIGITS AI超级计算机连接在一起，运行包含高达4050亿参数的模型。

华为DS版FusionCube A3000以及中科曙光的DS超融合一体机价格暂不清楚，而英伟达面向个人的消费级Project DIGITS的具体售价约在3000美元左右，今年晚些时候上市。</blockquote>

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  sellboy  
##### 6#       发表于 2025-2-18 16:19

<img src="https://i.guancha.cn/news/hmt/2025/02/17/20250217121812371.jpg" referrerpolicy="no-referrer">

跑671b是1911 token/s

*****

####  best32167  
##### 7#       发表于 2025-2-18 16:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458181&amp;ptid=2246645" target="_blank">一骑当千 发表于 2025-2-18 16:15</a>

虽然知道买不起，但还是好奇价格是多少？</blockquote>
“满血版”DeepSeek R1那个，里面2台Atlas800I A2，250-300万吧，还加了存储超300万也正常

*****

####  INDIASH  
##### 8#       发表于 2025-2-18 16:22

第一个满配的先不说

后两个肯定比不上隔壁贴2000块的垃圾佬拼装版本吧？

*****

####  Sunyalche  
##### 9#       发表于 2025-2-18 16:25

满血版1911 token/s，300万以上吗

要是能有百分之一速度和百分之一价格，面向个人消费者的就好了

*****

####  Realplayer  
##### 10#       发表于 2025-2-18 16:29

70b以下也去卖，有什么必要吗

什么都划拉是吧

*****

####  الطائر  
##### 11#       发表于 2025-2-18 16:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458285&amp;ptid=2246645" target="_blank">Sunyalche 发表于 2025-2-18 16:25</a>

满血版1911 token/s，300万以上吗

要是能有百分之一速度和百分之一价格，面向个人消费者的就好了 ...</blockquote>
企业、学校、机关本地部署一台，给100个人用，不就是这个效果吗？

*****

####  qratosones1337  
##### 12#       发表于 2025-2-18 16:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458327&amp;ptid=2246645" target="_blank">Realplayer 发表于 2025-2-18 16:29</a>

70b以下也去卖，有什么必要吗

什么都划拉是吧</blockquote>
两台服务器变一台呗

*****

####  泰坦失足  
##### 13#       发表于 2025-2-18 16:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458189&amp;ptid=2246645" target="_blank">a4ac7 发表于 2025-2-18 16:16</a>

新闻是有了，就是购买链接还没找到

主要是看下面英伟达的对比样机说3000美元的，有点想法</blockquote>
比较香, 虽然天生的tensor core较少导致推理速度慢. 但是别的解决方案都涉及到显存内存交换数据, 只有小黑盒是统一内存.理论上两个Project DIGITS合并到256GB就能跑量化到2bits的R1 671了 [https://unsloth.ai/blog/deepseekr1-dynamic](https://unsloth.ai/blog/deepseekr1-dynamic), 还有剩余越70G到90G的统一内存空间给长上下文用. 老黄看了拍断腿说早知道有R1这种超大显存需求,就不当场公布价格了. 

*****

####  秦南心  
##### 14#       发表于 2025-2-18 16:36

现在性价比还是烂，期待国内芯片技术上去，能把单人使用价格打到中高端手机售价

*****

####  洛拉斯  
##### 15#       发表于 2025-2-18 16:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458375&amp;ptid=2246645" target="_blank">秦南心 发表于 2025-2-18 16:36</a>
现在性价比还是烂，期待国内芯片技术上去，能把单人使用价格打到中高端手机售价 ...</blockquote>
个人部署的话真不如租云算力

*****

####  UNICORN00  
##### 16#       发表于 2025-2-18 16:38

哪里看的价格啊？

*****

####  tylunas  
##### 17#       发表于 2025-2-18 16:40

 本帖最后由 tylunas 于 2025-2-18 17:01 编辑 

一台Atlas 800 A2包含8张910B，前两天群友公司得到的报价是价格200W。两台之间应该是用InfiniBand连接的。估计价格450万往上了。再加上全固态存储更不止(两机共32T SSD，其实可以不买)。

亲民的方案大佬还在开发中，一块3090+512G DDR4内存就能流畅运行满血版R1了。

【满血DeepSeek V3 ，国产cpu低成本流畅运行-哔哩哔哩】 https://b23.tv/bV1OhB8

*****

####  qwased  
##### 18#       发表于 2025-2-18 16:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458357&amp;ptid=2246645" target="_blank">泰坦失足 发表于 2025-2-18 16:33</a>
比较香, 虽然天生的tensor core较少导致推理速度慢. 但是别的解决方案都涉及到显存内存交换数据, 只有小 ...</blockquote>
你是不是把苹果给忘了，价格不可能比苹果贵的

*****

####  百猪夜行  
##### 19#       发表于 2025-2-18 16:44

70b及以下模型有个96g内存的家用PC都能跑的很好，就算是企业用x86服务器也不会很贵，没必要花大钱买专用硬件。

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  qratosones1337  
##### 20#       发表于 2025-2-18 16:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458375&amp;ptid=2246645" target="_blank">秦南心 发表于 2025-2-18 16:36</a>

现在性价比还是烂，期待国内芯片技术上去，能把单人使用价格打到中高端手机售价 ...</blockquote>
这个还是别做梦了，看看API托管吧

*****

####  随机抽查  
##### 21#       发表于 2025-2-18 16:45

能不能把显存做成ssd插拔可替换模式

*****

####  qratosones1337  
##### 22#       发表于 2025-2-18 16:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458465&amp;ptid=2246645" target="_blank">百猪夜行 发表于 2025-2-18 16:44</a>

70b及以下模型有个96g内存的家用PC都能跑的很好，就算是企业用x86服务器也不会很贵，没必要花大钱买专用硬 ...</blockquote>
今后MoE模型推理会两极分化——你说的这种是KTransformers方案，基本上没有并发能力，企业不可能给每个人都配上几万块钱的设备

*****

####  a4ac7  
##### 23#       发表于 2025-2-18 16:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458397&amp;ptid=2246645" target="_blank">洛拉斯 发表于 2025-2-18 16:38</a>
个人部署的话真不如租云算力</blockquote>
云算力这价格是给个人的吗，比如华为云p2s每个月租金1万6左右，两张V100的机器，还只能搞32b的推理的

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  Realplayer  
##### 24#       发表于 2025-2-18 16:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458484&amp;ptid=2246645" target="_blank">qratosones1337 发表于 2025-2-18 16:46</a>

今后MoE模型推理会两极分化——你说的这种是KTransformers方案，基本上没有并发能力，企业不可能给每个人 ...</blockquote>
家用不提，四卡双路线程的4U就能跑

甚至有新闻说单卡24G+480RAM能跑完整的模型

菊花这么搞怕不是在硬件名字前面加上吃鸡二字

再者说了，你都Local跑70B了还要什么并发

*****

####  hentai烧酒  
##### 25#       发表于 2025-2-18 16:50

前几年因项目需要，研发环境逐步切换到ARM架构机器上，首选当然是华为的，然而实在是太贵了，公司舍不得大面积更换，只采购2台作为编译环境。

当时公司的很多机器都是i7-9700、i5-9400、 i5-10400 ，32G，500G或1T SSD采购价才4000~5000（DIY当然更便宜，这个另说）。这样的机器在开个几个虚拟机，能部署分布式集群。

华为的ARM机器配置是单CPU 4核，32G内存，500G SSD，一万多块，夸张点就是一台华为机器可以买2台性能更好的X86机器。

当然国产化替代无可避免，尤其是政府项目，不仅是硬件，后续操作系统也从centos切换到麒麟、openeuler等国产操作系统。

但是这种价格差距足以让“非必要”的项目重新思考。

*****

####  logiccat  
##### 26#       发表于 2025-2-18 16:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458397&amp;ptid=2246645" target="_blank">洛拉斯 发表于 2025-2-18 16:38</a>

个人部署的话真不如租云算力</blockquote>
那要求隐私呢？总不能啥都上网吧……

*****

####  macrosszhao  
##### 27#       发表于 2025-2-18 17:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458397&amp;ptid=2246645" target="_blank">洛拉斯 发表于 2025-2-18 16:38</a>

个人部署的话真不如租云算力</blockquote>
租用云算力是不是不能搞瑟瑟,这生产力得不到解放

*****

####  FeteFete  
##### 28#       发表于 2025-2-18 17:03

老黄也有类似的机器，有点事带宽很高

搞cpu gpu的offload很好用

*****

####  alixsander  
##### 29#       发表于 2025-2-18 17:04

<blockquote>一骑当千 发表于 2025-2-18 16:15
虽然知道买不起，但还是好奇价格是多少？</blockquote>
910B* 20万一张吧，2机16卡你算算

*****

####  qratosones1337  
##### 30#       发表于 2025-2-18 17:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458527&amp;ptid=2246645" target="_blank">Realplayer 发表于 2025-2-18 16:49</a>

家用不提，四卡双路线程的4U就能跑

甚至有新闻说单卡24G+480RAM能跑完整的模型

菊花这么搞怕不是在硬件名 ...</blockquote>
8卡910B跑LLama70B级模型，上百并发每秒几千Token还不是轻轻松松

*****

####  万恶淫猥手  
##### 31#       发表于 2025-2-18 17:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458285&amp;ptid=2246645" target="_blank">Sunyalche 发表于 2025-2-18 16:25</a>
满血版1911 token/s，300万以上吗

要是能有百分之一速度和百分之一价格，面向个人消费者的就好了 ...</blockquote>
个人用户也没必要满血版吧，一般 70b 就够了

*****

####  qratosones1337  
##### 32#       发表于 2025-2-18 17:10

 本帖最后由 qratosones1337 于 2025-2-18 17:12 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458527&amp;ptid=2246645" target="_blank">Realplayer 发表于 2025-2-18 16:49</a>

家用不提，四卡双路线程的4U就能跑

甚至有新闻说单卡24G+480RAM能跑完整的模型

菊花这么搞怕不是在硬件名 ...</blockquote>
你提到的那个新闻指的是KTransformers方案，所谓“完整的模型”指的是Q4量化的模型，完全不可并发且Decode勉强能跑到7t/s的下限速度。华为这边要是一样用量化模型的话四张Atlas300I Duo就能跑，一张三万块钱，而且推理速度比你说的KTransformers方案快很多。

*****

####  处男老司机  
##### 33#       发表于 2025-2-18 17:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458416&amp;ptid=2246645" target="_blank">tylunas 发表于 2025-2-18 16:40</a>

一台Atlas 800 A2包含8张910B，前两天群友公司得到的报价是价格200W。两台之间应该是用InfiniBand连接的。 ...</blockquote>
512G内存哪里亲民了<img src="https://static.saraba1st.com/image/smiley/face2017/003.png" referrerpolicy="no-referrer">

*****

####  qratosones1337  
##### 34#       发表于 2025-2-18 17:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458680&amp;ptid=2246645" target="_blank">alixsander 发表于 2025-2-18 17:04</a>

910B* 20万一张吧，2机16卡你算算</blockquote>
没那么贵，24年Q2的报价，某互联网大厂采购的x86底座16卡910B整机才170W

*****

####  Realplayer  
##### 35#       发表于 2025-2-18 17:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458728&amp;ptid=2246645" target="_blank">qratosones1337 发表于 2025-2-18 17:10</a>

你提到的那个新闻指的是KTransformers方案，所谓“完整的模型”指的是Q4量化的模型，完全不可并发且Decode ...</blockquote>
跑70B够了

没必要花那个冤枉钱

*****

####  qratosones1337  
##### 36#       发表于 2025-2-18 17:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458756&amp;ptid=2246645" target="_blank">Realplayer 发表于 2025-2-18 17:13</a>

跑70B够了</blockquote>
跑70B本来也不用你说的那套东西啊，四张4090开vllm就勉强够了，而且速度还挺快

*****

####  Realplayer  
##### 37#       发表于 2025-2-18 17:14

 本帖最后由 Realplayer 于 2025-2-18 17:16 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458760&amp;ptid=2246645" target="_blank">qratosones1337 发表于 2025-2-18 17:13</a>

跑70B本来也不用你说的那套东西啊，四张4090开vllm就勉强够了，而且速度还挺快 ...</blockquote>
那你说说菊花卖的单路什么配置什么价格

PS:而且我说的是单卡跑满血，直接ollama可能还不够

菊花这些1.5~70B的到底准备卖给谁

*****

####  alixsander  
##### 38#       发表于 2025-2-18 17:16

<blockquote>qratosones1337 发表于 2025-2-18 17:11
没那么贵，24年Q2的报价，某互联网大厂采购的x86底座16卡910B整机才170W</blockquote>
B1-4有区别，要看某厂买的是啥

还有16卡 应该当前跑的是int8量化的（量化流程见昇腾社区FP8-&gt;BF16-&gt;INT8）

*****

####  tylunas  
##### 39#       发表于 2025-2-18 17:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458730&amp;ptid=2246645" target="_blank">处男老司机 发表于 2025-2-18 17:10</a>
512G内存哪里亲民了</blockquote>
洋垃圾DDR4 32G*16，大船货马上还会来一堆。

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  qratosones1337  
##### 40#       发表于 2025-2-18 17:31

 本帖最后由 qratosones1337 于 2025-2-18 17:34 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458797&amp;ptid=2246645" target="_blank">alixsander 发表于 2025-2-18 17:16</a>

B1-4有区别，要看某厂买的是啥

还有16卡 应该当前跑的是int8量化的（量化流程见昇腾社区FP8-&gt;BF16-&gt;INT8 ...</blockquote>
推理用的Atlas800I便宜多了，这里说的16卡机器指的是训练卡（好像是B2）


*****

####  qratosones1337  
##### 41#       发表于 2025-2-18 17:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458772&amp;ptid=2246645" target="_blank">Realplayer 发表于 2025-2-18 17:14</a>

那你说说菊花卖的单路什么配置什么价格

PS:而且我说的是单卡跑满血，直接ollama可能还不够

菊花这些1.5~70 ...</blockquote>
正经商用服务谁用ollama啊，起码vllm起步，菊花这边对标的是MindIE。卡和显存数量越多，能支持的并发batch和context长度就越大，vllm如果要支持长上下文的话显存有多少吃多少

*****

####  yorktown  
##### 42#       发表于 2025-2-18 17:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458483&amp;ptid=2246645" target="_blank">随机抽查 发表于 2025-2-18 16:45</a>
能不能把显存做成ssd插拔可替换模式</blockquote>
amd之前不有个能插m.2 ssd当缓存的

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha


*****

####  小牛无大将  
##### 43#       发表于 2025-2-18 17:42

从来没想过fusion cube可以用来干这个…
对前部门大利好啊…

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  lyzsuper  
##### 44#       发表于 2025-2-18 17:49

请教一下大家，这些卡/机互联的话是不是得用光模块？ 谢谢


*****

####  tylunas  
##### 45#       发表于 2025-2-18 17:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458982&amp;ptid=2246645" target="_blank">qratosones1337 发表于 2025-2-18 17:31</a>
推理用的Atlas800I便宜多了，这里说的16卡机器指的是训练卡（好像是B2）</blockquote>
装下671B模型，用的应该是64G版本的910B3/B4，双机1TB。
看配置文件，好像B1是特挑体质的高频版，B2正常主频，B3是阉割1/6单元的版本，B4阉割加降频。

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha


*****

####  琉璃苑軒風  
##### 46#       发表于 2025-2-18 18:01

32B你哪怕其他都不改，atx板子插一张4060ti 16g 一张8g 20系往后的老卡，就够，根本不在意你的内存和cpu

以当下溢价，4060ti 16g算4000，2060s一张1000块，两者加一起5000块，完了

*****

####  希德尼娅  
##### 47#       发表于 2025-2-18 18:01

太贵了吧，不是说30w就能部署一台全血r1吗


*****

####  alixsander  
##### 48#       发表于 2025-2-18 18:10

<blockquote>qratosones1337 发表于 2025-2-18 17:31
推理用的Atlas800I便宜多了，这里说的16卡机器指的是训练卡（好像是B2）</blockquote>
这个我听说800T可不是这价啊，单卡80万？


*****

####  jeokeo  
##### 49#       发表于 2025-2-19 08:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458397&amp;ptid=2246645" target="_blank">洛拉斯 发表于 2025-2-18 16:38</a>
个人部署的话真不如租云算力</blockquote>
云上限制太多了


*****

####  大韩李明博  
##### 50#       发表于 2025-2-19 08:30

比8卡H100的机子还贵。


*****

####  鸳鸳相抱  
##### 51#       发表于 2025-2-19 09:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67458527&amp;ptid=2246645" target="_blank">Realplayer 发表于 2025-2-18 16:49</a>
家用不提，四卡双路线程的4U就能跑

甚至有新闻说单卡24G+480RAM能跑完整的模型

菊花这么搞怕不是在硬件名 ...</blockquote>
国内单位，为了免责，不连外网要跑local的不要太多


*****

####  qratosones1337  
##### 52#       发表于 2025-2-19 09:33

 本帖最后由 qratosones1337 于 2025-2-19 09:36 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67459395&amp;ptid=2246645" target="_blank">alixsander 发表于 2025-2-18 18:10</a>

这个我听说800T可不是这价啊，单卡80万？</blockquote>
你疯了吧，H20一台八卡整机没涨价之前也就100W，你单卡80W想卖给谁啊？

另外互联网大厂采购的是超聚变的服务器，单机16卡，Intel SPR底座

