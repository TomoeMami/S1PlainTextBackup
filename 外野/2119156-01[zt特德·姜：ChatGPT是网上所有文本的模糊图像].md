
*****

####  rough008  
##### 1#       楼主       发表于 2023-2-11 23:49

[https://www.thepaper.cn/newsDetail_forward_21877769](https://www.thepaper.cn/newsDetail_forward_21877769)

2013年，德国一家建筑公司的工人注意到他们的施乐复印机有一些奇怪的地方：当他们复印一张房子平面图时，副本与原件之间存在微妙而显着的差异。在最初的平面图中，每栋房子的三个房间都有一个矩形来说明其面积：房间分别为14.13平方米，21.11平方米和17.42平方米。然而，在复印件中，所有三个房间都被标记为14.13平方米。该公司联系了计算机科学家大卫·克里塞尔（David Kriesel），让他对这一看似不可思议的结果进行调查。他们需要一名计算机科学家，因为现代施乐复印机使用的不是20世纪60年代流行的物理静电复印工艺。相反，它以数字方式扫描文档，然后打印生成的图像文件。结合这一事实，为了节省空间，几乎每个数字图像文件都经过了压缩。谜底开始浮出水面。

压缩文件需要两个步骤：首先是编码，在此期间文件被转换为更紧凑的格式；然后是解码，将编码的过程反向进行。如果恢复的文件与原始文件相同，则压缩过程被描述为无损，即没有丢失信息。相比之下，如果恢复的文件只是原始文件的近似值，则压缩被描述为有损，即一些信息已丢失而无法恢复。无损压缩通常用于文本文件和计算机程序，因为在这些领域中，即使是一个错误的字符也有可能造成灾难性的后果。在绝对精度不重要的情况下，有损压缩通常用于照片、音频和视频。大多数时候，我们不会注意到一张图片、一首歌或电影是否被完美地复制。只有当文件被压缩得非常紧时，保真度的损失才会更加明显。在这些情况下，我们会注意到所谓的压缩伪影——最小的JPEG和MPEG图像的模糊，或者低比特率MP3的微弱声音。

施乐复印机使用一种被称为jbig2的有损压缩格式，专为黑白图像而设计。为了节省空间，复印机会识别图像中看起来相似的区域，并为所有这些区域存储一份副本；当文件被解压时，它会重复使用该副本来重建映像。结果是，复印机判断出指定房间面积的标签非常相似，所以它只需要存储其中一个，即14.13平方米的房间，并且在打印楼层平面图时，它对所有三个房间都重复使用这一个标签。

施乐复印机使用有损压缩格式而不是无损格式，这本身并不是一个问题。问题是复印机以一种微妙的方式压缩了图像，使其中压缩的伪影不能被立即识别出来。如果复印机只是打印出模糊的照片，每个人都会知道这不是原件的准确复制品。导致问题的原因是复印机输出的数字是可读的，但不准确——它使副本看起来准确，但实际上并不准确。（2014年，施乐发布了一个补丁来纠正这个问题。）

我认为，在我们研究OpenAI的ChatGPT和其他类似程序（人工智能研究人员称之为大语言模型）时，施乐复印机的这起事件值得我们铭记于心。复印机和大语言模型之间的相似之处可能不是很明显，但请考虑以下场景：想象一下，你即将永远失去上网的机会。在准备阶段，你计划为万维网上的所有文本创建一个压缩副本，以便将其存储在专用服务器上。不幸的是，你的私人服务器只有所需空间的1%；如果你想要所有的一切都是准确的，你就不能使用无损压缩算法。相反，你可以编写一个有损算法来识别文本中的统计规律，并将它们存储在专门的文件格式中。由于你在这个任务中拥有几乎无限的计算能力，因此你的算法可以识别非常细微的统计规律，这允许你实现所需的100:1的压缩比。

于是，失去网络连接不再那么可怕，因为你把网络上的所有信息都存储在了你的服务器上。唯一的问题是，由于文本被高度压缩，你无法通过搜索准确的引用来查找信息；你永远不会得到一个精确的匹配，因为存储的不是单词。为了解决这个问题，你创建了一个接口，该接口接受问题形式的查询，并以传达服务器上的要点的答案进行响应。

我所描述的听起来很像ChatGPT，或者大多数其他大语言模型。可以把ChatGPT看作是万维网上所有文本的模糊JPEG。它保留了万维网上的大部分信息，就像JPEG保留了高分辨率图像的大部分信息一样。但是，如果你要寻找精确的比特序列，你无法找到它，你得到的只是一个近似值。但是，因为这个近似值是以语法文本的形式呈现的，而ChatGPT擅长创建语法文本，所以它通常是可以接受的。你看到的仍然是一张模糊的JPEG，但模糊发生的方式不会使图片整体看起来不那么清晰。

这种与有损压缩的类比不仅仅是一种理解ChatGPT通过使用不同的单词重新打包万维网上找到的信息的方法，它也是一种理解“幻觉”或对事实性问题的无意义回答的方法。而大语言模型（如ChatGPT）都很容易出现这种情况。这些幻觉是压缩后的产物。但是，就像施乐复印机产生的错误标签一样，它们似乎是可信的，要识别它们就需要将它们与原件进行比较。在这种情况下，这意味着要么是万维网，要么是我们自己对世界的认识。当我们这样想的时候，这样的幻觉一点也不令人惊讶。如果一种压缩算法被设计成在99%的原始文本被丢弃后重建文本，我们应该预料到它生成的很大一部分内容将完全是捏造的。

当我们记得有损压缩算法使用的一种常用技术是插值（译者注：一种通过已知的、离散的数据点，在范围内推求新数据点的过程或方法）时，这个类比就更有意义了——也就是说，通过查看间隙两侧的内容来估计缺失的内容。当图像程序显示照片时，必须重建压缩过程中丢失的像素时，它会查看附近的像素并计算平均值。这就是当ChatGPT被提示用《独立宣言》的风格描述丢在烘干机里的袜子时所做的事情：它在“词汇空间”中取两个点，并生成占据它们之间位置的文本。（“在人类事件的过程中，一个人有必要把他的衣服与他们的同伴分开，以保持其清洁和秩序……”）ChatGPT非常擅长这种形式的插值，人们发现它很有趣：他们发现了一种用于段落而不是照片的“模糊”工具，并且玩得很开心。

鉴于像ChatGPT这样的大语言模型经常被吹捧为人工智能的前沿，将它们描述为有损文本压缩算法可能听起来令人不屑一顾，或者至少令人泄气。我确实认为这种观点为将大语言模型人格化的趋势提供了有用的纠正，但是压缩类比还有另一个方面值得考虑。自2006年以来，一位名叫马库斯·赫特（Marcus Hutter）的人工智能研究人员提供了一项现金奖励——被称为“压缩人类知识奖”或“赫特奖”，奖励任何能够无损地压缩**特定1GB快照的人，要求比上一位获奖者的数据更小。你可能遇到过使zip文件格式压缩的文件。zip格式将赫特的1GB文件压缩到300兆左右；而最近的获奖者已经设法将其减少到115兆字节。这不仅仅是一次磨合练习。赫特认为，更好的文本压缩将有助于创造人类级别的人工智能，部分原因是通过理解文本可以实现最大程度的压缩。

为了理解压缩和理解之间的关系，假设你有一个文本文件，其中包含上百万个加减乘除的示例。尽管任何压缩算法都可以减小这个文件的大小，但要实现最大的压缩比，可能需要推导出算术原理，然后编写计算器程序的代码。使用计算器，你不仅可以完美地重建文件中的数百万个示例，还可以重建将来可能遇到的任何其他算术示例。同样的逻辑也适用于压缩**的一部分。如果压缩程序知道力等于质量乘以加速度，那么在压缩有关物理的页面时，它可以丢弃大量的单词，因为它能够重建它们。同样，程序对供求关系了解得越多，在压缩有关经济的页面时，就能丢弃越多的单词，等等。

大型语言模型识别文本中的统计规律。对网络文本的任何分析都会揭示，像“供应不足”这样的短语经常出现在“价格上涨”这样的短语附近。当被问及有关供应短缺影响的问题时，包含这种相关性的聊天机器人可能会回答有关价格上涨的问题。如果一个大语言模型已经编译了大量经济术语之间的相关性——多到可以对各种各样的问题提供合理的回答——我们是否应该说它实际上理解了经济理论？像ChatGPT这样的模型没有资格获得赫特奖，原因有很多，其中之一就是它们不能精确地重建原始文本，也就是说它们不执行无损压缩。但是，它们的有损压缩是否可能表明，人工智能研究人员真正理解了他们感兴趣的那种类型？

让我们回到算术的例子。如果你要求GPT-3（ChatGPT构建的大语言模型）添加或减去一对数字，当数字只有两位数时，它几乎总是会给出正确的答案。但数字越大，准确率就会显着下降，当数字有五位数时，准确率会下降到10%。GPT-3给出的大多数正确答案都不能在网上找到——例如，包含“245 + 821”文本的网页并不多——所以它不是在进行简单的记忆。但是，尽管吸收了大量的信息，它也无法推导出算术原理。仔细检查GPT-3的错误答案表明，它在执行算术时不带“1”。万维网上当然包含携带“1”的解释，但是GPT-3不能包含这些解释。GPT-3对算术例子的统计分析使它能够产生与真实事物的表面近似，但仅此而已。

鉴于GPT-3在小学教学科目上的失败，我们如何解释它有时在写大学水平的论文时表现良好的事实？尽管大语言模型经常产生幻觉，但当它们清醒时，它们好像真的能理解经济理论等学科。也许算术是一个特殊的情况，大语言模型不太适合。有没有可能，在加减法之外的领域，文本中的统计规律确实与真实世界的真实知识相对应？

我认为有一个更简单的解释。想象一下，如果ChatGPT是一种无损算法会是什么样子。如果是这样的话，它总是通过提供来自相关网页的逐字引用来回答问题。我们可能会认为这个软件只是对传统搜索引擎的轻微改进，并对它印象不太深刻。ChatGPT从网络上重新表达材料，而不是逐字引用，这让它看起来像一个学生用自己的话表达思想，而不是简单地重复他读过的东西。它会造成ChatGPT理解了材料的错觉。在人类学生中，死记硬背并不是真正学习的标志，因此ChatGPT无法从网页中准确地引用内容，这恰恰使我们认为它学到了一些东西。当我们处理单词序列时，有损压缩看起来比无损压缩更聪明。

大语言模型已经有了很多种用法。把它们看作是模糊的JPEG文件，这就提供了一种评估它们可能适合或不适合的方法。让我们思考几种情况。

大语言模型能取代传统搜索引擎吗？为了让我们对它们有信心，我们需要知道他们有没有被灌输政治宣传和阴谋论——我们需要知道JPEG是否捕捉了正确的网络区域。但是，即使大语言模型只包含我们想要的信息，仍然存在模糊性的问题。有一种模糊是可以接受的，那就是用不同的词重新陈述信息；对于完全捏造的模糊，当我们寻找事实时，我们认为这是不可接受的。在消除不可接受的模糊性的同时，保留可接受的模糊性，在技术上是否可行尚不清楚，但我希望在不久的将来，我们能找到答案。

即使有可能限制大语言模型参与制作，我们应该使用它们来生成万维网内容吗？只有当我们的目标是重新打包网络上已有的信息时，这才有意义。有些公司就是这么做的，我们通常称它们为内容工厂。也许大语言模型的模糊性对他们来说是有用的，它可以作为一种避免侵犯版权的手段。不过，一般来说，我想说的是，任何对内容工厂有好处的东西都不适合搜索信息的人。这种重新包装的兴起使我们现在更难在网上找到我们想要的东西。大型语言模型生成的文本在网络上发布得越多，网络本身就变得越模糊。

关于OpenAI即将推出的ChatGPT继任者GPT-4的信息非常少。但是我想做一个预测：当收集用于训练GPT-4的大量文本时，OpenAI会尽一切努力排除由ChatGPT或任何其他大语言模型生成的材料。若事实果真如此，那么将大语言模型与有损压缩进行类比是有用的。反复保存JPEG会产生更多的压缩制件，因为每次都会丢失更多的信息。这就相当于过去不断复制副本的做法，图像质量只会越来越差。

事实上，衡量大语言模型质量的一个有用标准可能是，公司是否愿意使用它生成的文本作为新模型的训练材料。如果ChatGPT的输出对GPT-4来说不够好，我们或许会认为它对我们来说也不够好。相反，如果一个模型生成的文本非常好，可以用来训练新的模型，那么我们应该对文本的质量有信心。（我怀疑这样的结果需要在用于构建这些模型的技术上取得重大突破。）如果我们开始看到模型产生的输出和输入一样好，那么有损压缩的类比将不再适用。

大语言模型能帮助人类创作原创作品吗？要回答这个问题，我们需要明确这个问题的含义。有一种艺术类型被称为影印艺术，在这种艺术中，艺术家们利用复印机的独特特性作为创作工具。在ChatGPT复印机上，沿着这些路线的事情肯定是可能的，所以，在这个意义上，答案是肯定的。但我认为没有人会说，复印机已经成为艺术创作中的必备工具。绝大多数艺术家在创作过程中不会使用它们，没人会认为他们的这种选择会让自己处于不利地位。

所以让我们假设，我们并不是在谈论一种类似于“施乐艺术”的新的写作类型。鉴于这一规定，大语言模型生成的文本能否成为作家在创作原创作品时有用的起点，无论是小说还是非虚构？让一个大语言模型来处理样板文件，能让作者把注意力集中在真正有创意的部分吗？

显然，没有人能代表所有的作家，但我想说的是，以一份模糊的非原创作品作为起点，并不是创作原创作品的好办法。如果你是一个作家，在你写原创作品之前，你会写很多非原创的作品。花在非原创工作上的时间和精力不会被浪费。相反，我认为正是它让你最终能够创作出原创的作品。花在选择正确的词汇和重新排列句子以更好地遵循彼此上的时间，教会了你如何通过文章传达想要表达的意思。让学生写论文不仅仅是一种测试他们对材料掌握程度的方法，这给了他们表达自己想法的经验。如果学生从来不用写我们都读过的文章，他们就永远不会获得写我们从未读过的东西所需的技能。

这并不是说，一旦你不再是学生，你就可以安全地使用大语言模型提供的模板。想要表达自己想法的挣扎并不会在你毕业后消失。每当你开始起草一篇新文章时，这种挣扎就会出现。有时候，只有在写作的过程中，你才能发现自己最初的想法。有些人可能会说，大语言模型的输出看起来与人类作家的初稿没有太大不同，但是，我认为这只是表面上的相似。你的初稿不是一个明确表达的非原创想法；这是一个原始想法的拙劣表达，它伴随着你无定形的不满，你意识到它所说的和你想说的之间的距离。这是在重写时能够指导你的东西，这是当你开始使用人工智能生成的文本时所缺乏的东西之一。

写作没什么神奇或神秘的，但它不仅仅是把现有的文件放在一台不可靠的复印机上，然后按下打印按钮。在未来，我们有可能创造出一个人工智能，它能够仅凭自己对世界的经验就写出好文章。我们实现这一目标的那一天确实意义重大，但那一天远远超出了我们的预测范围。与此同时，我们有理由提出这样一个问题：重新表述万维网有何用途？如果我们永远无法访问互联网，不得不在空间有限的私人服务器上存储副本，那么像ChatGPT这样的大语言模型可能是一个很好的解决方案，假设它可以防止伪造。但我们并没有失去对互联网的访问。那么，当你还有原始图片的时候，一张模糊的JPEG到底有多大用处呢？

﹍﹍﹍

评分

 参与人数 8战斗力 +9

|昵称|战斗力|理由|
|----|---|---|
| GOESD| + 1|好评加鹅|
| 瑟尼欧利斯| + 1|好评加鹅|
| Belisarius| + 1|好评加鹅|
| wfm| + 2|好文|
| kingtigerc| + 1|好评加鹅|
| Rintani_Yahato| + 1|好评加鹅|
| ddddxxx| + 1|好评加鹅|
| 毒菇| + 1|好评加鹅|

查看全部评分

*****

####  rough008  
##### 2#         楼主| 发表于 2023-2-11 23:52

我觉得是很有意义的观点，总结：chatgpt只是模仿人类说话，这种模仿让人类觉得像是智能，但是chatgpt并没有真的理解，所以离真正的智能还有差距

*****

####  rough008  
##### 3#         楼主| 发表于 2023-2-11 23:53

 本帖最后由 rough008 于 2023-2-12 00:19 编辑 

编辑

*****

####  毒菇  
##### 4#       发表于 2023-2-11 23:56

还是文学工作者写出来好懂<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">说起来我第一印象觉得他姓蒋来着，可能因为老蒋也算幻想文学作家吧（指日记）

*****

####  哈扎马  
##### 5#       发表于 2023-2-11 23:56

 本帖最后由 哈扎马 于 2023-2-12 00:50 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708223&amp;ptid=2119156" target="_blank">rough008 发表于 2023-2-11 23:53</a>

另外提一句，这篇文章本身是deepl翻译的</blockquote>
编辑，原来是真人<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">我的文品还是太拉了，看不出ai和人的错误区别

*****

####  PlasmaSnake  
##### 6#       发表于 2023-2-12 00:01

确实，昨天试了一下，写小作文可以，但检索信息的深度还是不够，特别是工作相关的专业领域，有些随便一百度都能找到的东西他却答不上来。

*****

####  thebella  
##### 7#       发表于 2023-2-12 00:01

<blockquote>rough008 发表于 2023-2-11 23:53
另外提一句，这篇文章本身是deepl翻译的</blockquote>
惊！完全没发现

*****

####  sqlist  
##### 8#       发表于 2023-2-12 00:04

前半段看着像是在说降维

*****

####  thebella  
##### 9#       发表于 2023-2-12 00:04

<blockquote>rough008 发表于 2023-2-11 23:53
另外提一句，这篇文章本身是deepl翻译的</blockquote>
看了原网页，不是写着“澎湃新闻记者 程千千 译”吗？

*****

####  帕林马哲理  
##### 10#       发表于 2023-2-12 00:06

我这样的外行也能看懂，果然科幻作家才是最适合科普的<img src="https://static.saraba1st.com/image/smiley/face2017/177.png" referrerpolicy="no-referrer">

*****

####  allegray  
##### 11#       发表于 2023-2-12 00:07

之前stable diffusion的宣传也是"compresses the visual information of humanity into a few gigabytes"

*****

####  rough008  
##### 12#         楼主| 发表于 2023-2-12 00:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708356&amp;ptid=2119156" target="_blank">thebella 发表于 2023-2-12 00:04</a>

看了原网页，不是写着“澎湃新闻记者 程千千 译”吗？</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/105.png" referrerpolicy="no-referrer">不会吧，我是在别处看完文章搜题目出来的网址，那边有标注是deepl翻译，其实没看这边有没有变化，我再去比较一下

*****

####  moonmagian  
##### 13#       发表于 2023-2-12 00:17

可是现在的GPT确实用了InstructGPT来自己生成数据喂给自己啊<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

—— 来自 Sony XQ-BT52, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  rough008  
##### 14#         楼主| 发表于 2023-2-12 00:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708356&amp;ptid=2119156" target="_blank">thebella 发表于 2023-2-12 00:04</a>

看了原网页，不是写着“澎湃新闻记者 程千千 译”吗？</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/107.png" referrerpolicy="no-referrer">破案了，确实这篇是人工，至少润色过

*****

####  naclken.  
##### 15#       发表于 2023-2-12 00:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708205&amp;ptid=2119156" target="_blank">rough008 发表于 2023-2-11 23:52</a>

我觉得是很有意义的观点，总结：chatgpt只是模仿人类说话，这种模仿让人类觉得像是智能，但是chatgpt并没有 ...</blockquote>
chatgpt可以说是有智能

但是它并不了解语义，炼图AI同理

AI了解语义之后可以取代很多很多的人……

*****

####  rough008  
##### 16#         楼主| 发表于 2023-2-12 00:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708540&amp;ptid=2119156" target="_blank">naclken. 发表于 2023-2-12 00:19</a>

chatgpt可以说是有智能

但是它并不了解语义，炼图AI同理

AI了解语义之后可以取代很多很多的人…… ...</blockquote>
了解语义的话人类就能真的从工作里解脱吧，即使现在这些小编体也解脱了很多人，至于被解放的人失业在家没有收入，我觉得是管理者和资本家的问题

*****

####  93子  
##### 17#       发表于 2023-2-12 00:28

GPT本身就是经验主义的产物。超级熟能生巧的匠人而非逻辑严密的工程师。情况大概就类似公知嘴里的封建时期的中国和中医，知其然不知其所以然，没有系统化的知识积累。解决一些问题是可以的，甚至很快的。

*****

####  lvseqiji  
##### 18#       发表于 2023-2-12 00:41

无论是最强的ai还是最搓的ai都是基于统计数据的拟合函数。只要这个基本属性没变，强AI是不太可能实现。在这里我们其实可以看到ai反而最不擅长的就是理性思维。因为人的理性显然不需要历史经验来运行。

*****

####  夜空疾走  
##### 19#       发表于 2023-2-12 00:53

如果早二十年让奈须蘑菇这样的人描述AI，可能会出现什么赛博之神

*****

####  燕山雪  
##### 20#       发表于 2023-2-12 01:02

很好的角度，但从AI技术的角度看，chatGPT最惊人的还不是它满嘴跑火车的本事，而是它理解自然语言并把上下文联系起来的能力，而这点恰恰是单纯的压缩程序做不到的。另外，希尔顿中文屋的悖论依然存在：如果一个模型能够通过最严格的图灵测试，而你只因为了解它的运作机制就认为“它显然没有真正的智能”，这真的合理么？

另外“压缩程序不能创造新内容”的说法实际上也很可疑，stable diffusion decoding的核心算法就是基于对隐变量的去噪实现，隐变量本质上是一种压缩，图像生成也就是一个解压的过程。说“stable diffusion不能创造新内容”，想必很多人不会同意。

*****

####  pyx  
##### 21#       发表于 2023-2-12 01:06

仍然还是一个概率模型吧

*****

####  rryu  
##### 22#       发表于 2023-2-12 01:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708205&amp;ptid=2119156" target="_blank">rough008 发表于 2023-2-11 23:52</a>

我觉得是很有意义的观点，总结：chatgpt只是模仿人类说话，这种模仿让人类觉得像是智能，但是chatgpt并没有 ...</blockquote>
那么问题来了，洗稿的自媒体工作者算不算有智能<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  الطائر  
##### 23#       发表于 2023-2-12 01:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708896&amp;ptid=2119156" target="_blank">燕山雪 发表于 2023-2-12 01:02</a>

很好的角度，但从AI技术的角度看，chatGPT最惊人的还不是它满嘴跑火车的本事，而是它理解自然语言并把上下 ...</blockquote>
原文认为“压缩程序能创造新内容”，建议你再读几遍。

*****

####  lefteyelisa  
##### 24#       发表于 2023-2-12 01:14

特德姜还是比大刘硬核得多

----发送自 [OnePlus IN2010,Android 12](http://stage1.5j4m.com/?1.37)

*****

####  martinium  
##### 25#       发表于 2023-2-12 01:15

绝大部分写作就是复读啊，用这个生成周报之类的不是挺好的，节约时间

*****

####  燕山雪  
##### 26#       发表于 2023-2-12 01:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708950&amp;ptid=2119156" target="_blank">الطائر 发表于 2023-2-12 01:11</a>

原文认为“压缩程序能创造新内容”，建议你再读几遍。</blockquote>
如果你觉得“有损压缩解压时出现误差”等同于“创造新内容”，那么你说得对<img src="https://static.saraba1st.com/image/smiley/face2017/026.png" referrerpolicy="no-referrer">

*****

####  我是大鲨鱼  
##### 27#       发表于 2023-2-12 01:21

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708254&amp;ptid=2119156" target="_blank">毒菇 发表于 2023-2-11 23:56</a>

还是文学工作者写出来好懂说起来我第一印象觉得他姓蒋来着，可能因为老蒋也算幻想文学作家吧（指日 ...</blockquote>
姜峯楠是用英文发表作品的，署名也都是用的英文名Ted Chiang。所以他的早期作品被引进国内的时候，作者名字就曾被译为“特德&amp;#xB7;蒋”。我读的第一篇他的作品《巴比伦塔》就有这个问题。

哪怕到现在，这位华裔作家的百度百科词条里，还是把蒋和姜两个字混着用。考虑到他在作品中对汉字文化流露出的偏见，我都怀疑是不是他本人都不太在意自己的祖姓用汉字怎么写<img src="https://static.saraba1st.com/image/smiley/face2017/245.png" referrerpolicy="no-referrer">

*****

####  天网  
##### 28#       发表于 2023-2-12 01:24

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708896&amp;ptid=2119156" target="_blank">燕山雪 发表于 2023-2-12 01:02</a>

很好的角度，但从AI技术的角度看，chatGPT最惊人的还不是它满嘴跑火车的本事，而是它理解自然语言并把上下 ...</blockquote>
看介绍，上下文的连贯性不也是学习数据量够了大力飞砖飞起来的

我其实感觉人也就是那样，大脑没法想象出没有见过的东西，“逻辑”希腊原始词源有speech的意思。

*****

####  citrus  
##### 29#       发表于 2023-2-12 01:29

因为Ted Chiang主张废除汉字，个人觉得没必要看他关于语言的，哪怕看起来很有道理的言论<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 偽物| + 1|感谢网友提醒，不知道这人这么坏.|

查看全部评分

*****

####  Lunamos  
##### 30#       发表于 2023-2-12 01:30

能理解作者想表达的意思，但感觉比喻不是很贴切。一般不存在有损压缩后能胜过原无损框架的情况。比如让ChatGPT写个正则表达式或是python脚本，提出的要求也是搜不到的，它可以写出并能正确匹配或运行的。而在“存储了全网信息”的搜索引擎里却搜不出，你必须理解并学习regex和python的相关语法以及API，通过理解官方文档或stackoverflow中的例子才能慢慢自行推写出来。Stable Diffusion也类似。只从信息论框架出发计算有损失真率之类方法还是不好直接套用在这里。


*****

####  燕山雪  
##### 31#       发表于 2023-2-12 01:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709032&amp;ptid=2119156" target="_blank">天网 发表于 2023-2-12 01:24</a>

看介绍，上下文的连贯性不也是学习数据量够了大力飞砖飞起来的

我其实感觉人也就是那样，大脑没法想象出 ...</blockquote>
现在NLP juan最难解释的就是emergent，所谓准确率所谓智能都是大到一定程度后突然涌现出来的，而且LLM各种爆杀小规模专家模型。直接堵死一票苦逼博士的毕业路。然而人类从单个神经元行为到智力同样也是emergent，这两者真的有本质区别么？

*****

####  ac死或生  
##### 32#       发表于 2023-2-12 01:36

 本帖最后由 ac死或生 于 2023-2-12 01:40 编辑 

原来如此，不过我倒是对这个用数学题来检测是否真的是强人工智能比较感兴趣。
果然数学不会就是不会<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  NarwhalC  
##### 33#       发表于 2023-2-12 01:41

好文 收藏了

*****

####  الطائر  
##### 34#       发表于 2023-2-12 01:45

 本帖最后由 الطائر 于 2023-2-12 02:37 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708999&amp;ptid=2119156" target="_blank">燕山雪 发表于 2023-2-12 01:19</a>

如果你觉得“有损压缩解压时出现误差”等同于“创造新内容”，那么你说得对 ...</blockquote>
建议先总结原文段落大意、概括中心思想。从结论开始倒着看，会比较方便：

首先，作者在最后几段讨论的是“大语言模型能帮助人类创作原创作品吗？”这里的“原创”是针对人类作者而言，并不涉及AI是否在原创这件事。“原创”意味着“表达自己想法”，即使AI有它的想法，仍然不是人类自己的想法。去掉最后几段不看，就能注意到作者讨论的重点并非AI能否<strong>原创</strong>，而在于AI能否用较短的篇幅传达出“与<strong>真实</strong>世界的真实知识相对应”的信息（即不损害重点信息的压缩）。全文讨论的是人类能否借助AI学习互联网上的知识。

作者猜测要让AI学会真实知识需要“在用于构建这些模型的技术上取得重大突破”，但并不完全否定这种可能性。因此他在前述段落之前几段提出“将大语言模型与有损压缩进行类比是有用的……因为每次都会丢失更多的信息”、“衡量大语言模型质量的一个有用标准可能是，公司是否愿意使用它生成的文本作为新模型的训练材料。”、“如果我们开始看到模型产生的输出和输入一样好，那么有损压缩的类比将不再适用。” 这都是围绕着真实世界的信息来讲的，和独创性没啥关系。

然后，回到前面作者对有损压缩的理解，“如果一种压缩算法被设计成在99%的原始文本被丢弃后重建文本，我们应该预料到它生成的很大一部分内容将完全是<strong>捏造</strong>的。” 注意这个99%，捏造的概念显然已经超过了误差的概念，是新的内容。但作者认为这是“不可接受的”。联系上下文，不可接受不是因为不“有趣”，而是因为不真实。

*****

####  fufusako  
##### 35#       发表于 2023-2-12 01:53

我记得好像不是这样，原理更像是对所有概念的“学习”而非“记忆”，比如学习“蓝色”和“狗”以后，就可以推理出蓝色的狗的样子，尽管世界上并没有蓝色的狗（的资料）。如果单从存储方式思考有点过于肤浅了

*****

####  الطائر  
##### 36#       发表于 2023-2-12 01:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709166&amp;ptid=2119156" target="_blank">الطائر 发表于 2023-2-12 01:45</a>

建议先总结原文段落大意、概括中心思想。从结论开始倒着看，会比较方便：

首先，作者在最后几段讨论的是 ...</blockquote>
也能注意到人们对AI技术未来应用期待的区别：Stable Diffusion 属于艺术创作，人们期待用他来创造新奇有趣的内容，重要的是它画的帅哥美女能否让观众产生性冲动。而 ChatGPT，并非只是一个聊天软件或文学创作软件（类似功能甚至可以用低水平的AI完成。值得注意的是，聊天软件有时甚至不需要神经网络，几十年前根据关键词返回预设句子的聊天机器人假扮心理医生，可以和客户聊个有来有回）。相反，ChatGPT现在已被当成了一个可以发展成超越搜索引擎的通用智能的雏形。

*****

####  الطائر  
##### 37#       发表于 2023-2-12 01:59

 本帖最后由 الطائر 于 2023-2-12 02:38 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709202&amp;ptid=2119156" target="_blank">fufusako 发表于 2023-2-12 01:53</a>

我记得好像不是这样，原理更像是对所有概念的“学习”而非“记忆”，比如学习“蓝色”和“狗”以后，就可以 ...</blockquote>
ChatGPT 有基本的推理能力，但和你说的没啥关系。“蓝色的狗”只是字符组合，可以衍生出无限组合，如“蓝色的狗尾巴”、“蓝色的狗叫声”。

推理指的则是：已知“狗是蓝色的”、“小明是狗”，以及逻辑三段论，推出“小明是蓝色的”。推理的结果是固定的。

当然，ChatGPT 的推理能力并不完善，有时它会得出“小明是红色的”这样的结论。

注意：这个结论对了一半，即“小明”是可以用颜色描述的概念，而“叫声”不是。

*****

####  Rho  
##### 38#       发表于 2023-2-12 02:05

<blockquote>燕山雪 发表于 2023-2-12 01:02
很好的角度，但从AI技术的角度看，chatGPT最惊人的还不是它满嘴跑火车的本事，而是它理解自然语言并把上下 ...</blockquote>
上个世纪有个美国人说自己训练驴子学会了算数，这驴子能用蹄子敲击数表达算数答案。后来发现这驴子只是看着主人的神色敲，等敲对了数后主人开心了驴子就知道自己做对了。

*****

####  الطائر  
##### 39#       发表于 2023-2-12 02:06

计算机CPU的工作方式是存储和运算，但神经网络的记忆不是存储，而是和人的大脑一样，不断学习“概念的联系”，并适当地遗忘。

很多人误以为AI像CPU一样运作，甚至是计算，这混淆了不同层次的结构。当AI表现得像人时，他们就以为AI是人与机器合体的超人。实际情况是，AI和人一样不擅长计算。

*****

####  advancedigger  
##### 40#       发表于 2023-2-12 02:14

有意思的观点，但他没有从不同需求的角度考虑。很多情景下其实不需要高清图像，而只需要几张JPG。

*****

####  الطائر  
##### 41#       发表于 2023-2-12 02:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709166&amp;ptid=2119156" target="_blank">الطائر 发表于 2023-2-12 01:45</a>

建议先总结原文段落大意、概括中心思想。从结论开始倒着看，会比较方便：

首先，作者在最后几段讨论的是 ...</blockquote>
“总结段落大意”、“概括中心思想”，其实就是有损压缩。对人来说，思考与理解是在“压缩”之后的事，没有压缩就谈不上思考和理解。

好的“有损压缩”应该是丢掉细节、抓住主干，即作者所说的“可接受的模糊性”。你们可以试试让AI阅读长文抓重点，看看对不对。

*****

####  الطائر  
##### 42#       发表于 2023-2-12 02:35

 本帖最后由 الطائر 于 2023-2-12 02:58 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709213&amp;ptid=2119156" target="_blank">الطائر 发表于 2023-2-12 01:56</a>

也能注意到人们对AI技术未来应用期待的区别：Stable Diffusion 属于艺术创作，人们期待用他来创造新奇有 ...</blockquote>
            聊天机器人

1966年的心理按摩师 Eliza，只有200行代码，却能让人以为她是人。
 <blockquote>Men are all alike. （患者：男人都是一样的。）

IN WHAT WAY （ELIZA：怎么说？）

They're always bugging us about something or another. （患者：他们总是说我们这儿不好那儿不好。）

CAN YOU BE MORE SPECIFIC （ELIZA：能更加具体一些么？）

Well, my boyfriend made me come here. （患者：恩，我男朋友让我来这儿。）

YOUR BOYFRIEND MADE YOU COME HERE （ELIZA：你的男朋友让你来这儿？）

He says I'm depressed much of the time. （患者：他说我大多时候都很沮丧。）

I AM SORRY TO HEAR YOU ARE DEPRESSED（ELIZA：很抱歉听到您感到沮丧。）

It's true. I am unhappy. （患者：是的，我不开心。）

DO YOU THINK COMING HERE WILL HELP YOU NOT TO BE UNHAPPY （ELIZA：你觉得来这里能让你开心一点吗？）

I need some help, that much seems certain. （患者：我需要帮助，这一点似乎可以肯定。）

WHAT WOULD IT MEAN TO YOU IF YOU GOT SOME HELP （ELIZA：对你来说，什么意味着对你有帮助呢？）

Perhaps I could learn to get along with my mother. （患者：也许我该试着和我妈妈好好相处。）

TELL ME MORE ABOUT YOUR FAMILY（ELIZA：跟我谈谈你的妈妈吧。）</blockquote>
地址如下：
[https://www.cyberpsych.org/eliza/](https://www.cyberpsych.org/eliza/)

建议图灵自杀前和她聊一聊

*****

####  Lucario  
##### 43#       发表于 2023-2-12 03:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708254&amp;ptid=2119156" target="_blank">毒菇 发表于 2023-2-11 23:56</a>

还是文学工作者写出来好懂说起来我第一印象觉得他姓蒋来着，可能因为老蒋也算幻想文学作家吧（指日 ...</blockquote>
因为特德姜除了是科幻作家以外，他还是布朗大学CS专业毕业的，正正经经的科班出身

就算脱离前沿科研领域多年，他对计算机技术的本质还是有清醒认识的，换个文科生来就算文字写得好也不能解释的这么清楚

*****

####  sukal2008  
##### 44#       发表于 2023-2-12 03:35

转帖一下他这篇着名的《坏汉字》，没别的意思，只是供大家更全面地了解一个美国华裔。

============================

作者：特德·姜

这不是个人恩怨。我在小时候被迫上过周六上午的中文学校，什么都没有学到，但我不是因为这个才写这篇文章。我上这些课程表现不佳，原因有很多，其中之一是我因为要错过卡通片“super friends”而很不爽。我不会把自己学习中文的失败算到汉字头上。

不，我的反对是实际性的。我喜欢识文断字，而中国文字千年来都是识文断字的阻碍。用表音书写系统如字母文字或者音节文字，你只需要学几十个符号就可以阅读报纸上印的大部分内容。但用中国文字，你得学三千个。书写比阅读就更难了。如果你不能用发音作为拼写的辅助，你只有靠死记硬背了。这种认知上的困难非常大，即使受过高等教育的汉语使用者也常常忘记最近没用过的汉字是怎么写的。

海量的汉字也造成了其他困难，我曾经翻过一本中文字典，我见过一部汉字打字机的照片，我读过关于中文电报的东西。虽说各有精巧之处，但他们都是笨重的发明，是用来承载中国文化脖子上重担的独轮手推车。如果局限于汉字是不可能使用电脑和智能手机的，只有用拼音和注音符之类的语音书写系统，才可能输入文字。上个世纪曾经有多次用字母表取代汉字的提议，但都失败了。唯一执行的改革是对复杂的汉字进行简化，这没有解决我上面说过的任何问题，而又产生了出了新的问题。

所以让我们设想一个汉字一开始就没有被发明出来的世界。如果有这样的文字真空，字母表就可能以我们的历史上没有的方式从印度传到东方。为了避免这个思想实验太过印欧中心，让我们设想古代中国人在三千年前就发明了他们自己的语音书写系统，类似于今天的注音符号。后果是什么呢？很明显，识字率会提高很多，也更容易采纳现代技术。但是请允许我设想另一种可能的后果。

中国文字据说有一个长处：它们能让人容易地阅读几千年前的着作。阅读古典汉语的容易度被严重夸大了，但就古代文本的可理解性来说，我怀疑这是因为中国文字不是表音的。发音在数百年间变化着，当你用字母进行书写时，拼写最后会跟着发音走。（想想《贝奥武甫》（按：公元八世纪古英语长诗）《坎特伯雷故事集》（十四世纪作品）《哈姆雷特》（十六世纪末作品）之间的不同）古典汉语一直可以理解，恰是因为汉字无视发音的变化。所以如果古代中国的手稿是用表音文字书写的，随着时间推移，它们就会变得越来越难以解读。

中国文化因为赋予传统以太高价值而臭名昭着。如果说这完全是古典汉语易于阅读所致，大概过于简化了，但可以合理地提出这会带来某些影响。想象一个世界，在其中英文书写变化极小，以至于《贝奥武甫》时代的作品在过去一千二百年里都一直可读。我能够很容易相信，在这样一个世界里，当代英语文化会比现在保持更多的盎格鲁-撒克逊时代价值观。所以在我所提出的、中国采用字母文字的反事实历史中，中国文献的可理解性随着语音变化的浪潮而被侵蚀，中国文化似乎也就可能不再那么植根于过去了。也许中国在其历史中会进化得更快，对于新的观念也更少抵抗。它将有更好的准备去处理现代性，这并不只是说用改进的方式去使用电报或电脑。

在这样一个世界里，我不知道我个人是不是会过得更好，因为那时候我是否存在还不一定呢。但有一件事我可以肯定，在一个汉语用表音文字书写的世界里，我永远也用不着去读到或听到更多关于中国文字的误解——它们像是小画啦，它们直接呈现观念啦，表示“crisis（危机）”的中文词是“危险”加上“机遇”啦。这一点至少也让我如释重负了。

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 偽物| + 1|好评加鹅|

查看全部评分

*****

####  Licheus  
##### 45#       发表于 2023-2-12 03:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709589&amp;ptid=2119156" target="_blank">sukal2008 发表于 2023-2-12 03:35</a>
转帖一下他这篇着名的《坏汉字》，没别的意思，只是供大家更全面地了解一个美国华裔。

=================== ...</blockquote>
知道你纠结帽子了，退下吧baby，谁还没点毛病呢。

*****

####  sukal2008  
##### 46#       发表于 2023-2-12 03:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709596&amp;ptid=2119156" target="_blank">Licheus 发表于 2023-2-12 03:38</a>

知道你纠结帽子了，退下吧baby，谁还没点毛病呢。</blockquote>
都说了没别的意思了，您就不要给人扣帽子了好吧

*****

####  Licheus  
##### 47#       发表于 2023-2-12 03:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709603&amp;ptid=2119156" target="_blank">sukal2008 发表于 2023-2-12 03:40</a>
都说了没别的意思了，您就不要给人扣帽子了好吧</blockquote>
是是是你说的都对

*****

####  sukal2008  
##### 48#       发表于 2023-2-12 03:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709608&amp;ptid=2119156" target="_blank">Licheus 发表于 2023-2-12 03:41</a>

是是是你说的都对</blockquote>
嗯嗯

*****

####  哈扎马  
##### 49#       发表于 2023-2-12 03:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709032&amp;ptid=2119156" target="_blank">天网 发表于 2023-2-12 01:24</a>

看介绍，上下文的连贯性不也是学习数据量够了大力飞砖飞起来的

我其实感觉人也就是那样，大脑没法想象出 ...</blockquote>
人类对黑洞的推理想象先于实际看到黑洞<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  哈扎马  
##### 50#       发表于 2023-2-12 03:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708896&amp;ptid=2119156" target="_blank">燕山雪 发表于 2023-2-12 01:02</a>

很好的角度，但从AI技术的角度看，chatGPT最惊人的还不是它满嘴跑火车的本事，而是它理解自然语言并把上下 ...</blockquote>
从艺术角度来看，sd确实没有创造新内容与新形式<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  哈扎马  
##### 51#       发表于 2023-2-12 03:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709589&amp;ptid=2119156" target="_blank">sukal2008 发表于 2023-2-12 03:35</a>

转帖一下他这篇着名的《坏汉字》，没别的意思，只是供大家更全面地了解一个美国华裔。

=================== ...</blockquote>
鲁迅对汉语也是类似的看法

*****

####  blackeyed  
##### 52#       发表于 2023-2-12 03:56

 本帖最后由 blackeyed 于 2023-2-12 03:59 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709062&amp;ptid=2119156" target="_blank">Lunamos 发表于 2023-2-12 01:30</a>

能理解作者想表达的意思，但感觉比喻不是很贴切。一般不存在有损压缩后能胜过原无损框架的情况。比如让Chat ...</blockquote>
它是猜出, 我实测了不少正则表达式, 简单点的成功率就四五成, 复杂点就两三成

用久了感觉真就是猜……

就是那种他觉得语义上像回事的就当解了

比如我让他写个功能, 他确实给我几行代码, 看起来无懈可击, 读起来完全就是那回事

但你一运行…… 发现他写的 Object.Write(); 可是这里的这种Object根本没有Write方法啊!

他显然是训练的时候看过别的对象可以Write(); 然后从语义上来说这个Object.Write()就合理了

真就一本正经的胡说八道的感觉

当然写代码确实能帮一些, 毕竟用他写的跑一下不行再自己写还是省时间的

*****

####  erghrecu7  
##### 53#       发表于 2023-2-12 04:02

感觉文章里提出的未来互联网被各种大语言模型内容污染，纯净的训练材料无处可寻确实是个问题

*****

####  瑟尼欧利斯  
##### 54#       发表于 2023-2-12 04:36

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709704&amp;ptid=2119156" target="_blank">erghrecu7 发表于 2023-2-12 04:02</a>
感觉文章里提出的未来互联网被各种大语言模型内容污染，纯净的训练材料无处可寻确实是个问题 ...</blockquote>
现在互联网上的内容农场已经够糟糕了吧，chatgpt的训练材料大概也是经过人工筛选过的。

—— 来自 Xiaomi 22041211AC, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  yukiecho  
##### 55#       发表于 2023-2-12 05:10

其实互联网本身就有作者所说的这些问题啊，就算是搜索引擎也是有内部排序权重的，难道现在的搜索引擎就是不压缩的真实世界了？

*****

####  alacab  
##### 56#       发表于 2023-2-12 07:08

一个足够支撑一篇科幻小说的点子，蒋/姜老师随随便便的就说出来了。

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  天知道  
##### 57#       发表于 2023-2-12 07:20

这个不就是人工智能两大路线之争么；印象中写GEB的侯世达曾经批评过目前通过机器学习来达到人工智能的这条线。

*****

####  QUI  
##### 58#       发表于 2023-2-12 08:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59708254&amp;ptid=2119156" target="_blank">毒菇 发表于 2023-2-11 23:56</a>

还是文学工作者写出来好懂说起来我第一印象觉得他姓蒋来着，可能因为老蒋也算幻想文学作家吧（指日 ...</blockquote>
这位是CS科班出身，不写科幻的时候写的是软件文档，还在微软找了个女朋友

*****

####  shinigamix  
##### 59#       发表于 2023-2-12 08:13

一个工具而已，有没有真的智能重要吗？只要我用着顺手，能帮我解决一些问题就行了。它真要能自己会思考了，还要我干嘛？

*****

####  幻肢痛  
##### 60#       发表于 2023-2-12 09:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59710262&amp;ptid=2119156" target="_blank">shinigamix 发表于 2023-2-12 08:13</a>

一个工具而已，有没有真的智能重要吗？只要我用着顺手，能帮我解决一些问题就行了。它真要能自己会思考了， ...</blockquote>
然而泥潭已经在嚷嚷ai取代人类了<img src="https://static.saraba1st.com/image/smiley/face2017/049.png" referrerpolicy="no-referrer">


*****

####  Lunamos  
##### 61#       发表于 2023-2-12 09:31

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709675&amp;ptid=2119156" target="_blank">blackeyed 发表于 2023-2-12 04:56</a>

它是猜出, 我实测了不少正则表达式, 简单点的成功率就四五成, 复杂点就两三成

用久了感觉真就是猜……</blockquote>
这个我在隔壁也提到了，指望直接无脑复制粘贴就能用的话是不行的，但多数都是稍微改改就OK。关键在于交流中清晰而具体地描述需求，逐渐指出它的问题，它会慢慢改。

之前试着逐渐描述需求让它写的一些具体python脚本都是直接能用的水平。一些难度高的需求它可以给出一个包含了正确包、API和类的框架，也可以把它作为高近似的伪代码加速编写。regex很多都能直接用，至少可以作为自然语言解释器给出正确方向。现在已经相当实用了，在驾驭和使用方法上需要一些技巧。

*****

####  呼鲁鲁修  
##### 62#       发表于 2023-2-12 09:34

唉。。。文章里说的那些缺点，真正的人类又能好到哪里去呢，

大把真人一样轻信一些是似而非、半真半假的**包，然后咀嚼“压缩”一番，又喂给下一个真人，AI把这个进程加速了。

我们的大脑就是容易相信这种似是而非的东西，要不断的学习和自省才能克服天性。

*****

####  downnote  
##### 63#       发表于 2023-2-12 09:37

我从来不觉得AI是和人类一样从道理和逻辑上“理解”了事情，他们没有构筑人类这样的思维方式。都是通过算法模拟出看起来差不多的结果，只是在某些领域比如围棋，表现得更像那么回事而已。

说回特德姜这个文章，下面的内容还会好理解，反而最开始那个影印机的例子，怎么感觉问题出现得弱智，居然这样对图像采样吗？因为”那几个数字“在图像上有某些相似性就互相替换，如果人眼能分辨出来的数字都能互相替换，那么图像其他局部肯定有更多问题。这个影印机居简直莫名其妙。要不是文章都给出了这个品牌，乱说就会吃官司大概率是真事，否则我就觉得他是在扯淡了。

*****

####  蛋饼  
##### 64#       发表于 2023-2-12 09:41

这写得什么...压缩是什么不着边际的比喻

经典科幻作家谈技术

llm当然没有狭义的推理功能，

但你无法拒绝它是有部分认知功能的，是确实可以取代不少认知工作的。而不是所谓的模糊压缩，或者什么创新靠压缩错误


*****

####  lindley  
##### 65#       发表于 2023-2-12 09:53

<img src="https://img.saraba1st.com/forum/202302/12/095308qynxnpvygv7agyyn.png" referrerpolicy="no-referrer">

<strong>206C66E1-095B-47F5-B84F-2A198AE1941A.png</strong> (41.05 KB, 下载次数: 0)

下载附件

2023-2-12 09:53 上传

就chatGPT现在这表现，离突破图灵测试也太早了吧

*****

####  洛拉斯  
##### 66#       发表于 2023-2-12 09:55

这玩意不是强人工智能，但是做搜索引擎足够了

*****

####  洛拉斯  
##### 67#       发表于 2023-2-12 09:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59711012&amp;ptid=2119156" target="_blank">lindley 发表于 2023-2-12 09:53</a>
就chatGPT现在这表现，离突破图灵测试也太早了吧</blockquote>
因为训练集的问题，国内高水平文字训练集太贵了，互联网上都是复制粘贴的垃圾信息

*****

####  勿徊哉  
##### 68#       发表于 2023-2-12 10:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59711012&amp;ptid=2119156" target="_blank">lindley 发表于 2023-2-12 09:53</a>

就chatGPT现在这表现，离突破图灵测试也太早了吧</blockquote>
背后还需要大量人工调教，其实成本很高的。

不过和搜索引擎公司合作的话，就可以把相当一部分人工调教成本转移给用户。例如，当其他用户使用传统搜索引擎搜索“中山市古镇镇有哪些口碑好的餐厅”并点击列出餐厅名的页面，相当于完成了一次调教，即告诉插头GPT合规的答案应该长什么样。


*****

####  IRIS虹  
##### 69#       发表于 2023-2-12 10:26

啥时候能看到他的新的科幻小说啊，等不及了

—— 来自 Xiaomi Redmi K30 Pro, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2


*****

####  心跳男孩扭扭扭  
##### 70#       发表于 2023-2-12 10:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59710905&amp;ptid=2119156" target="_blank">蛋饼 发表于 2023-2-12 09:41</a>

这写得什么...压缩是什么不着边际的比喻

经典科幻作家谈技术</blockquote>
经典做题家不服藤校CS专业智力水平


*****

####  燕山雪  
##### 71#       发表于 2023-2-12 11:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709628&amp;ptid=2119156" target="_blank">哈扎马 发表于 2023-2-12 03:43</a>

从艺术角度来看，sd确实没有创造新内容与新形式</blockquote>
99%画师都没有，其中一大半的构图用色能力甚至还不如现在的AI


*****

####  哈扎马  
##### 72#       发表于 2023-2-12 11:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59711912&amp;ptid=2119156" target="_blank">燕山雪 发表于 2023-2-12 11:30</a>

99%画师都没有，其中一大半的构图用色能力甚至还不如现在的AI</blockquote>
这要看如何定义画师这个行当了。就算真人画师是99%，ai也是100%<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">


*****

####  الطائر  
##### 73#       发表于 2023-2-12 11:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59710905&amp;ptid=2119156" target="_blank">蛋饼 发表于 2023-2-12 09:41</a>

这写得什么...压缩是什么不着边际的比喻

经典科幻作家谈技术</blockquote>
作者认为理解即压缩，无损压缩无穷多的乘法算式，压缩到极限，应该得到运算规则和乘法表。文章称这个想法是人工智能研究人员马库斯.赫特提出的。

*****

####  BREEEEZE  
##### 74#       发表于 2023-2-12 12:00

喂点百家号给chatgpt


*****

####  rp1993  
##### 75#       发表于 2023-2-12 12:26

特德姜这是用真正全知全能的人工智能来要求chatgpt，但我觉得自然语言模型离人工智能确实很遥远，里面列举的缺陷也是以数理逻辑来当例子，但作为人类语言的模拟已经是够格的了。

人对文本或者非严格逻辑的理解本身也是有损压缩，比如我完全理解《出师表》蕴含的意义与背景知识（压缩），但如果我不是逐字逐句去背过出师表（不压缩），你让我复述出师表，我回答也是必然缺失一部分韵味或者文字的（有损）。而这正也是人类语言的特点，不要说完全理解，现实中有多少人对自己一知半解的事物高谈阔论。有损压缩才是chatgpt表现得更像人类自然语言的关键。

*****

####  草格瓦拉  
##### 76#       发表于 2023-2-12 12:32

如果说ai对信息的处理是模糊的jpg，那大部分人对数据的处理就是对着jpg画的手绘草图，关键有些人随手画完还很志得意满地说，你看，我画的是不是一模一样，照我这个就行了

—— 来自 Xiaomi 22081283C, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play


*****

####  oct71952  
##### 77#       发表于 2023-2-12 14:35

哈哈哈想起来我问chatGPT的第一个问题就是你觉得特德姜这个作家怎么样来自: iPhone客户端

*****

####  orecheng  
##### 78#       发表于 2023-2-12 14:37

图神经网络的Embedding不就是高维降低维的有损压缩吗


*****

####  citrus  
##### 79#       发表于 2023-2-12 15:26

人类思想史从古希腊（或者西方近代伪托的古希腊<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">）以来的一条主线，就是从客观经验中抽象出概念，以及对事物进行分类

这两种方法都是去掉非关键信息而保留关键信息，也就是Ted Chiang所说的“压缩”

但是jpeg、mp3这种针对人的感知的专有领域压缩，和霍夫曼编码等仅由子串出现频率来决定的压缩，其性质是否相同？是否具有相同的意义？是否就是“概念”？

Demis Hassabis有个观点，目前的AI还不能做到从物理世界的认知形成概念

如果给AI喂一亿小时的交通监控录像，它能自动形成泥头车、猫狗、鬼火少年、路人等概念，并对新录像中的这些特征信息加以标注吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  osborn  
##### 80#       发表于 2023-2-12 16:04

印象中好像是机吉斯卡以前贴过 坏汉字 的全文，我感觉就是个很普通的接触到汉字的西方人对汉字体系的吐槽而已。这个从我们的角度也没啥好纠结的，字母型语言确实有一些自己的优势，就算未来某一天中国占领了全世界，字母型语言也不可能被废除，不然键盘你都没法设计。当然汉字体系有其他的优势，各种体系并存才是最好的

*****

####  石傅  
##### 81#       发表于 2023-2-12 16:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59714916&amp;ptid=2119156" target="_blank">osborn 发表于 2023-2-12 16:04</a>

印象中好像是机吉斯卡以前贴过 坏汉字 的全文，我感觉就是个很普通的接触到汉字的西方人对汉字体系的吐槽而 ...</blockquote>
所以说，就算是华裔，思维已经完全是西方那一套

*****

####  吃人不吐葡萄  
##### 82#       发表于 2023-2-12 16:12

「alphago是所有棋谱的模糊图像」


*****

####  雷囧羊  
##### 83#       发表于 2023-2-12 16:30

说得很在理，例子很有意思，事实性错误对于目前的ai还是比较致命的

不过回头一想，大部分人类也就是个复读机的水平，瞎编乱造各种fake news还少吗

梗小鬼不说了，再有数据女工百家号洗稿这些一叠加，就觉得，md，真人水平也就那jb样子


*****

####  Cres  
##### 84#       发表于 2023-2-12 16:42

这个时候就可以拿出刘慈欣的《诗云》了，力大飞砖才是浪漫呀。

诗就在那里了，只要挑选出来就好了。


*****

####  osborn  
##### 85#       发表于 2023-2-12 17:09

 本帖最后由 osborn 于 2023-2-12 17:11 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59714944&amp;ptid=2119156" target="_blank">石傅 发表于 2023-2-12 16:07</a>
所以说，就算是华裔，思维已经完全是西方那一套</blockquote>
那当然了，华裔这个身份你可以说跟纯种白人有点不同，但显然不可能会跟中国人一边啊。就好比在中国出生的黑人也不会把瓦坎达当成故乡…吧？

*****

####  泉玲奈  
##### 86#       发表于 2023-2-12 17:09

alhpago

有没有理解围棋..

可以说说为什么要那样下吗?


*****

####  lugiyahan  
##### 87#       发表于 2023-2-12 17:13

我觉得算不算真正的智能得看这个东西有没有主动思考并输出的能力，否则再表现的像人，也只是一个输入输出工具而已


*****

####  jpwhzh  
##### 88#       发表于 2023-2-12 17:51

chatgpt的意义在于证明现在技术能做到多好，正如ai所说你可能在嘲笑1+1=3的错误，而ai在现今已经能达到如此高


*****

####  厄斯沃穆  
##### 89#       发表于 2023-2-12 20:45

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59709641&amp;ptid=2119156" target="_blank">哈扎马 发表于 2023-2-12 03:46</a>
鲁迅对汉语也是类似的看法</blockquote>
鲁迅是一百年前的人。

—— 来自 HUAWEI ELS-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  血河之舞  
##### 90#       发表于 2023-2-12 21:00

我觉得你们都太看中所谓智能了，其实AI作为一个好用工具更适合人类发展，如果AI真发展到可以无需人类干预就能自由思考这种结果太可怕了，工业应用上也不可能用这种有大量不可控因素的AI。


*****

####  鸣鸣子  
##### 91#       发表于 2023-2-12 21:02

这个观察方向很有趣啊


*****

####  巨魔型美羽  
##### 92#       发表于 2023-2-12 23:20

发散一下思维，生物的意识是否是对他所感受到的物质及信息的压缩，如果无法跳出当前宇宙，那生命就是有上限的，好比重复压缩后得到均匀的灰度图或无意义的白噪声<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  さいなら  
##### 93#       发表于 2023-2-12 23:32

 本帖最后由 さいなら 于 2023-2-12 23:41 编辑 

我对这篇文章部分内容的 lossy compression 是（提前声明我完全不懂人工智能）：
1. ChatGPT 的内部机制相当于把互联网上的内容有损压缩了一下。
2. ChatGPT 并不真正理解什么，比如它不能做算术；你觉得它有智能只是因为有损压缩看起来确实更聪明。
但是这些观点的论据在哪里呢？关于 1，整篇文章似乎都没有提到 LLM 的内部机制啊，lossy compression 真的是一个准确的描述吗？关于 2，我觉得他的论述还是停留在外部现象，就像在说，“我用过 ChatGPT 算数，知道它现在不行，所以一定是它从本质上就不行。”但是说不定未来就行了呢？我觉得不从原理上分析很难让人信服啊。


*****

####  完先生  
##### 94#       发表于 2023-2-13 00:19

我想起来了一个

把zun的所有人物混合起来生成一个角色，看起来感觉也挺像那么回事儿


*****

####  thesa  
##### 95#       发表于 2023-2-13 00:24

框架，然后逻辑填充，绝大部分人自己记忆和使用记忆差不多也是这样


*****

####  Lucario  
##### 96#       发表于 2023-2-13 00:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59720131&amp;ptid=2119156" target="_blank">さいなら 发表于 2023-2-12 23:32</a>

我对这篇文章部分内容的 lossy compression 是（提前声明我完全不懂人工智能）：

1. ChatGPT 的内部机制相 ...</blockquote>
其实是有一定道理的，LLM学习的是各种字和词在语言里面分布的概率，通过喂了几十tb的语料，gpt3学到了人类语言里各种字词的概率分布。

它不用懂这些词汇的实际意义，也不用懂各种语言的语法，它只是学到了词A跟词B在一个句子里的概率比词C高或者低就行了，通过概率分布它就能生成数学上最符合自然语言和输入要求的文本。

理论上所有字词都可以任意排列，那排出来的文本数不胜数而且大部分都无意义，而概率分布可以说是对自然语言的一种抽象，理解成压缩也行。所以它目前做算数还是不太行，因为一道加法题在gpt那里是没有数学意义的，跟一串英文或者一句诗歌都是一回事儿，它用相同的方式去处理。


*****

####  Sacross  
##### 97#       发表于 2023-2-13 00:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59720131&amp;ptid=2119156" target="_blank">さいなら 发表于 2023-2-12 23:32</a>
我对这篇文章部分内容的 lossy compression 是（提前声明我完全不懂人工智能）：
1. ChatGPT 的内部机制相 ...</blockquote>
因为人类现在搞不清大脑工作原理，而现在的人工智能用的网络本质是大伙认为人脑大概是这样工作的而延伸的模仿扩展，所以没法从根本上给你说这玩意儿到底行不行

第一点有损压缩应该没啥问题，本质就是信号的特征矩阵提取之后关联，你要是清楚有损压缩那肯定也能理解现在的ai大致咋回事

第二点就是这玩意儿现在应该是有一定自适应性，按理说是可以不断变得看上去更合理，或者索性用额外网络串联把硬件继续提升啥的，肯定可以不断完善一些很显然的缺陷，实际的感觉其实有点像对一块破布缝缝补补让它逐渐变得像一件衣服，但是说不定他怎么补都还算一块更大的布

而且有个实际情况，ai现在是个黑箱，如果能做到输入输出符合要求，哪怕是模仿，在应用层面而言大多数情况下也不需要去考虑这东西到底是自己解决的还是转发给一个印度人帮你解决的了

—— 来自 OnePlus IN2020, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  ackroyd2  
##### 98#       发表于 2023-2-13 01:00

总结

chatgpt=压缩

压缩=理解

chatgpt ！= 理解  (做不了数学题但别的可以

用于拟似搜索引擎-重述or捏造

重述内容or生成原创-缺乏原生思考

思考

理解=数据挖掘  (对数据做分析，计算相关性，

chatgpt在无意识下模拟近似逼近了数据挖掘的结果

但人类大脑里面也是一坨，那是怎么理解的呢，是不是chatgpt和人类学数学一样都要经历逻辑训练。

人只是复读机，chatgpt也是复读机，但人可以学会逻辑思考？


*****

####  自主规制  
##### 99#       发表于 2023-2-13 01:06

压缩信息、模糊理解并做出看起来有道理的回复，这和人有什么区别，人的记忆不也是有损压缩。至于原创更是，像有损压缩信息的复印机一样“搞原创”的人类工作者不说80%起码也50%了……
文章看下来再对照现实总觉得多少有点安慰少数人的意思，毕竟AI和大部分人都不会数学<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  触手皇帝  
##### 100#       发表于 2023-2-13 01:23

我最震惊的反而是开头举例的复印机工作逻辑<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">，另外我很期待ted什么时候能用这点子再写写新作


*****

####  ackroyd2  
##### 101#       发表于 2023-2-13 01:42

高中学物理时无法理解电压的概念，就算说水压=电压，水位=电位也不理解。

人理解概念是用熟悉的概念去模拟想象，是不是有点像ai画图，电/水=发色，位/压=画风。

但这只是理解而非创造新概念。

根据物理观测数据，从已有概念里用ai画图创造新概念，演算新数学新物理？


*****

####  火樹銀華  
##### 102#       发表于 2023-2-13 02:24

既然说到压缩，为啥不从信息论/信息熵的角度展开谈谈

—— 来自 Xiaomi M2102J2SC, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  木瓜奶五元  
##### 103#       发表于 2023-2-13 05:35

好消息：AI只会缝合、模仿、复读、装出一副机灵的样子。不用担心它取代人类，因为它并没有真正的智慧。
坏消息：大多数人也没有。

—— 来自 Sony XQ-BC72, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  Liberation  
##### 104#       发表于 2023-2-13 06:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59718207&amp;ptid=2119156" target="_blank">厄斯沃穆 发表于 2023-2-12 20:45</a>

鲁迅是一百年前的人。

—— 来自 HUAWEI ELS-AN00, Android 12上的 S1Next-鹅版 v2.5.4 ...</blockquote>
哈扎马是当代的互联网小画家。


*****

####  大同小康  
##### 105#       发表于 2023-2-13 06:56

我的观点是，互联网时代，信息是冗余的，与其把机器学习技术用来进行缝合拼接而接着产出垃圾信息，不如用来进一步深化检索功能。


*****

####  pgain2004  
##### 106#       发表于 2023-2-13 07:04

要么你们还是先去关注 Two Minute Papers，多看几篇成果简洁吧……<img src="https://static.saraba1st.com/image/smiley/face2017/028.png" referrerpolicy="no-referrer">


*****

####  WindDragon  
##### 107#       发表于 2023-2-13 08:29

我看到倒数第三段的时候忽然在想：如果结尾加入一句“本文完全用chatGPT生成”那得多有艺术效果


*****

####  齐德隆  
##### 108#       发表于 2023-2-13 09:52

<blockquote>さいなら 发表于 2023-2-12 23:32
我对这篇文章部分内容的 lossy compression 是（提前声明我完全不懂人工智能）：

1. ChatGPT 的内部机制相 ...</blockquote>
你要原谅一下一个几十年前摸过程序的人对现代深度学习的想象只能停留在gzip压缩了，可能人家几十年前就是写这个的。科幻作家抛概念就好了，谈技术细节只会露馅，原来他什么都不懂。


*****

####  ceruleancard  
##### 109#       发表于 2023-2-13 10:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59721225&amp;ptid=2119156" target="_blank">ackroyd2 发表于 2023-2-13 01:42</a>

高中学物理时无法理解电压的概念，就算说水压=电压，水位=电位也不理解。

人理解概念是用熟悉的概念去模拟 ...</blockquote>
前几天刚好看了个费曼讲电磁场，物理学家不是这么思考的，水和电在他们看来是不能类比的


*****

####  舞野咲  
##### 110#       发表于 2023-2-13 10:29

换个角度想人对所谓智能有这样那样的定义是不是因为人不了解人的大脑是怎么运作的？


*****

####  Jimlee079  
##### 111#       发表于 2023-2-13 11:20

现在的深度学习模型还是可以被抽象理解成多项式拟合吧。我是觉得这类结构在当下的技术条件还是做不到强ai的。


*****

####  zephyrus_z  
##### 112#       发表于 2023-2-13 11:34

有意思，所以只是通过不同词之间一起出现的概率来生成新文章吗？如果是这样那和人还是不一样，应该没有人是这么思考的（部分网上垃圾信息除外）。人还是有多得多的不同阶层的常识、逻辑作为框架来限定新生成的内容的。不过常识涉及到的对象太多了是不是很难人为教给AI？毕竟人或生物学会常识可能得益于神经系统亿万年进化下来就是主攻对环境的抽象和互动的？之前看另一文章讲

*****

####  GloryXie  
##### 113#       发表于 2023-2-13 11:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59723071&amp;ptid=2119156" target="_blank">齐德隆 发表于 2023-2-13 09:52</a>

你要原谅一下一个几十年前摸过程序的人对现代深度学习的想象只能停留在gzip压缩了，可能人家几十年前就是 ...</blockquote>
不用几十年前，现在不搞ai的程序员对深度学习的想象也是一样的，甚至搞ai的很多研究生的理解也差不太多

*****

####  mosku  
##### 114#       发表于 2023-2-13 11:38

ted姜我记得是个科幻小说家来着


*****

####  ackroyd2  
##### 115#       发表于 2023-2-13 12:03

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59723370&amp;ptid=2119156" target="_blank">ceruleancard 发表于 2023-2-13 10:16</a>

前几天刚好看了个费曼讲电磁场，物理学家不是这么思考的，水和电在他们看来是不能类比的 ...</blockquote>
个人感觉是：他们学的多，自然有了更多的概念和更具象、更准确、更精细的想象，但那些想象也应该是从最基本的概念逐渐去靠拢的。


*****

####  ceruleancard  
##### 116#       发表于 2023-2-13 12:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59725095&amp;ptid=2119156" target="_blank">ackroyd2 发表于 2023-2-13 12:03</a>
个人感觉是：他们学的多，自然有了更多的概念和更具象、更准确、更精细的想象，但那些想象也应该是从最基 ...</blockquote>
他大概的意思是，电磁力才是更基本的，普通人经验中的宏观现象不够基本。
更具体一点，微观粒子的特性几乎全是数学推导出来的，比如普通人最熟悉波粒二象性，完全反直觉，但数学推导成立，换句话说，数学推导出来的这些个反直觉玩意，你让ai总结一万年也出不来，毕竟ai不会推导，算3位数加减法都困难…


*****

####  JOJO42  
##### 117#       发表于 2023-2-13 12:50

记得他笔下的短篇小说《领悟》里，超人类突破之后第一件事情就是创造出一门能更贴合自己智力的语言体系，

联系这篇他对ChatGPT的见解，还是挺有意思的


*****

####  小修  
##### 118#       发表于 2023-2-13 12:54

这文章观点是真好。我很赞同，之前模模糊糊的想法，一下被点醒被归纳出来了。


*****

####  evatrix  
##### 119#       发表于 2023-2-13 13:06

其实冯诺依曼说过，数学中你没有理解什么，只是习惯了它们而已


*****

####  蛋饼  
##### 120#       发表于 2023-2-13 13:13

 本帖最后由 蛋饼 于 2023-2-13 13:15 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59712241&amp;ptid=2119156" target="_blank">الطائر 发表于 2023-2-12 11:58</a>

作者认为认知即压缩，在保持正确性的前提下，压缩无穷多的乘法算式，压缩到极限，应该得到运算规则和乘法 ...</blockquote>
科幻作家谈技术的问题就是，有些内容很可能像ChatGPT的瞎编一样是not even remotely true的，

比如这个压缩的例子的理论来源赫特奖，这个<strong>无损压缩</strong>比赛现在效果最好的就是transformer大模型...

然后他说 <blockquote>ChatGPT这样的模型没有资格获得赫特奖</blockquote>
同样，有这样一个奖项也不意味着可以反过来用无损压缩来理解ChatGPT， 

更不是什么“LLM是有损压缩，所有文本的模糊图像”，

transformer能跨界做的事情太多了，蛋白质设计也能做，怎么不说它是蛋白质设计。

里面提到的算术也是大模型的涌现能力，
<img src="https://preview.redd.it/nfp8ck4j1w591.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d993a2d1ccde5735d97290a449c475215fa196cf" id="aimg_ZCLlQ" onclick="zoom(this)" onmouseover="img_onmouseoverfunc(this)" style="cursor:pointer" width="800"/)

另外， <blockquote>LLM从海量自由文本中学习了大量知识，如果把这些知识做粗略分类的话，可以分为语言类知识和世界知识两大类。

语言类知识指的是词法、词性、句法、语义等有助于人类或机器理解自然语言的知识。关于LLM能否捕获语言知识有较长研究历史，自从Bert出现以来就不断有相关研究，很早就有结论，各种实验充分证明LLM可以学习各种层次类型的语言学知识，这也是为何使用预训练模型后，各种语言理解类自然语言任务获得大幅效果提升的最重要原因之一。另外，各种研究也证明了浅层语言知识比如词法、词性、句法等知识存储在Transformer的低层和中层，而抽象的语言知识比如语义类知识，广泛分布在Transformer的中层和高层结构中。

世界知识指的是在这个世界上发生的一些真实事件（事实型知识，Factual Knowledge），以及一些常识性知识(Common Sense Knowledge)。比如“拜登是现任美国总统”、“拜登是美国人”、“乌克兰总统泽连斯基与美国总统拜登举行会晤”，这些都是和拜登相关的事实类知识；而“人有两只眼睛”、“太阳从东方升起”这些属于常识性知识。关于LLM模型能否学习世界知识的研究也有很多，结论也比较一致：LLM确实从训练数据中吸收了大量世界知识，而这类知识主要分布在Transformer的中层和高层，尤其聚集在中层。而且，随着Transformer模型层深增加，能够学习到的知识数量逐渐以指数级增加（可参考：BERTnesia: Investigating the capture and forgetting of knowledge in BERT）。其实，你把LLM看作是一种以模型参数体现的隐式知识图谱，如果这么理解，我认为是一点问题也没有的。

“When Do You Need Billions of Words of Pre-training Data?”这篇文章研究了预训练模型学习到的知识量与训练数据量的关系，它的结论是：对于Bert类型的语言模型来说，只用1000万到1亿单词的语料，就能学好句法语义等语言学知识，但是要学习事实类知识，则要更多的训练数据。这个结论其实也是在意料中的，毕竟语言学知识相对有限且静态，而事实类知识则数量巨大，且处于不断变化过程中。而目前研究证明了随着增加训练数据量，预训练模型在各种下游任务中效果越好，这说明了从增量的训练数据中学到的更主要是世界知识。</blockquote>


*****

####  魔神赵日天  
##### 121#       发表于 2023-2-13 13:19

这不就介绍autoencoder么


*****

####  compass01  
##### 122#       发表于 2023-2-13 13:37

机器学习就是压缩，这不是很早就有的说法了嘛。所有可能字符串，语法正确文本，事实正确文本，是从大到小三个集合。也有人认为ai学到语法正确就行了，学到事实正确就是过拟合了，死记硬背会扼杀ai的创造力。


*****

####  lexi  
##### 123#       发表于 2023-2-13 14:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59711012&amp;ptid=2119156" target="_blank">lindley 发表于 2023-2-12 09:53</a>

就chatGPT现在这表现，离突破图灵测试也太早了吧</blockquote>中文环境里很多app的数据不对搜索引擎开放，而openAI估计也没多重视中文互联网，没喂多少中文数据给AI，估计它爬不到多少有价值的食店评价，甚至根本没搜到，就只能给出百度百科或者百家号之类信息有效性很差的来源所提供的资料了<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">


*****

####  halfelf  
##### 124#       发表于 2023-2-13 14:50

会尝试找出问题在哪，并重新给自己定义，后面不知道会变成啥样


*****

####  霜降2233  
##### 125#       发表于 2023-2-13 14:58

人类的记忆包含着大量的错觉，也应该算是对现实世界的有损压缩


*****

####  ackroyd2  
##### 126#       发表于 2023-2-13 16:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59725902&amp;ptid=2119156" target="_blank">蛋饼 发表于 2023-2-13 13:13</a>

科幻作家谈技术的问题就是，有些内容很可能像ChatGPT的瞎编一样是not even remotely true的，

比如这个压 ...</blockquote>
你说“里面提到的算术也是大模型的涌现能力，”

那意思chatgpt再扩张规模就能算数了？


*****

####  ackroyd2  
##### 127#       发表于 2023-2-13 16:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59725443&amp;ptid=2119156" target="_blank">ceruleancard 发表于 2023-2-13 12:34</a>

他大概的意思是，电磁力才是更基本的，普通人经验中的宏观现象不够基本。

更具体一点，微观粒子的特性几 ...</blockquote>
感觉物理公式也是对物理现象的压缩。

喂进去一万年的太阳系各行星恒星相对位置坐标，是不是能预测出下一刻地球的位置在哪。不能直接给出引力公式，但是能给出计算结果。


*****

####  ceruleancard  
##### 128#       发表于 2023-2-13 16:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=59728527&amp;ptid=2119156" target="_blank">ackroyd2 发表于 2023-2-13 16:11</a>

感觉物理公式也是对物理现象的压缩。

喂进去一万年的太阳系各行星恒星相对位置坐标，是不是能预测出下一 ...</blockquote>
万有引力也许可以，但是，进入理论物理的时代以来，有大量不存在现象的物理公式，很多重要的公式都是先推导出来，再设计实验证明，更别说现在还有很多实验尚未证实的。

你说的喂坐标预测地球在哪儿，与其说是研究物理，不如说是用大数据来模拟自然，也许在元宇宙里会很有用吧。

