
*****

####  无可奉吿  
##### 1#       楼主       发表于 2025-2-18 08:05

 本帖最后由 无可奉吿 于 2025-2-18 08:12 编辑 

思路就是3674服务器搭配英特尔持久内存

把模型跑到持久内存模拟的磁盘上

买2条256g的就够了，速度是1.1token

现在都在等ktransformers方案落地 那样搭配m10计算卡就能跑到7token速度就真完美了

毕竟是五六年前服务器用的了 现在鱼上大把淘汰处理的

当然这个价格能下来前提是鱼贩子不会应声涨价

可惜我去年买的是730xd 当时要是加点钱上740就玩上了

[https://www.bilibili.com/video/BV1SPwdevEKP](https://www.bilibili.com/video/BV1SPwdevEKP)

*****

####  雪影  
##### 2#       发表于 2025-2-18 08:09

带宽多少？最大限制是带宽

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  无可奉吿  
##### 3#         楼主| 发表于 2025-2-18 08:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67453543&amp;ptid=2246579" target="_blank">雪影 发表于 2025-2-18 08:09</a>

带宽多少？最大限制是带宽

—— 来自 鹅球 v3.3.96-alpha</blockquote>
英特尔持久内存磁盘模式读取是80g/s吧

比固态虚拟内存可快太多了

*****

####  thelinli2  
##### 4#       发表于 2025-2-18 08:57

感觉这真是改变时代的创举了。。。

*****

####  曾经很纯良  
##### 5#       发表于 2025-2-18 09:11

这两根傲腾的带宽比双路X99的八通道ddr3还高一点

*****

####  qqks  
##### 6#       发表于 2025-2-18 09:15

再多加几根傲腾可行吗

*****

####  ltycomputer  
##### 7#       发表于 2025-2-18 09:21

 本帖最后由 ltycomputer 于 2025-2-18 09:27 编辑 

<img src="https://p.sda1.dev/22/e7ad2d41068efac16a95b92dce0b6db2/ssss.jpg" referrerpolicy="no-referrer">

两年前还真买过这玩意洋垃圾

首先这玩意DDR4 2666，硬盘模式单条带宽只有20GB/s读，延迟比DIMM高一个数量级，带宽和同频内存一样，也就便宜点

另外视频里量化到很小，UP说128G硬盘就够用……全量671B模型占用多少大家都知道

另外真想便宜，CPU去买腾讯定制的6133，几十块一颗，英业达刀片双路主板，200元一张

双路合计12通道DDR4 2666带宽仍然捉鸡

*****

####  Hikiyaga⑧man  
##### 8#       发表于 2025-2-18 09:22

傲腾价格要起飞了吗 英特尔又卖飞一个业务<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  鸳鸳相抱  
##### 9#       发表于 2025-2-18 09:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67453939&amp;ptid=2246579" target="_blank">Hikiyaga⑧man 发表于 2025-2-18 09:22</a>
傲腾价格要起飞了吗 英特尔又卖飞一个业务

—— 来自 鹅球 v3.3.96-alpha</blockquote>
也就是现在消费级产品缺失所以各种玩具频出…论个人用性价比不如直接买API，多人用token太低没法做服务
推理专用的产品以后大概率还是靠统一内存

*****

####  GrimReaper  
##### 10#       发表于 2025-2-18 09:29

这思路莫名有种图吧大佬的感觉……

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  小牛无大将  
##### 11#       发表于 2025-2-18 09:31

1.1token能干啥…太慢了，翻十倍都不够快

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  隰有苌楚  
##### 12#       发表于 2025-2-18 09:32

可以说是AI篮子工程了

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

﹍﹍﹍

评分

 参与人数 1战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| darktide| + 2|欢乐多|

查看全部评分

*****

####  百猪夜行  
##### 13#       发表于 2025-2-18 09:33

如果只想低成本玩玩可以这样弄，但这种已淘汰硬件后续维护成本还是挺高的，过几年价格翻几倍都很正常。

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  格林达姆  
##### 14#       发表于 2025-2-18 09:33

1.1.token，那说句话岂不是都是以分钟为单位<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

*****

####  Elicasa  
##### 15#       发表于 2025-2-18 09:35

按d老师的深度思考强度，一个问题等300秒思考，再300秒回答<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

----发送自 [Sony XQ-AT72,Android 12](http://stage1.5j4m.com/?1.42)

*****

####  中国人  
##### 16#       发表于 2025-2-18 09:37

闪电："Ha~~ha~~ha~~"

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| darklinden| + 1|欢乐多|

查看全部评分

*****

####  Rufus.X  
##### 17#       发表于 2025-2-18 09:41

3DXpoint 技术刚出时惊为天人，傲腾退市时我扼腕叹息 

搞不好这才是英特尔翻身的机会，抢的还是英伟达的饭碗

*****

####  原装大小姐  
##### 18#       发表于 2025-2-18 09:42

这太慢了，不属于可用范畴，100每秒还差不多

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  ysubm  
##### 19#       发表于 2025-2-18 09:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67453935&amp;ptid=2246579" target="_blank">ltycomputer 发表于 2025-2-18 09:21</a>
两年前还真买过这玩意洋垃圾

首先这玩意DDR4 2666，硬盘模式单条带宽只有20GB/s读，延迟比DIMM高一个数 ...</blockquote>
视频里的方案是6条128g的傲腾

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  like0036  
##### 20#       发表于 2025-2-18 09:48

这个速度 还不如花2000充值一下api

*****

####  罗莉控  
##### 21#       发表于 2025-2-18 09:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67453560&amp;ptid=2246579" target="_blank">无可奉吿 发表于 2025-2-18 08:14</a>

英特尔持久内存磁盘模式读取是80g/s吧

比固态虚拟内存可快太多了</blockquote>
感觉拿16根32GB的基础版傲腾条子，插到高内存通道的主板上，效果更好吧

*****

####  蜇灵  
##### 22#       发表于 2025-2-18 09:57

这也太慢了<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

翻十倍可能还凑合一下

*****

####  塔奇克马  
##### 23#       发表于 2025-2-18 09:59

有2000元 14t/s方案吗<img src="https://static.saraba1st.com/image/smiley/face2017/027.png" referrerpolicy="no-referrer">

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  シマエナガ  
##### 24#       发表于 2025-2-18 10:00

1.1 token/s。好家伙，问AI点事睡一觉起来看回答是吧

*****

####  哌啶  
##### 25#       发表于 2025-2-18 10:00

我平时拿api读文献都是三万三万的用<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">这速度比我自己读还慢了

*****

####  treexper  
##### 26#       发表于 2025-2-18 10:04

别这样。

*****

####  gearh  
##### 27#       发表于 2025-2-18 10:05

不考虑思考过程，至少要5token每秒以上才能匹配人类阅读速度

*****

####  ColinWine  
##### 28#       发表于 2025-2-18 10:06

不上d5这带宽约等于残废啊，基本没什么没可用性，等过两年上d5吧

*****

####  9Suns  
##### 29#       发表于 2025-2-18 10:12

 本帖最后由 9Suns 于 2025-2-18 10:17 编辑 

KTransformer的新更新

[https://github.com/kvcache-ai/kt ... ekR1_V3_tutorial.md](https://github.com/kvcache-ai/ktransformers/blob/main/doc/en/DeepseekR1_V3_tutorial.md)

[NEW!!!] Local 671B DeepSeek-Coder-V3/R1: Running its Q4_K_M version using only 14GB VRAM and 382GB DRAM.
Prefill Speed (tokens/s):KTransformers: 54.21 (32 cores) → 74.362 (dual-socket, 2×32 cores) → 255.26 (optimized AMX-based MoE kernel, V0.3 only) → 286.55 (selectively using 6 experts, V0.3 only)Compared to 10.31 tokens/s in llama.cpp with 2×32 cores, achieving up to 27.79× speedup.
Decode Speed (tokens/s):
KTransformers: 8.73 (32 cores) → 11.26 (dual-socket, 2×32 cores) → 13.69 (selectively using 6 experts, V0.3 only)Compared to 4.51 tokens/s in llama.cpp with 2×32 cores, achieving up to 3.03× speedup.

看这个速度算是不错了，不过硬件要求还是有的， 跑的也只是Q4量化
Model: DeepseekV3-q4km (int4)CPU: cpu_model_name: Intel (R) Xeon (R) Gold 6454S, 32 cores per socket, 2 sockets, 2 numa nodesGPU: 4090 24G VRAM

*****

####  UNICORN00  
##### 30#       发表于 2025-2-18 10:27

纯垃圾佬的玩具。。

*****

####  黑夜再来1987  
##### 31#       发表于 2025-2-18 10:52

好嘛.2000块钱我是真的有.

*****

####  ltycomputer  
##### 32#       发表于 2025-2-18 11:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67454339&amp;ptid=2246579" target="_blank">シマエナガ 发表于 2025-2-18 10:00</a>

1.1 token/s。好家伙，问AI点事睡一觉起来看回答是吧</blockquote>
什么赛博笔友

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| zing223| + 1|可爱的比喻hhh|

查看全部评分

*****

####  老岳  
##### 33#       发表于 2025-2-18 11:15

<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">以前是垃圾佬装机跑3A游戏，以后就是垃圾佬装机跑AI模型了

*****

####  thq  
##### 34#       发表于 2025-2-18 11:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67454070&amp;ptid=2246579" target="_blank">格林达姆 发表于 2025-2-18 09:33</a>

1.1.token，那说句话岂不是都是以分钟为单位</blockquote>
佛诺文奇的《真名实姓》里面， 大反派邮件人的token怕是都不到1.1。现在2000就能有了。

*****

####  剑起苍斓  
##### 35#       发表于 2025-2-18 11:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67454475&amp;ptid=2246579" target="_blank">9Suns 发表于 2025-2-18 10:12</a>
KTransformer的新更新</blockquote>
还有内存382G啊

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  Alexmacau8  
##### 36#       发表于 2025-2-18 11:32

傲腾内存本来就是个半成品 还要附带配置普通ddr4 搭配兼容性极差 垃圾佬折腾折腾可以 生产是不可能的

*****

####  gammatau  
##### 37#       发表于 2025-2-18 11:45

<blockquote>Hikiyaga⑧man 发表于 2025-2-18 09:22
傲腾价格要起飞了吗 英特尔又卖飞一个业务

—— 来自 鹅球 v3.3.96-alpha</blockquote>
傲腾有人接吗？不是卖飞是直接没了吧

*****

####  琉璃苑軒風  
##### 38#       发表于 2025-2-18 11:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67454162&amp;ptid=2246579" target="_blank">原装大小姐 发表于 2025-2-18 09:42</a>
这太慢了，不属于可用范畴，100每秒还差不多

—— 来自 鹅球 v3.3.96-alpha</blockquote>
你有没有用过ds的api，他都没有100tokens/s

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  原装大小姐  
##### 39#       发表于 2025-2-18 11:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67455658&amp;ptid=2246579" target="_blank">琉璃苑軒風 发表于 2025-2-18 11:48</a>
你有没有用过ds的api，他都没有100tokens/s</blockquote>
你用钉钉带的那个吧，就ds那动不动上万token的回复，4 50/s回答个问题就要几分钟了，用来干嘛，我还不如用通义千问

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha

*****

####  cleaner  
##### 40#       发表于 2025-2-18 11:56

有种末世之后去垃圾填埋区捡垃圾维系数字化社会，然后发射航天器进行银河播种计划的莫名史诗感


*****

####  yuxiao  
##### 41#       发表于 2025-2-18 12:08

傲腾再怎么样速度也没有内存快吧？为啥不直接买大容量内存模拟成硬盘？开机的时候把程序文件全部加载到内存模拟的硬盘里，只要不关机就行了呗？


*****

####  无可奉吿  
##### 42#         楼主| 发表于 2025-2-18 12:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67455898&amp;ptid=2246579" target="_blank">yuxiao 发表于 2025-2-18 12:08</a>
傲腾再怎么样速度也没有内存快吧？为啥不直接买大容量内存模拟成硬盘？开机的时候把程序文件全部加载到内存 ...</blockquote>
贵啊 普通内存就算最便宜16g也要100元
傲腾256g内存300-400元

*****

####  Wiksy  
##### 43#       发表于 2025-2-18 12:20

这速度给你个直观的比较对象：我本地3token每秒的时候让它给我写一个算pi的算法，它think的部分输出了半个小时


*****

####  ななひら  
##### 44#       发表于 2025-2-18 12:27

要不要算算生成相同长度的结果，耗的电是不是比用api还贵

就不算速度差别了


*****

####  anmdrree  
##### 45#       发表于 2025-2-18 12:32

意思是现成的模型其实不需要很高的性能，只要把路铺好，让他走顺畅就行了？ 

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha


*****

####  琉璃苑軒風  
##### 46#       发表于 2025-2-18 12:49

 本帖最后由 琉璃苑軒風 于 2025-2-18 12:51 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67456167&amp;ptid=2246579" target="_blank">anmdrree 发表于 2025-2-18 12:32</a>

意思是现成的模型其实不需要很高的性能，只要把路铺好，让他走顺畅就行了？ 

—— 来自 鹅球 v3.3.96-alph ...</blockquote>
没错，ds的模型，你只推理不训练，可以用高带宽大内存模去代替极其昂贵的大显存显卡

虽然现在一把576G D5内存也要个万把块，但是你想想这钱不够买一张4090，后者单卡只能跑32BQ4的蒸馏模型，只能说勉强解决基础问题

按照KTF的方案，能跑671B 1.58量化的模型整机也就折合1张多4090...(在这里3090不差太多速度，我很怀疑都可以用2080ti 22g魔改卡）


*****

####  精钢魔像  
##### 47#       发表于 2025-2-18 13:04

<blockquote>xia<a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67456329&amp;ptid=2246579" target="_blank">琉璃苑軒風 发表于 2025-2-18 12:49</a>

没错，ds的模型，你只推理不训练，可以用高带宽大内存模去代替极其昂贵的大显存显卡

虽然现在一把576G D5 ...</blockquote>
说不定很快就会出现可以插内存的显卡


*****

####  qqks  
##### 48#       发表于 2025-2-18 13:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67456329&amp;ptid=2246579" target="_blank">琉璃苑軒風 发表于 2025-2-18 12:49</a>

没错，ds的模型，你只推理不训练，可以用高带宽大内存模去代替极其昂贵的大显存显卡

虽然现在一把576G D5 ...</blockquote>
现阶段，只看指标，最划算的是前两天香橙派推出的用华为芯片的ai studio pro，12通道ddr4266，400G带宽的192g内存，配合352tops算力，16000块不到，市面上还没有同类竞品。

问题就是昇腾生态不全，雷电4连接只有5g带宽，不知道能不能加多卡，能加多卡，四块就能跑int8满血版


*****

####  btnooni  
##### 49#       发表于 2025-2-18 14:38

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">那一块主板两个8222l插满12通道能不能跑个2t/s？


*****

####  寻找无双  
##### 50#       发表于 2025-2-18 15:44

我觉得不用在部署上花太多精力研究，先凑合用着。

奥特曼预计ai的成本每年降10倍，听起来有点夸张，不过毋庸置疑的是，每过几个月，更高性能的大模型，更少的参数，更便利的部署方式都会出现。


*****

####  无可奉吿  
##### 51#         楼主| 发表于 2025-2-18 15:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67453935&amp;ptid=2246579" target="_blank">ltycomputer 发表于 2025-2-18 09:21</a>
两年前还真买过这玩意洋垃圾

首先这玩意DDR4 2666，硬盘模式单条带宽只有20GB/s读，延迟比DIMM高一个数 ...</blockquote>
我看视频是128g是系统盘
他买了6条128g傲腾使用磁盘模式生成700多g空间
把400多g的671b放里跑的
所以作者推荐的是买2个256g傲腾就够用了
这样搭配的普通内存也只要2根

*****

####  hydrogen  
##### 52#       发表于 2025-2-18 15:52

说不定过几年手机就能跑本地模型了

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.3.96-alpha


*****

####  windrarara  
##### 53#       发表于 2025-2-19 22:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67457843&amp;ptid=2246579" target="_blank">寻找无双 发表于 2025-2-18 15:44</a>

我觉得不用在部署上花太多精力研究，先凑合用着。

奥特曼预计ai的成本每年降10倍，听起来有点夸张，不过毋 ...</blockquote>
我感觉不会，有一定智力真的能用的AI是不会太小的，不说别的，那些几十G的AI估计连预料都装不完，怎么回答问题……


*****

####  相参降解社畜  
##### 54#       发表于 2025-2-19 22:12

思路挺不错，但是个人认为对一般人乃至普通AI玩家来说，实际意义不大，我觉得我还是等国产内存厂发力把内存价格打下来吧


*****

####  orecheng  
##### 55#       发表于 2025-2-19 22:18

<blockquote>hydrogen 发表于 2025-2-18 15:52
说不定过几年手机就能跑本地模型了

—— 来自 鹅球 v3.3.96-alpha</blockquote>
现在就能

下个阿里的mnn大模型

<img src="https://img.saraba1st.com/forum/202502/19/221850le2500du0embsr3e.jpg" referrerpolicy="no-referrer">

<strong>1000007680.jpg</strong> (357 KB, 下载次数: 0)

下载附件

2025-2-19 22:18 上传


*****

####  某爷  
##### 56#       发表于 2025-2-20 08:03

关键要看kt的落地方案了

