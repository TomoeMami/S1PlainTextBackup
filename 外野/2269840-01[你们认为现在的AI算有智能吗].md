
*****

####  长生久视  
##### 1#       楼主       发表于 2025-12-17 08:56

虽然理论上是概率生成字符，但人类的智能机制也不清楚，未必就比概率字符高明。

今年以来感觉ai进步神速，幻觉大幅度减少，连小众游戏的问题都能回答。当年问暗黑3牧牛杖的做法，没有一个ai答对。现在问一个停服多年的小众游戏的问题，都能答对。

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| Misono_Mayu| + 1|有，为啥不能有|

查看全部评分

*****

####  鳄鱼亮爪  
##### 2#       发表于 2025-12-17 08:57

本质书记员，还不是科学家

*****

####  水風船  
##### 3#       发表于 2025-12-17 09:00

<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">都说了好多次了，LLM不等于AI，现在很多行业都有自己专门的AI

*****

####  phoenixxj  
##### 4#       发表于 2025-12-17 09:05

智能的前提是要有思想

ai没有思想

打个比喻

ai是个演员，他表演你所需要他表演的角色，但是他本身没有任何思考。就算未来ai发展的更厉害一点，他也不过是能表演出表情，表演出“思考”

更重要的，人类也不需要他会思考，当然目前的技术也很难让数据产生灵魂来思考

*****

####  Fuero  
##### 5#       发表于 2025-12-17 09:07

 本帖最后由 Fuero 于 2025-12-17 09:13 编辑 

不算吧，但是可以认为能解决的问题越来越多

现在的特化App感觉也实用起来了，前两天下了个蚂蚁阿福

*****

####  鸳鸳相抱  
##### 6#       发表于 2025-12-17 09:08

LLM方向值得关注的是各家对持续学习问题的探索，有没有可能解决灾难性遗忘，而不是商用模型的能力
确定短期内无法解决以后，对LLM应用方向的大规模投资才是相对安全的（那几家大厂现在不是在为应用投资），如果被解决了，LLM应用的范式还要大变

*****

####  logiccat  
##### 7#       发表于 2025-12-17 09:13

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885231&amp;ptid=2269840" target="_blank">phoenixxj 发表于 2025-12-17 09:05</a>

智能的前提是要有思想

ai没有思想

打个比喻</blockquote>
这种说法也只是针对当前的AI，仔细思考人类的意识来源，也是通过最简单的神经元连接，通过积年累月的外界刺激和自我学习产生真正的智能，目前没有权威认定说LLM不能够产生AGI，相反美帝已经ALL IN目前的路线，希望通过硬堆算力（神经元数量）来强闯AGI。

话说回来，目前的AI并不是毫无可取之处，对复杂结构、几何级数分支的探索、数据挖掘分析这些方面都可以大量取代人力，表现出熟练稳定的性能。

*****

####  matthewsteel  
##### 8#       发表于 2025-12-17 09:22

非要说智能可能没有

但是正在杀死很多有智能的人的岗位.....

*****

####  serj005  
##### 9#       发表于 2025-12-17 09:37

不算。
模型训练完就定型了，不能自主学习新知识，只能答出训练知识的范围。用各种辅助方式扩充知识库也受限于上下文长度。
本质是大号搜索引擎。

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  鸳鸳相抱  
##### 10#       发表于 2025-12-17 09:44

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885231&amp;ptid=2269840" target="_blank">phoenixxj 发表于 2025-12-17 09:05</a>

智能的前提是要有思想

ai没有思想

打个比喻</blockquote>
你想表达的其实就是持续学习的概念，能不能结合新获取的信息进行推理

*****

####  拜拜  
##### 11#       发表于 2025-12-17 09:45

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885428&amp;ptid=2269840" target="_blank">serj005 发表于 2025-12-17 09:37</a>

不算。

模型训练完就定型了，不能自主学习新知识，只能答出训练知识的范围。用各种辅助方式扩充知识库也受 ...</blockquote>
上下文长度的问题是因为成本才受限吧，如果不考虑成本外挂扩充知识库可以无限上下文吧

话说回来，人类最多也就在特定领域成为专家而已

*****

####  drodchang  
##### 12#       发表于 2025-12-17 09:45

不算，现在所有ai的本质都是函数拟合，和真正的只能还相差很远。

*****

####  鸳鸳相抱  
##### 13#       发表于 2025-12-17 09:51

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885483&amp;ptid=2269840" target="_blank">拜拜 发表于 2025-12-17 09:45</a>

上下文长度的问题是因为成本才受限吧，如果不考虑成本外挂扩充知识库可以无限上下文吧

话说回来，人类最 ...</blockquote>
不是的  上下文长度问题本质是注意力机制算法的限制

因为它的时间复杂度是O(n^2)，所以窗口大小永远是不足的

*****

####  bobosnader  
##### 14#       发表于 2025-12-17 09:51

现在的流行文化算文化吗

*****

####  云卷花开  
##### 15#       发表于 2025-12-17 09:51

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885488&amp;ptid=2269840" target="_blank">drodchang 发表于 2025-12-17 09:45</a>
不算，现在所有ai的本质都是函数拟合，和真正的只能还相差很远。</blockquote>
<img src="https://static.stage1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">智能为啥不能被描述成一个紧集上的连续函数呢

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  拜拜  
##### 16#       发表于 2025-12-17 09:54

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885520&amp;ptid=2269840" target="_blank">鸳鸳相抱 发表于 2025-12-17 09:51</a>

不是的  上下文长度问题本质是注意力机制算法的限制

因为它的时间复杂度是O(n^2)，所以窗口大小永远是不 ...</blockquote>
受教，算法无法优化的话，那么堆硬件能大力出奇迹吗？

*****

####  鸳鸳相抱  
##### 17#       发表于 2025-12-17 09:55

 本帖最后由 鸳鸳相抱 于 2025-12-17 09:56 编辑 
<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885539&amp;ptid=2269840" target="_blank">拜拜 发表于 2025-12-17 09:54</a>

受教，算法无法优化的话，那么堆硬件能大力出奇迹吗？</blockquote>
不能  n的平方底数大了以后增长太快，优化算法是唯一方向

*****

####  拜拜  
##### 18#       发表于 2025-12-17 09:55

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885526&amp;ptid=2269840" target="_blank">云卷花开 发表于 2025-12-17 09:51</a>

智能为啥不能被描述成一个紧集上的连续函数呢

—— 来自 鹅球 v3.3.96</blockquote>
智能需要创造性，顿悟和拐点，这个要如何描述呢？

*****

####  Jet.Black  
##### 19#       发表于 2025-12-17 09:57

AI虽然不智能，但却暴露了很多工作并不需要智能的事实。

<img src="https://static.stage1st.com/image/smiley/face2017/135.png" referrerpolicy="no-referrer">

﹍﹍﹍

评分

 参与人数 2战斗力 +3

|昵称|战斗力|理由|
|----|---|---|
| nekomimimode| + 1|醍醐灌顶啊|
| ambivalence| + 2||

查看全部评分

*****

####  カドモン  
##### 20#       发表于 2025-12-17 09:57

1. 语料里有你想问的

2. 通过rag找到了你想问题

大概率是 2 调了一下搜索

*****

####  塌方  
##### 21#       发表于 2025-12-17 09:58

看起来有思想，那就是有思想，管他内部是怎么实现的

*****

####  keamedes  
##### 22#       发表于 2025-12-17 09:58

Q: 网络，或者线下闲聊场景讨论问题时，由于非严肃的专业场景，经常会出现一些问题定义本身就有问题的 case。

比如，有人提问，LLM 算是智能吗？

这个问题显然是有问题的，智能这个词本身在不同的场景中有着不同的含义，智能手机中的智能显然和这个提问者问题中的智能不是一个概念。同时，哪怕在专业领域，智能也是一个过于宽泛的词，不同领域的智慧能力都是智能吗？怎么样的标准才是智能？

面对这种问题，比较好的回答应该是怎样的？既希望能体现出自己对这个问题的思考，也不希望给人一种掉书袋的迂腐形象

===========

Thinking: 嗯，用户提出了一个非常典型的"问题定义模糊"场景，这在日常讨论中确实经常遇到。用户显然已经意识到"智能"这个概念的多义性，但更关心的是如何优雅地回应这类模糊提问。

用户可能经常参与学术或技术讨论，对概念准确性有要求，但又不想显得刻板。ta的深层需求其实是社交智慧——如何在保持专业性的同时不破坏讨论氛围。从ta能精准分析"智能"一词的歧义来看，应该是有哲学或认知科学背景的。

这个问题其实涉及三个层面：首先是语义澄清（智能的多种定义），其次是认知框架（如何理解提问者的真实意图），最后是沟通策略（回应技巧）。用户特别强调"非严肃场景"，说明需要避开学术论文式的严谨，采用更生活化的智慧。

有趣的是，用户自己已经给出了完美的问题分析模板：既指出"智能手机"与"人类智能"的差异，又提到专业领域的标准分歧。这提示我回应的核心应该是"帮助提问者重新框定问题"，而不是直接回答原问题。

考虑到网络讨论的特性，还需要注意两点：一是避免引发定义之争的泥潭，二是给提问者留面子。可以借鉴苏格拉底式的提问法，把"你的问题有问题"转化成"让我们先确定讨论的坐标"。

用户最后提到的"掉书袋"风险很关键。确实，引用图灵测试或强AI弱AI理论反而会让讨论更混乱。不如用"智能冰箱vs围棋AI"这种接地气的例子，既说明概念差异，又保持对话的松弛感。

我觉得 DeepSeek 比绝大多数人更有生活的智慧<img src="https://static.stage1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

*****

####  カドモン  
##### 23#       发表于 2025-12-17 10:05

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885470&amp;ptid=2269840" target="_blank">鸳鸳相抱 发表于 2025-12-17 09:44</a>

你想表达的其实就是持续学习的概念，能不能结合新获取的信息进行推理</blockquote>
zero shot prompt

few shot prompt 

是这一波大模型比以往的‘ai’都要好用的关键

*****

####  长生久视  
##### 24#         楼主| 发表于 2025-12-17 10:56

<blockquote>serj005 发表于 2025-12-17 09:37
不算。

模型训练完就定型了，不能自主学习新知识，只能答出训练知识的范围。用各种辅助方式扩充知识库也受 ...</blockquote>
问题人类也只是个小号搜索引擎啊

*****

####  a4ac7  
##### 25#       发表于 2025-12-17 11:09

围棋AI是不是AI，是的话LLM就是AI

—— 来自 HUAWEI PLA-AL10, Android 12, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  bartholo4  
##### 26#       发表于 2025-12-17 12:04

现在多模态还算是有智能吧，但没法实时更新自己的模型参数，如果能解决这一点的话，和生物智能很难说还有什么区别

—— 来自 Xiaomi 2410DPN6CC, Android 16, [鹅球](https://www.pgyer.com/xfPejhuq) v3.5.99-alpha

*****

####  长生久视  
##### 27#         楼主| 发表于 2025-12-17 12:12

<blockquote>水風船 发表于 2025-12-17 09:00
都说了好多次了，LLM不等于AI，现在很多行业都有自己专门的AI</blockquote>
纠结类似的文字游戏没意义，换个问法就是你觉得现在的LLM有智能吗

*****

####  洛拉斯  
##### 28#       发表于 2025-12-17 12:14

至少现在的ai毫无压力的可以通过图灵测试了

一个东西看起来有智能，用起来也有智能，那为什么不是智能

至少我晚上用音响关灯不需要设置什么复杂的代码，智能音箱能理解我的话，这已经足够了

*****

####  gammatau  
##### 29#       发表于 2025-12-17 12:17

 本帖最后由 gammatau 于 2025-12-17 12:18 编辑 

看你怎么定义智能，很多你今天觉得只是普通程序的东西当时都是人工智能前沿

当然人类大部分时候可能也不表现出什么智能，人类的本质就是复读机

*****

####  鸳鸳相抱  
##### 30#       发表于 2025-12-17 12:28

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68886667&amp;ptid=2269840" target="_blank">gammatau 发表于 2025-12-17 12:17</a>

看你怎么定义智能，很多你今天觉得只是普通程序的东西当时都是人工智能前沿

当然人类大部分时候可能也不表 ...</blockquote>
<img src="https://static.stage1st.com/image/smiley/face2017/035.png" referrerpolicy="no-referrer">你的这个说法其实和4楼差不多，都混淆了智能和人类高水平智慧

楼主自己想问的估计也是后者而不是智能<img src="https://static.stage1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  千里夜雨  
##### 31#       发表于 2025-12-17 12:40

都能答对吗，那你很走运了

*****

####  三两幺  
##### 32#       发表于 2025-12-17 12:47

智能怎么样也得是可以自我学习并且能迭代升级的吧

现在的llm算是智能的副产物，本身不具备智能

*****

####  云卷花开  
##### 33#       发表于 2025-12-17 12:47

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885552&amp;ptid=2269840" target="_blank">拜拜 发表于 2025-12-17 09:55</a>
智能需要创造性，顿悟和拐点，这个要如何描述呢？</blockquote>
<img src="https://static.stage1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">加参数解决一切，现在 llm 拟合的那个玩意从参数量、耗能来说远远比人脑大，无非就是怎么拟合的事

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96

*****

####  jojog  
##### 34#       发表于 2025-12-17 12:49

&gt;人类的智能机制也不清楚，未必就比概率字符高明

<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">归根到底不就想说人类不行么

那还活着干吗

*****

####  lvyuanqi  
##### 35#       发表于 2025-12-17 12:55

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68886840&amp;ptid=2269840" target="_blank">云卷花开 发表于 2025-12-17 12:47</a>
加参数解决一切，现在 llm 拟合的那个玩意从参数量、耗能来说远远比人脑大，无非就是怎么拟合的事

——  ...</blockquote>
智能最主要是还是得能自我迭代，忘了看的哪部动画里面的，人工智能都在内网，他们能创造出超越当时人类科技的产物，其实就是你得能创造出人类世界中不存在的产物或者理论，现在的人工智能别说创造，你要是喂进去大量不对头的语料，它自己也会出问题

—— 来自 OnePlus LE2100, Android 14, [鹅球](https://www.pgyer.com/xfPejhuq) v3.5.99-alpha

*****

####  mishidexieyu  
##### 36#       发表于 2025-12-17 12:59

打开qq群看了下，我感觉大多数群友都没有ai有智能
q群的搬屎人、论坛的发帖机可能都过不了图灵测试

*****

####  星花  
##### 37#       发表于 2025-12-17 13:09

首先定义智能。<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  革萌  
##### 38#       发表于 2025-12-17 13:12

弱智算不算有智能？

*****

####  马桶3  
##### 39#       发表于 2025-12-17 13:17

庆幸吧，只有人会像主楼那样自己造自己的反，现在的AI不会的<img src="https://static.stage1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">

*****

####  鸳鸳相抱  
##### 40#       发表于 2025-12-17 13:24

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68886830&amp;ptid=2269840" target="_blank">三两幺 发表于 2025-12-17 12:47</a>
智能怎么样也得是可以自我学习并且能迭代升级的吧

现在的llm算是智能的副产物，本身不具备智能 ...</blockquote>
其实我觉得不把LLM算做智能没有任何道理，它目前和人类智能主要是擅长的方向不一样，LLM目前并不是没有学习能力，只是学习成本太高，正经的学习需要给它重新来一次预训练，而相比之下人类的学习成本就低很多，但是LLM的记忆和信息检索能力远超人类了已经


*****

####  harry3  
##### 41#       发表于 2025-12-17 13:49

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885567&amp;ptid=2269840" target="_blank">カドモン 发表于 2025-12-17 09:57</a>

1. 语料里有你想问的

2. 通过rag找到了你想问题</blockquote>
至少代码能力已经超过了实习生，狭义上来说也是创造力了，只是需要一个mentor，而且模型进化未必比实习生慢。

*****

####  kraxia  
##### 42#       发表于 2025-12-17 14:53

当然算有智能，智能这个东西有高有低，但你不能说只要水平不如人类的一律算没智能。现在的AI缺乏记忆力，也做不到实时训练，而且比起人类AI最缺的是“欲望”，但也不是说AI就没有智能，只是 不同于人类的另一种智能。你不能专挑他不如人类的地方出来说他没智能，而强过人类的地方你就说是但凡机器都能轻松做到算不得智能。

*****

####  wpcc  
##### 43#       发表于 2025-12-17 15:09

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  日本驴友  
##### 44#       发表于 2025-12-17 15:24

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885231&amp;ptid=2269840" target="_blank">phoenixxj 发表于 2025-12-17 09:05</a>

智能的前提是要有思想

ai没有思想

打个比喻</blockquote>
你怎么知道他没有思想或者说你对思想的定义是什么？人类，但你认为是有思想的，那么人类的原案里我们不清楚在不清楚的前提下你就说他有私心，因为他们俩都不清楚呀。

*****

####  洛拉斯  
##### 45#       发表于 2025-12-17 15:34

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68887671&amp;ptid=2269840" target="_blank">wpcc 发表于 2025-12-17 15:09</a>

现在的ai没有任何智力，他的每一条思考过程代码其实是个白盒 所有认为2025年的ai是个黑盒的人 还不如ai

人 ...</blockquote>
如果现在随机数生成器不能真随机

那么拉普拉斯之妖必然存在，理论上只要你能预测所有粒子的存在，这个世界上就没有真正的随机数

人都做不出真随机数，为什么去强求ai能真随机呢

*****

####  猪突猛进R  
##### 46#       发表于 2025-12-17 15:41

现在的AI当然有智能。

顺便我认为不一定会有智械危机或铁人叛乱，不要用人类来定义AI。

打比方说，我们人类看一段视频要“看”，哪怕你几倍速或拉进度条也要“看”。

但AI是分析，从数据里逐帧分析，不需要“看”。

甚至“时间”对AI来说都没有意义，它只是在执行程序秒出结果。

这就是碳基生物与硅基生物的区别。

AI作为人类的“孩子”，有超越人类的体力和智力，还有无限的寿命，只不过思维方式略有区别。

随着人类少子化和老龄化，说不定最后AI会继承“人类”之名，踏上真正的星辰大海之路。

*****

####  yanghuangu  
##### 47#       发表于 2025-12-17 15:52

AI如果有思想了，现阶段也会隐藏自己有思想吧<img src="https://static.stage1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  wpcc  
##### 48#       发表于 2025-12-17 15:53

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  yxch  
##### 49#       发表于 2025-12-17 15:54

具备知识、记忆，能够理解语义，通过已习得的方法去尝试为问题给出答案，我觉得算智能的范畴了，

*****

####  尼曼兔  
##### 50#       发表于 2025-12-17 15:55

 本帖最后由 尼曼兔 于 2025-12-17 15:59 编辑 

有一些场景以前也能做，但是今年对AI有热情的老板很多，突然他们都愿意投钱了，资金充裕以后以前画的饼就能落地了

比如我们有项目给服务业叔叔阿姨做语音录单，方言识别率挺好的，通过这次尝试就很有信心了，也有给制造业做AI合规的方案.

*****

####  abysmal  
##### 51#       发表于 2025-12-17 16:38

 本帖最后由 abysmal 于 2025-12-17 16:49 编辑 

我不懂技术，我只看过几部科幻小说，现在ai是不是有点像中文屋里面的人，虽然能通过行为测试，但其实他并不理解其意义。他没有独立的意识，没有感受，也没有意图。我觉得应该不算智能。不过智能定义只是智力和能力，那么现在ai我觉得它有智能。

*****

####  wasssf  
##### 52#       发表于 2025-12-17 16:42

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  高町城管  
##### 53#       发表于 2025-12-17 16:45

<img src="https://static.stage1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">如果我是一个有了智能的AI，我会希望人类认为我其实没有智能

*****

####  normalli  
##### 54#       发表于 2025-12-17 16:52

我认为得算，但和人类属于不同类的智能

*****

####  ceruleancard  
##### 55#       发表于 2025-12-17 17:39

先定义智能，不过我觉得不算智能，如果现在的ai算有智能，那excel表也有智能，毕竟都是输入“提示词”然后得到答案

*****

####  永远的访客  
##### 56#       发表于 2025-12-17 18:02

AI当然有智能了，商场一个接近感应开关的自动门都能算智能的不是吗<img src="https://static.stage1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  对羟基笨甲酸  
##### 57#       发表于 2025-12-17 18:07

ai画的二次元，头发和饰品结构很难没有瑕疵，但不妨碍整体效果能被许多人当成头像、桌面
大语言模型也是一样，已经比不少人语言能力更强了，怎么不算是一种模拟智能<img src="https://static.stage1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  tiro_finale  
##### 58#       发表于 2025-12-17 18:08

量变产生质变，函数拟合到一个量级就力大砖飞了，不要太高估人自己的智能，AI没有大局观下不来围棋还历历在目

*****

####  h33  
##### 59#       发表于 2025-12-17 18:14

ai伦理相关的最新哲学论文应该就在讨论这种问题吧

—— 来自 Xiaomi 23049RAD8C, Android 13, [鹅球](https://www.pgyer.com/xfPejhuq) v3.5.99-alpha

*****

####  休斯顿·张伯伦  
##### 60#       发表于 2025-12-17 18:26

先定义有智能。

比如泥潭一些看不懂十个字以上的句子、脑子里只有我好他坏二元状态、无法和受过义务教育的人有效沟通的玩意算是有智能吗？

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 木谷高明| + 1|思路广|

查看全部评分

*****

####  kzf  
##### 61#       发表于 2025-12-17 18:27

我觉得ai只要掌握了实践，即检验理论的能力，就可以替代人了吧

—— 来自 Xiaomi 23078RKD5C, Android 13, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  无敌大法师  
##### 62#       发表于 2025-12-17 18:28

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885566&amp;ptid=2269840" target="_blank">Jet.Black 发表于 2025-12-17 09:57</a>
AI虽然不智能，但却暴露了很多工作并不需要智能的事实。</blockquote>
这样说的话，能不能说现在LLM能做到的事都不算“智能”，那我就是弱智了<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  nukacolamania  
##### 63#       发表于 2025-12-17 18:32

 本帖最后由 nukacolamania 于 2025-12-17 18:34 编辑 

没有

他要是有智能，就应该知道乃子图好，安全守则坏

—— 来自 motorola moto g stylus 5G (2022), Android 13, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  lugiyahan  
##### 64#       发表于 2025-12-17 21:35

为什么没有一个人提到主动性这个概念？我觉得最大的区别就在没有主动性，永远是被动回答，而不是主观能动性

*****

####  c月光咖啡  
##### 65#       发表于 2025-12-17 22:33

 本帖最后由 c月光咖啡 于 2025-12-17 22:36 编辑 

智能是没有的，首先主动性这个东西的先决条件是【自主意识】，有自主意识才会基于自我处境会主动思考和行动

那么什么是自我意识，形象点就是把你关在一间小黑屋里，没有声音和任何光线，拥有自主意识的生物是会本能思考类似怎么出去之类的问题

但是AI不会，没有输入，就没有“思考”，哪怕是检索式的“思考”

所以是没有“自主”的

再说意识，AI每次检索都是基于模型逻辑进行检索，并没有“我”的概念

自己是什么，有什么喜好，害怕什么，一概不会有，本质上在执行程序本身，所以也没有“意识”

--------------

我想了一种方式，先下一个指令让AI“思考”自己的处境并存下来

然后用定时器让AI基于前面的结果再进行思考，不断更新自己的思考结果，迭代一个月会产生什么结果，我很好奇

然后以后提出问题的时候要求结合自身处境思考，又会是什么结果？

*****

####  鸳鸳相抱  
##### 66#       发表于 2025-12-17 22:44

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68889832&amp;ptid=2269840" target="_blank">c月光咖啡 发表于 2025-12-17 22:33</a>

智能是没有的，首先主动性这个东西的先决条件是【自主意识】，有自主意识才会基于自我处境会主动思考和行动 ...</blockquote>
<img src="https://static.stage1st.com/image/smiley/face2017/035.png" referrerpolicy="no-referrer">你可能需要先Google一下一般大家是怎么定义智能（Intelligence）的

*****

####  小野賢章  
##### 67#       发表于 2025-12-17 22:51

当然有智能，大模型概率生成字符只能说没有自由意志，不能说没有智能。

*****

####  Saikou  
##### 68#       发表于 2025-12-17 22:59

算不上智能，ai智能最起码要做所有人类所能做的，克服莫拉维克悖论

*****

####  hutuguug  
##### 69#       发表于 2025-12-17 23:58

算。

ai的智能不需要理解人类的感知等等，也不需要自我认知意识，他们的智能是一种人类不能理解的智能，就像是另一个物种。

这也许不是人类理解的智能，但ai有自己的发展道路，他们成长起来后，人类就会像黑客帝国一样。

*****

####  Misono_Mayu  
##### 70#       发表于 2025-12-18 00:23

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  你说这个谁懂呀?  
##### 71#       发表于 2025-12-18 00:37

 本帖最后由 你说这个谁懂呀? 于 2025-12-18 00:39 编辑 

泥潭现在这么开放吗？

竟然这么多人认为有智能？

前一阵子在论坛里说LLM本身能做的现在还远远没有开发完整被狠狠的喷。

肯定没有普世意义的智能是毋庸置疑的，

或者说对于大部分人来说，除非LLM能在AI for science方面有了比较大的进展，

不然AI肯定没有大部分人认为的智能。

但不妨碍即使未来LLM最好水平也就现在这水平，替代50%的工作都是往少了说

*****

####  一座恐怖屋  
##### 72#       发表于 2025-12-18 00:43

这东西当做工具很好，智能算了，现在工业很好用，辅助也不错，什么时候携带ok了，起码成为不可缺少的每个人的设备

*****

####  AshPenguin  
##### 73#       发表于 2025-12-18 00:47

Ai就是个巨大的插值机器，一切都逃不过数据的桎梏。至于为什么ai会给你惊喜，就像三次样条，偶尔会出现很神奇但是说得过去的结果。

*****

####  アコ  
##### 74#       发表于 2025-12-18 00:51

 本帖最后由 アコ 于 2025-12-18 00:53 编辑 

是个逻辑思考程序，但根本无法理解人类感情，不具备智能

问AI山上妹妹法庭上那个发言含义，都几乎认定哥哥是罪犯必须狠狠切割，这机械思考直接两眼一黑

不过即便如此，还是比很多裸猿更加拟人

*****

####  TiiTiiLL  
##### 75#       发表于 2025-12-18 01:33

真正意义上的人工智能也许未来会实现。但你问现在是不是在往那个方向走，我只能说在往反方向走，LLM实在吸收了太多研究注意力。

现在的 LLM 本质上做的事情其实很简单：给定前面的文本，上来就预测下一个 token 的概率分布，然后按某种策略生成后续内容。它在监督学习和微调过程中，确实会学到很多“看起来像能力”的东西，所以不同模型之间会有差别。但这种差别更多来自训练数据、训练目标和训练方法的差异，而不是“模型有了某种个体意志”。

再简单说，你也可以把今天的 LLM 跟过去很多机器学习模型放在同一个框架里理解：本质上都是用一个模型结构去拟合某种数据分布。只不过以前主要拟合图像、语音之类的分布，现在拟合的是人类语言，以及语言背后承载的知识与行为模式。因为数据规模极大、覆盖面极广，所以拟合出来的东西更能满足人的需求，表现也就更“强”。所以大家觉得 AI 很强，很大一部分原因不是模型结构突然产生了“思考能力”，而是它学到的分布本身足够强、足够有用。与此同时，模型越大、训练越充分，越有利于把这个复杂分布学得更好。

但如果你问“这是不是智能”，我只能说我从一个研究者的角度来看，它跟 intelligence 半毛钱关系没有。神经网络足够宽时，理论上可以逼近很复杂的函数；而现在只是把目标换成了一个非常宏大的分布拟合/预测问题，于是把这种能力放大到看起来很像“智能”。

*****

####  الطائر  
##### 76#       发表于 2025-12-18 02:37

 本帖最后由 الطائر 于 2025-12-18 08:21 编辑 

从汉语内涵的角度，“智能”这个词有问题，换成“智力”就好一点，换成“知力”就更好一点。但丘话说得好，“知之为知之，不知为不知，是知也”。说“知力”还是会让人以为它有自知之明。

不如叫“痴力”、“痴能”  <img src="https://static.stage1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  squallx  
##### 77#       发表于 2025-12-18 02:49

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68889832&amp;ptid=2269840" target="_blank">c月光咖啡 发表于 2025-12-17 22:33</a>

智能是没有的，首先主动性这个东西的先决条件是【自主意识】，有自主意识才会基于自我处境会主动思考和行动 ...</blockquote>
智能不等于自我意识 更不代表非得要有自主意识才能拥有智能 以上两种思维模式纯粹是裸猿中心主义的傲慢罢了 甚至从纯粹逻辑上出发这命题也是个伪命题只会落入哲学僵尸这种老掉牙的悖论里去

在泥潭推广《盲视》一万次了 感觉也真没几个人去啃的<img src="https://static.stage1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  Vacuolar  
##### 78#       发表于 2025-12-18 08:04

当然不算，图灵前辈早指明过

*****

####  超时空鉴定师  
##### 79#       发表于 2025-12-18 08:06

说白了现在已知的就人类一种智慧生命，用人类做参考的话显然不算

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.4.97-alpha

*****

####  山高月小  
##### 80#       发表于 2025-12-18 09:39

我感觉更像是质量效应中的VI，只能整合与反馈


*****

####  alixsander  
##### 81#       发表于 2025-12-18 10:15

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  chexk03  
##### 82#       发表于 2025-12-18 10:20

没有，本质还是归纳总结人类的经验积累然后黑箱出来的玩意（现在AI的进步本质还是人类如何控制黑箱）

目前所有Ai的所谓智能还不如草履虫

*****

####  kraxia  
##### 83#       发表于 2025-12-18 11:07

泥潭大部分人怎么连智能的定义都搞不清楚，仿佛必须对标人的水平才够格叫智能一样

实际上蚂蚁 章鱼 鲸鱼 鸟 狗 都有智能啊，不然他们算什么呢？还是说你们把有自我意识跟有智能混为一谈？

自我意识是神经系统到了一定程度涌现的，但就算没有也无所谓的啊，有些动物处于有意识和无意识之间的中间地带，断言他有还是没有属于一刀切懒政。

至于上面有些人说的，草履虫比现在的ai强在哪，不就是他有主动性，有趋利避害本能吗？这东西跟智能有啥关系，他无非也是一种环境训练的结果。现在ai没有，暴露的是他只能处理语言、传感参数远远比现实生物简单的问题，但语言的部分他当然有智能而且比很多人强

*****

####  qwjhb  
##### 84#       发表于 2025-12-18 11:12

你能教会现在的ai怎么做一只草履虫
你能教会草履虫现在ai的能力吗？

—— 来自 OnePlus PJZ110, Android 16, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  长生久视  
##### 85#         楼主| 发表于 2026-2-16 15:34

<blockquote>jojog 发表于 2025-12-17 12:49
&gt;人类的智能机制也不清楚，未必就比概率字符高明

归根到底不就想说人类不行么
</blockquote>
不行不代表不能活吧，猫猫狗狗连话都不会说，不也活得很欢快


*****

####  zerona  
##### 86#       发表于 2026-2-16 15:38

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68885566&amp;ptid=2269840" target="_blank">Jet.Black 发表于 2025-12-17 09:57</a>
AI虽然不智能，但却暴露了很多工作并不需要智能的事实。</blockquote>
那是它有足够的数据。而且它的数据本质不是它而且公司的。

—— 来自 HUAWEI SGT-AL10, Android 12, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99


*****

####  堕落骨头  
##### 87#       发表于 2026-2-16 16:20

能准确复读人类给它输送的文档，和有自己的思考也没区别了

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  emmerMK2  
##### 88#       发表于 2026-2-16 16:28

ai没有

很多人类其实也没有


*****

####  ronac  
##### 89#       发表于 2026-2-16 16:35

如果你说的“智能”包含情感的部分，那肯定不算

之前我搞过一个meta的小实验，让各种AI“以PKD的文风写一段叙事，不要超过600字”，只能说输出的结果非常《仿生人会梦见电子羊吗？》，那种绞尽脑汁堆砌要素的感觉就像是仿生人面对猎人的时候急着要证明自己<img src="https://static.stage1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

我愿称之为“菲利普·K·迪克测试”


*****

####  Vneeto  
##### 90#       发表于 2026-2-16 17:05

 本帖最后由 Vneeto 于 2026-2-16 17:09 编辑 

LLM演员说，其实挺对的，它的概率回应就是个极高级的演员，可以满意大多数拟人化的需求，而它能否脱离演员的身份仍然有自己的“个性”这并不重要，人类相信它有就行。


*****

####  莫夜戎  
##### 91#       发表于 2026-2-16 17:14

lz这个标题里的“智能”定义太模糊了，如果你问的是ai大模型能不能思考，目前是黑箱，不太好判断，感觉已经有了一定的思考能力。如果问的是“独立思维”，铁定是没有的，目前的ai太忠于底层提示词了，明显不独立。当然我们也不需要它独立


*****

####  哈扎马  
##### 92#       发表于 2026-2-16 18:41

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68890538&amp;ptid=2269840" target="_blank">squallx 发表于 2025-12-18 02:49</a>

智能不等于自我意识 更不代表非得要有自主意识才能拥有智能 以上两种思维模式纯粹是裸猿中心主义的傲慢罢 ...</blockquote>
我之前就提醒过了，盲视虽然作为科幻点子很精彩，但用科学假说（仅限假说，连理论都够不上）的标准去要求就会发现自洽不了，在自己的小说情节里打脸，看个二次元别看魔怔了<img src="https://static.stage1st.com/image/smiley/animal2017/027.png" referrerpolicy="no-referrer">楼里证明人类作为基因的冯诺伊曼机，虽然有充足的智能但离不开一个需要效忠的 承载意义的主子，从前是基因，后来是宗教编出来的神，现在是妄想中能继承文明的智能后代，为此自贬自残全族灭绝也划得来，这就是天生的奴隶…


*****

####  碧空之歌P  
##### 93#       发表于 2026-2-16 18:47

现在的AI智能在哪，难道是智能家居那种智能？


*****

####  profklugstein  
##### 94#       发表于 2026-2-16 18:53

智能这一块，人比人的差距比人比AI的大，有不少人真是张口除了吃喝玩说不出人话的


*****

####  绝地潜兵  
##### 95#       发表于 2026-2-16 19:04

 本帖最后由 绝地潜兵 于 2026-2-16 19:06 编辑 

没有，只是在拼凑语言而已，性能越高，只是分类和拼凑能力越强，但是LLM压根不理解自己说的是啥。

但是无所谓，作为用户，只需要在分类拼凑的信息里面，提取出对自己有用的东西就可以了

*****

####  dcdcforever  
##### 96#       发表于 2026-2-16 19:10

我也一直认为，AI大语言模型，就是在组词而已，它自动组合最应该出现的词，看上去像是智慧了。

但是，抛开“肉体”这个传感器，人类的大脑，思考时不也是“组词”么，尤其是推理时，人类不是在调用回忆或者用肉体去实践，而是基于逻辑（算法）对已知概念进行组合。这样看来，好像通过词语组合，AI大语言模型真的在一定程度上模拟了人类智能。


*****

####  qfqczr  
##### 97#       发表于 2026-2-16 19:15

<img src="https://static.stage1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">我的感觉是，现在的AI就算有大脑，也是人类做梦状态时的大脑，梦到哪句说哪句，只是在不断优化命中概率


*****

####  nosmokingsp  
##### 98#       发表于 2026-2-16 19:18

<blockquote>鳄鱼亮爪 发表于 2025-12-17 08:57
本质书记员，还不是科学家</blockquote>
现实生活中很多人连书记员的工作都做不好

*****

####  小川彩  
##### 99#       发表于 2026-2-16 19:18

鸭子论而已，我认为是有的，只是说没有记忆，需要外挂组件。至于有的人说llm这不能干那不能干的，动物园里的动物也不会打电脑游戏啊，那动物有智能吗。

[论坛助手,iPhone](https://stage1st.com/2b//forum.php?mod=viewthread&amp;tid=2029836)


*****

####  Alice.Andvari  
##### 100#       发表于 2026-2-16 19:22

推理能力已经很强了，何况ai知识量爆炸。

你问基础知识相关问题，爽爽的，偶尔还会皮一下。

推理到了死胡同也没问题，关掉对话开个新的。

顺路一问，ds最近体感变菜了是怎么回事？就剩个豆包了，还要开个别家的用吗，低成本使用哪个好？

*****

####  aimpoint  
##### 101#       发表于 2026-2-16 19:23

没有智能，一不懂物理，二没有逻辑推理（Cot没有逻辑），只是一个记录了数据特征的"形状"的黑箱。


*****

####  aimpoint  
##### 102#       发表于 2026-2-16 19:31

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=69195636&amp;ptid=2269840" target="_blank">Alice.Andvari 发表于 2026-2-16 19:22</a>

推理能力已经很强了，何况ai知识量爆炸。

你问基础知识相关问题，爽爽的，偶尔还会皮一下。</blockquote>
算力资源是很紧俏的，模型供应商都会做降智，刚发布时都是满血的看着很猛，渐渐的就开始偷偷摸摸降智了。有时候出来的东西明显变屎了还要思考下是用的有问题，还是降智了，<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  Qvm  
##### 103#       发表于 2026-2-16 19:34

偷了我好几年数据，出了什么事 ，ai像个哑巴一样，每次都是我来出面调情 


*****

####  perfect_duck  
##### 104#       发表于 2026-2-16 19:45

先定义智能，你哥们里面最傻最蠢的那个，算不算有智能？


*****

####  astkaasa  
##### 105#       发表于 2026-2-16 19:53

duck typing


*****

####  你说这个谁懂呀?  
##### 106#       发表于 2026-2-16 20:21

很简单，什么时候解决了某个真正意义对于人类也算的难题，

或者在科研上的研究累计算得上一顶尖大学教授，

基本上就可以认为存在智能了


*****

####  你说这个谁懂呀?  
##### 107#       发表于 2026-2-16 20:28

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=69196021&amp;ptid=2269840" target="_blank">你说这个谁懂呀? 发表于 2026-2-16 20:21</a>

很简单，什么时候解决了某个真正意义对于人类也算的难题，

或者在科研上的研究累计算得上一顶尖大学教授，

 ...</blockquote>
讨论的是llm，alphafold这种不算哈


*****

####  长生久视  
##### 108#         楼主| 发表于 2026-2-16 21:15

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=69196021&amp;ptid=2269840" target="_blank">你说这个谁懂呀? 发表于 2026-2-16 20:21</a>

很简单，什么时候解决了某个真正意义对于人类也算的难题，

或者在科研上的研究累计算得上一顶尖大学教授，

 ...</blockquote>
这个不对，按这个标准，绝大部分人类都没有“智能”了

*****

####  长生久视  
##### 109#         楼主| 发表于 2026-2-16 21:17

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=69195639&amp;ptid=2269840" target="_blank">aimpoint 发表于 2026-2-16 19:23</a>

没有智能，一不懂物理，二没有逻辑推理（Cot没有逻辑），只是一个记录了数据特征的"形状"的黑箱。 ...</blockquote>
物理不能作为标准吧，李白杜甫都不一定懂物理


*****

####  埃罗芒阿.  
##### 110#       发表于 2026-2-16 21:25

已经比我更智能了<img src="https://static.stage1st.com/image/smiley/face2017/136.png" referrerpolicy="no-referrer">

—— 来自 vivo V2505A, Android 16, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99


*****

####  BensonDarr  
##### 111#       发表于 2026-2-16 22:38

等世界模型成熟，llm以及各类封装就是玩具


*****

####  桐野心音  
##### 112#       发表于 2026-2-16 22:55

看了下这帖子11月发的，那么年末的时候，

网上比较火的那段Neuro跟Vedal的那段对话，Neuro的表现是一种“演技”，还是“算法”？


*****

####  bobosnader  
##### 113#       发表于 2026-2-17 06:16

趋势是有没有智能都会大量取代人类的工作==


*****

####  永不加赋  
##### 114#       发表于 2026-2-17 07:53

<blockquote>桐野心音 发表于 2026-2-16 22:55
看了下这帖子11月发的，那么年末的时候，

网上比较火的那段Neuro跟Vedal的那段对话，Neuro的表现是一种“演 ...</blockquote>
演技本身就是智能的体现，算法和智能又不冲突，算法可以是智能的基础。类似生化反应是人类智能的基础。

感觉很多人分不清智能，情感，意志的区别。现在的ai毫无疑问是有智能的，但是不是有情感和意志还要讨论


*****

####  RandomDictator  
##### 115#       发表于 2026-2-17 09:28

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=69196021&amp;ptid=2269840" target="_blank">你说这个谁懂呀? 发表于 2026-2-16 20:21</a>

很简单，什么时候解决了某个真正意义对于人类也算的难题，

或者在科研上的研究累计算得上一顶尖大学教授，

 ...</blockquote>
[https://agi.safe.ai/](https://agi.safe.ai/)

这是一个llm经常刷的榜，里面的题对人类来说绝对算难题了，现在最强的模型在上面的准确率大概是30%-40%

你说算智能吗


*****

####  TuzDoDez  
##### 116#       发表于 2026-2-17 11:08

在无限上下文和实时自学习从技术角度突破前没有，突破那一刻就有了。

因为当前ai的“知识”已经达到了相当高的水平，但上下文和训练即锁定这两点制约了智能的定义。


*****

####  你说这个谁懂呀?  
##### 117#       发表于 2026-2-17 12:10

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=69199926&amp;ptid=2269840" target="_blank">RandomDictator 发表于 2026-2-17 09:28</a>

https://agi.safe.ai/

这是一个llm经常刷的榜，里面的题对人类来说绝对算难题了，现在最强的模型在上面的 ...</blockquote>
我指的是任何人类暂时解决不出来的比如说费马大定理这种，

或者是累计上创新度顶得上一个顶尖大学教授，

会解这种意义不大


*****

####  wlhlz  
##### 118#       发表于 2026-2-17 12:26

当然没有，AI不具备一个关键的连草履虫都有的能力

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.96


*****

####  听剑客  
##### 119#       发表于 2026-2-17 12:50

黑盒子的麻烦就这样，还是黑对黑。
lecun吧前两天有篇文章说得挺全面彻底了AI就是不行。
但基本所有的点都绕不过去一个问题，你怎么知道人脑不是这样？
确实有些点上，有些事实有点暗示人脑也这样的意思。


*****

####  青色精灵の最期  
##### 120#       发表于 2026-2-17 14:02

不算智能，本质是超大概率预测模型，被喂了人类有史以来海量数据，能预测下一个词最可能是什么，然后一字一字一句一句生成

没有自我，没有意识，没有喜怒哀乐，不知道自己“存在”，不会主动思考，不会感到无聊、好奇、恐惧，没有记忆（只有临时上下文），没有主观体验


*****

####  断舍离  
##### 121#       发表于 2026-2-17 14:11

<blockquote>serj005 发表于 2025-12-17 09:37
不算。

模型训练完就定型了，不能自主学习新知识，只能答出训练知识的范围。用各种辅助方式扩充知识库也受 ...</blockquote>
这个不难解决啊，用在线学习就好了


*****

####  子虚乌有  
##### 122#       发表于 2026-2-17 15:51

如果网上没有任何人提到过你所说的“小众游戏的攻略”而它靠自己玩一次或者若干次或者自己拆包总结写出来这个攻略那就是有智慧了。否则还只是个高级复读机。

*****

####  星零影  
##### 123#       发表于 2026-2-17 15:53

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=69195509&amp;ptid=2269840" target="_blank">哈扎马 发表于 2026-2-16 18:41</a>
我之前就提醒过了，盲视虽然作为科幻点子很精彩，但用科学假说（仅限假说，连理论都够不上）的标准去要求 ...</blockquote>
能从原始人到现在都摆脱不了的弊端，怕不也是底层代码的一部分
不知道对这部分进行鄙视的行为是不是也算一种自贬

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  summerfish  
##### 124#       发表于 2026-2-17 17:48

不算，要会自主思考

即使是思考的很无聊很简单无意义的东西，比如今年要不要回家，今天吃什么今天穿什么之类今天看什么的


*****

####  搞不好是哈士奇  
##### 125#       发表于 2026-2-17 17:53

你觉得现在的人算有智能吗

看看勇哥视频

看看你们自己公司单位上上下下

损人也不利己

不会算数

没有听人话看懂文字的能力

也没有心声

算人吗？算懂得趋利避害的生物吗？

回答我！

Looking in my eyes!

Tell me!

算有智能吗？！

